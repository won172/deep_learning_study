{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 전체 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[노션 참고]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 합성곱 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1 완전연결 계층의 문제점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[노션 참고]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.2 합성곱 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[노션 참고]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.3 패딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[노션 참고]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.4 스트라이드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[노션 참고]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.5 3차원 데이터의 합성곱 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[노션 참고]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.6 블록으로 생각하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[노션 참고]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.7 배치 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 풀링 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1 풀링 계층의 특징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[노션 참고]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 합성곱/풀링 계층 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.1 4차원 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(10, 1, 28, 28) # 무작위로 데이터 생성\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.79574817, 0.08842828, 0.70718898, 0.34929613, 0.07131358,\n",
       "        0.13829308, 0.96501063, 0.9466335 , 0.52488883, 0.07356137,\n",
       "        0.11617374, 0.85532189, 0.27119053, 0.47457073, 0.77830674,\n",
       "        0.86699355, 0.46014595, 0.43935413, 0.37091545, 0.03251342,\n",
       "        0.63263562, 0.20855837, 0.42444054, 0.84739944, 0.23845904,\n",
       "        0.8390973 , 0.76565161, 0.50660779],\n",
       "       [0.17016683, 0.95014408, 0.0168886 , 0.87623508, 0.54911526,\n",
       "        0.14216594, 0.95062529, 0.89017534, 0.70414122, 0.00299544,\n",
       "        0.91583023, 0.1400501 , 0.01300034, 0.02065967, 0.30084633,\n",
       "        0.80022788, 0.46938183, 0.20867255, 0.14792393, 0.28199655,\n",
       "        0.31301244, 0.21010532, 0.38289695, 0.33603544, 0.8439165 ,\n",
       "        0.78389929, 0.23743627, 0.39987564],\n",
       "       [0.68185365, 0.0666599 , 0.13073756, 0.61808279, 0.44085632,\n",
       "        0.18973621, 0.40153522, 0.96432748, 0.19187952, 0.64703375,\n",
       "        0.9109528 , 0.70547423, 0.35461413, 0.38289457, 0.5305602 ,\n",
       "        0.09936051, 0.8328704 , 0.98861724, 0.4838718 , 0.33466919,\n",
       "        0.29231544, 0.98340341, 0.39054227, 0.01556352, 0.71296589,\n",
       "        0.09069206, 0.55069422, 0.35592115],\n",
       "       [0.92267984, 0.46810949, 0.25088966, 0.61738812, 0.22647351,\n",
       "        0.20341897, 0.64204581, 0.08162895, 0.28661764, 0.30307404,\n",
       "        0.32736917, 0.59114261, 0.67648072, 0.64972726, 0.13284424,\n",
       "        0.59899575, 0.3968587 , 0.11575218, 0.92988333, 0.38317055,\n",
       "        0.70383634, 0.52377261, 0.47870836, 0.34105798, 0.0016811 ,\n",
       "        0.27879906, 0.34110658, 0.96590758],\n",
       "       [0.44423896, 0.14936347, 0.73122957, 0.29495975, 0.23368635,\n",
       "        0.12670483, 0.02119207, 0.22832097, 0.73582968, 0.66432038,\n",
       "        0.1804238 , 0.08240574, 0.35929184, 0.71870807, 0.38400335,\n",
       "        0.87379973, 0.49150973, 0.46790472, 0.77915725, 0.39529563,\n",
       "        0.7481365 , 0.4374642 , 0.93792608, 0.51798821, 0.49320227,\n",
       "        0.20504246, 0.10652096, 0.57005252],\n",
       "       [0.85189605, 0.55157808, 0.71953281, 0.36859661, 0.55374891,\n",
       "        0.00231881, 0.85229648, 0.32689066, 0.19262676, 0.61753431,\n",
       "        0.7591029 , 0.60802513, 0.10735811, 0.84692472, 0.80611611,\n",
       "        0.38432005, 0.68877493, 0.15007388, 0.21013752, 0.93482009,\n",
       "        0.60466061, 0.24947486, 0.738761  , 0.36414904, 0.34602911,\n",
       "        0.90909716, 0.30790565, 0.05659939],\n",
       "       [0.03851191, 0.76028337, 0.43046087, 0.82765607, 0.74402795,\n",
       "        0.64145523, 0.57805498, 0.05553216, 0.64839919, 0.59638143,\n",
       "        0.24513295, 0.06725038, 0.0096182 , 0.85847076, 0.17220831,\n",
       "        0.68019364, 0.05204946, 0.42368606, 0.70905949, 0.63386616,\n",
       "        0.40150517, 0.6971397 , 0.24330383, 0.05951429, 0.27240179,\n",
       "        0.64208799, 0.59496006, 0.7171637 ],\n",
       "       [0.84502592, 0.39390353, 0.74440622, 0.27055649, 0.98996106,\n",
       "        0.24255773, 0.80331505, 0.05375013, 0.23226953, 0.23114415,\n",
       "        0.42840849, 0.46181717, 0.13794112, 0.15207173, 0.10695659,\n",
       "        0.72163856, 0.7394239 , 0.17192706, 0.22742234, 0.81712283,\n",
       "        0.80208414, 0.07079862, 0.48240141, 0.79660092, 0.0426423 ,\n",
       "        0.76256287, 0.80972307, 0.3008433 ],\n",
       "       [0.73265122, 0.34370916, 0.61474885, 0.00994765, 0.28154161,\n",
       "        0.52653854, 0.83119529, 0.16492229, 0.43759406, 0.9426372 ,\n",
       "        0.74712697, 0.85610137, 0.16221567, 0.89684968, 0.21281963,\n",
       "        0.61163942, 0.30461702, 0.46546554, 0.67010323, 0.8053658 ,\n",
       "        0.92422851, 0.62058395, 0.33576033, 0.96204608, 0.92296896,\n",
       "        0.06668611, 0.66613761, 0.02887626],\n",
       "       [0.80148438, 0.7557705 , 0.47887436, 0.98133773, 0.74986666,\n",
       "        0.02165689, 0.06361358, 0.666626  , 0.67956847, 0.67857501,\n",
       "        0.48150078, 0.5706864 , 0.09093541, 0.80478276, 0.62115122,\n",
       "        0.39807492, 0.39225472, 0.86925447, 0.77529998, 0.20352875,\n",
       "        0.8260613 , 0.45937192, 0.22343943, 0.38535671, 0.07048394,\n",
       "        0.59958436, 0.64589099, 0.1671674 ],\n",
       "       [0.15007745, 0.70563231, 0.85331029, 0.41028156, 0.41297712,\n",
       "        0.77642247, 0.43653148, 0.41147684, 0.32419553, 0.31354842,\n",
       "        0.67952126, 0.81254332, 0.48052298, 0.60804358, 0.62477338,\n",
       "        0.64435562, 0.03999588, 0.75922548, 0.31436294, 0.91265267,\n",
       "        0.91023416, 0.01052859, 0.83951845, 0.07029033, 0.88846491,\n",
       "        0.14433575, 0.26070083, 0.80133348],\n",
       "       [0.04848423, 0.1902016 , 0.39430053, 0.37243372, 0.41142916,\n",
       "        0.50388786, 0.59622181, 0.98144196, 0.41569982, 0.27069088,\n",
       "        0.37760647, 0.51677536, 0.33314264, 0.97188805, 0.53414406,\n",
       "        0.22155453, 0.46899765, 0.63741691, 0.06069967, 0.357696  ,\n",
       "        0.86411394, 0.86092659, 0.95151159, 0.29701409, 0.9896065 ,\n",
       "        0.26011613, 0.40727289, 0.89875578],\n",
       "       [0.6964328 , 0.77789765, 0.74504155, 0.57882098, 0.51624196,\n",
       "        0.28220995, 0.35458688, 0.9932809 , 0.2943474 , 0.50653407,\n",
       "        0.94349148, 0.37118652, 0.73005487, 0.42127573, 0.34150941,\n",
       "        0.80711191, 0.13400699, 0.94086725, 0.67508107, 0.17619844,\n",
       "        0.24843048, 0.72399904, 0.34293572, 0.90467829, 0.98421412,\n",
       "        0.33920068, 0.70800017, 0.06520077],\n",
       "       [0.74999428, 0.47427177, 0.12914344, 0.22107719, 0.56383622,\n",
       "        0.3249669 , 0.02356383, 0.1141039 , 0.41413074, 0.17404671,\n",
       "        0.26911454, 0.32208378, 0.25536521, 0.85251823, 0.32763236,\n",
       "        0.83817494, 0.59350208, 0.86177456, 0.9802132 , 0.53427058,\n",
       "        0.40789514, 0.16562833, 0.03382371, 0.34875957, 0.9915741 ,\n",
       "        0.4173547 , 0.9842005 , 0.79286721],\n",
       "       [0.80279775, 0.1368115 , 0.72042595, 0.23082876, 0.22010386,\n",
       "        0.11297896, 0.21407402, 0.66728578, 0.55190406, 0.73308104,\n",
       "        0.30586865, 0.84140676, 0.95513553, 0.78658946, 0.67022828,\n",
       "        0.6102291 , 0.30242085, 0.12939686, 0.03154366, 0.96610964,\n",
       "        0.09382481, 0.04721824, 0.93624767, 0.77421015, 0.04375895,\n",
       "        0.47316996, 0.00930092, 0.16164493],\n",
       "       [0.45784838, 0.03939625, 0.3101485 , 0.95234844, 0.98866965,\n",
       "        0.24013463, 0.44725318, 0.31919507, 0.39368703, 0.61528976,\n",
       "        0.61446183, 0.94505956, 0.39712873, 0.50698373, 0.10415554,\n",
       "        0.05841215, 0.7233102 , 0.21158513, 0.42748767, 0.33897398,\n",
       "        0.83117805, 0.43174141, 0.79498999, 0.14954956, 0.94920832,\n",
       "        0.21297717, 0.90678713, 0.66424498],\n",
       "       [0.33881001, 0.25788237, 0.4942392 , 0.70721614, 0.88943394,\n",
       "        0.03994251, 0.5290953 , 0.56370688, 0.61823665, 0.80171215,\n",
       "        0.31938996, 0.49679354, 0.22732081, 0.4829857 , 0.38985914,\n",
       "        0.45424112, 0.84628419, 0.71895765, 0.12558082, 0.64000621,\n",
       "        0.17650477, 0.89510374, 0.20629627, 0.70787568, 0.44603671,\n",
       "        0.66144234, 0.36793021, 0.70657182],\n",
       "       [0.87153452, 0.28898858, 0.05080699, 0.08018565, 0.55142917,\n",
       "        0.69709222, 0.1155471 , 0.2519315 , 0.54023437, 0.939071  ,\n",
       "        0.52189661, 0.85584576, 0.5033948 , 0.6469911 , 0.86226846,\n",
       "        0.35573764, 0.8926105 , 0.83365511, 0.82740395, 0.72258818,\n",
       "        0.40908791, 0.52687024, 0.49052667, 0.94583529, 0.83625784,\n",
       "        0.26449368, 0.02753371, 0.42611713],\n",
       "       [0.66922176, 0.48743654, 0.1994766 , 0.6826813 , 0.80959241,\n",
       "        0.49623807, 0.67470583, 0.53732272, 0.51760331, 0.54079681,\n",
       "        0.34348806, 0.28319693, 0.83501633, 0.93700098, 0.26041035,\n",
       "        0.82515181, 0.92199641, 0.58765664, 0.4839693 , 0.60261107,\n",
       "        0.53482122, 0.68574861, 0.81634057, 0.89138006, 0.17717272,\n",
       "        0.218604  , 0.79092606, 0.72908136],\n",
       "       [0.77194676, 0.88805799, 0.42691516, 0.19748672, 0.35179263,\n",
       "        0.10082017, 0.26072515, 0.88351799, 0.5687885 , 0.01646119,\n",
       "        0.03918142, 0.72154274, 0.30731538, 0.29882453, 0.47443367,\n",
       "        0.97126344, 0.65592595, 0.2836071 , 0.33811741, 0.39882374,\n",
       "        0.60681923, 0.52300677, 0.62042865, 0.89649438, 0.21630955,\n",
       "        0.69521675, 0.85654115, 0.62596232],\n",
       "       [0.41746094, 0.89262264, 0.1909561 , 0.15490059, 0.98158419,\n",
       "        0.17085495, 0.30438386, 0.27832358, 0.44590937, 0.15786179,\n",
       "        0.33711297, 0.44306309, 0.01361705, 0.42637664, 0.96421016,\n",
       "        0.08260629, 0.72033187, 0.96276062, 0.61751806, 0.35458552,\n",
       "        0.5136305 , 0.04134018, 0.87254043, 0.41113703, 0.22309327,\n",
       "        0.42105273, 0.43421536, 0.42025775],\n",
       "       [0.0697248 , 0.72668847, 0.29662977, 0.3907402 , 0.4285938 ,\n",
       "        0.94853133, 0.19865097, 0.51034184, 0.95022723, 0.67798219,\n",
       "        0.16345851, 0.28388577, 0.00859129, 0.44040472, 0.34451992,\n",
       "        0.38790417, 0.72596288, 0.55598681, 0.78364951, 0.33508821,\n",
       "        0.37796187, 0.83334283, 0.5737522 , 0.60550296, 0.62513097,\n",
       "        0.4101485 , 0.77694702, 0.28718645],\n",
       "       [0.9005562 , 0.21504199, 0.61170155, 0.2110293 , 0.08093767,\n",
       "        0.56095812, 0.56784276, 0.97388205, 0.81979443, 0.19286904,\n",
       "        0.49106323, 0.55280223, 0.85349229, 0.51141287, 0.93674891,\n",
       "        0.54723153, 0.86423532, 0.88623411, 0.02704668, 0.19516932,\n",
       "        0.54934055, 0.02850672, 0.93229568, 0.92771225, 0.7271908 ,\n",
       "        0.66126839, 0.675455  , 0.22625048],\n",
       "       [0.98144173, 0.30521394, 0.71282891, 0.90708281, 0.96357596,\n",
       "        0.60522388, 0.22929273, 0.91615524, 0.04785266, 0.01930249,\n",
       "        0.34805498, 0.72931964, 0.30759411, 0.73091196, 0.82021395,\n",
       "        0.43413559, 0.71113437, 0.79003353, 0.63995669, 0.53587327,\n",
       "        0.59744125, 0.80133431, 0.77494259, 0.93513523, 0.93590342,\n",
       "        0.06235542, 0.79126577, 0.72176637],\n",
       "       [0.78670266, 0.88089514, 0.32165665, 0.27331401, 0.67909804,\n",
       "        0.43679953, 0.48460313, 0.66148851, 0.39329967, 0.72992759,\n",
       "        0.13867734, 0.30507673, 0.07807297, 0.97364646, 0.61815193,\n",
       "        0.16414834, 0.26913658, 0.22034912, 0.07068687, 0.82498499,\n",
       "        0.12989005, 0.86229483, 0.42989552, 0.29787567, 0.12367215,\n",
       "        0.36932408, 0.50228347, 0.47215557],\n",
       "       [0.83885327, 0.86303228, 0.64769883, 0.22370511, 0.02643655,\n",
       "        0.09828108, 0.77798875, 0.89220506, 0.46654511, 0.54912579,\n",
       "        0.234936  , 0.44681523, 0.70603758, 0.50998027, 0.31044745,\n",
       "        0.79646802, 0.59805231, 0.57347344, 0.86223509, 0.35661454,\n",
       "        0.80091961, 0.24355701, 0.68960059, 0.39062279, 0.11752541,\n",
       "        0.54699256, 0.04496246, 0.85719406],\n",
       "       [0.71324728, 0.01603884, 0.19740634, 0.13288434, 0.47674155,\n",
       "        0.92383564, 0.67895934, 0.35294285, 0.80266825, 0.32896603,\n",
       "        0.17536967, 0.53667949, 0.00428681, 0.84940458, 0.39547763,\n",
       "        0.91847081, 0.25091723, 0.40617146, 0.9731572 , 0.06482629,\n",
       "        0.41444548, 0.8034828 , 0.80714365, 0.01965783, 0.40527966,\n",
       "        0.61873017, 0.54085516, 0.51351915],\n",
       "       [0.06256902, 0.05294655, 0.42199783, 0.81255697, 0.15399616,\n",
       "        0.68331539, 0.22945475, 0.21515559, 0.37678148, 0.98074045,\n",
       "        0.20421296, 0.42059257, 0.69948762, 0.92785928, 0.25109074,\n",
       "        0.44932227, 0.45029439, 0.8079755 , 0.75710029, 0.07429286,\n",
       "        0.28168007, 0.15595226, 0.57931632, 0.56825175, 0.85555704,\n",
       "        0.82893057, 0.1076021 , 0.65548255]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0] # or x[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.2 im2col로 데이터 전개하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[노션 참고]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.3 합성곱 계층 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "im2col(input_data, filter_h, filter_w, stride=1, pad=0)\n",
    "\n",
    "- input_data - (**데이터 수, 채널 수, 높이, 너비**)의 4차원 배열로 이뤄진 입력 데이터\n",
    "- filter_h - 필터의 높이\n",
    "- filter_w - 필터의 너비\n",
    "- stride - 스트라이드\n",
    "- pad - 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 75)\n",
      "(90, 75)\n"
     ]
    }
   ],
   "source": [
    "from common.util import im2col\n",
    "\n",
    "x1 = np.random.rand(1, 3, 7, 7)\n",
    "col1 = im2col(x1, 5, 5, stride=1, pad=0)\n",
    "print(col1.shape)\n",
    "\n",
    "x2 = np.random.rand(10, 3, 7, 7) # 데이터 10개\n",
    "col2 = im2col(x2, 5, 5, stride=1, pad=0)\n",
    "print(col2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape # FN: 핕터 개수, C: 채널, FH: 필터 높이, FW: 필터 너비\n",
    "        N, C, H, W = x.shape\n",
    "        \n",
    "        # 출력 형상 계산\n",
    "        out_h = int(1 + (H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)\n",
    "        \n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T # 필터 전개\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        \n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.4 풀링 계층 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "        \n",
    "        # 전개 (1) : 입력데이터를 전개한다.\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "        \n",
    "        # 최댓값 (2) : 행별 최댓값을 구한다.\n",
    "        out = np.max(col, axis=1)\n",
    "        \n",
    "        # 성형 (3) : 적절한 모양으로 성형한다.\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 CNN 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**단순한 합성곱 신경망**\n",
    "    \n",
    "conv - relu - pool - affine - relu - affine - softmax\n",
    "\n",
    "[init]\n",
    "**Parameters**\n",
    "- input_size : 입력 크기（MNIST의 경우엔 784）\n",
    "- hidden_size_list : 각 은닉층의 뉴런 수를 담은 리스트（e.g. [100, 100, 100]）\n",
    "- output_size : 출력 크기（MNIST의 경우엔 10）\n",
    "- activation : 활성화 함수 - 'relu' 혹은 'sigmoid'\n",
    "- weight_init_std : 가중치의 표준편차 지정（e.g. 0.01）\n",
    "    - 'relu'나 'he'로 지정하면 'He 초깃값'으로 설정\n",
    "    - 'sigmoid'나 'xavier'로 지정하면 'Xavier 초깃값'으로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class SimpleConvNet:\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"손실 함수를 구한다.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다（수치미분）.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다(오차역전파법).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.300384378390718\n",
      "=== epoch:1, train acc:0.279, test acc:0.268 ===\n",
      "train loss:2.2981569220574327\n",
      "train loss:2.2947045369437102\n",
      "train loss:2.2910512290733136\n",
      "train loss:2.2802067896688865\n",
      "train loss:2.2741041577114927\n",
      "train loss:2.263083235274093\n",
      "train loss:2.240997464071731\n",
      "train loss:2.2370411280682183\n",
      "train loss:2.200789364733324\n",
      "train loss:2.16440539261889\n",
      "train loss:2.165528231259315\n",
      "train loss:2.132791010940525\n",
      "train loss:2.0704085482996537\n",
      "train loss:2.0514846644169626\n",
      "train loss:1.971784073652665\n",
      "train loss:1.9827041240457868\n",
      "train loss:1.8605229972806248\n",
      "train loss:1.8106963472344941\n",
      "train loss:1.7272987754384141\n",
      "train loss:1.6695378235419227\n",
      "train loss:1.63661392102161\n",
      "train loss:1.4802954719604542\n",
      "train loss:1.4693315447768875\n",
      "train loss:1.373363191062001\n",
      "train loss:1.2736400128624807\n",
      "train loss:1.2951242080979197\n",
      "train loss:1.1613207366427751\n",
      "train loss:1.162942773715384\n",
      "train loss:1.0150141356960531\n",
      "train loss:0.8400467687414743\n",
      "train loss:0.8560302783603342\n",
      "train loss:0.8221208103949649\n",
      "train loss:0.8125755785173514\n",
      "train loss:0.7262967595976428\n",
      "train loss:0.7423919883281527\n",
      "train loss:0.7518050086255166\n",
      "train loss:0.7637792964955783\n",
      "train loss:0.6219678748411352\n",
      "train loss:0.6938345534362717\n",
      "train loss:0.7693620204538216\n",
      "train loss:0.6172820818560483\n",
      "train loss:0.7104645003053944\n",
      "train loss:0.5354345676098111\n",
      "train loss:0.5369082245430599\n",
      "train loss:0.5213256248625022\n",
      "train loss:0.3873459771125802\n",
      "train loss:0.6062207808376976\n",
      "train loss:0.560755235119997\n",
      "train loss:0.5506265434419412\n",
      "train loss:0.6546375527486552\n",
      "train loss:0.6356385772618637\n",
      "train loss:0.44705984895516016\n",
      "train loss:0.5897876975058974\n",
      "train loss:0.4740490056800042\n",
      "train loss:0.4918604512822873\n",
      "train loss:0.5945888319034547\n",
      "train loss:0.6725074110494613\n",
      "train loss:0.5642281013499402\n",
      "train loss:0.5454659073302992\n",
      "train loss:0.48091206228750955\n",
      "train loss:0.508842094705082\n",
      "train loss:0.4771470268335817\n",
      "train loss:0.3237310328466978\n",
      "train loss:0.49939444645807596\n",
      "train loss:0.46875771341435085\n",
      "train loss:0.5923819003053794\n",
      "train loss:0.5446116791248088\n",
      "train loss:0.5418951319236627\n",
      "train loss:0.7302177385887292\n",
      "train loss:0.5356788581710075\n",
      "train loss:0.31165941525355306\n",
      "train loss:0.41112801559748385\n",
      "train loss:0.45798942984584806\n",
      "train loss:0.3887073525354592\n",
      "train loss:0.486294786902456\n",
      "train loss:0.4323863686429219\n",
      "train loss:0.43553067900284503\n",
      "train loss:0.4759698774348901\n",
      "train loss:0.37113119881468654\n",
      "train loss:0.33354795692953\n",
      "train loss:0.4294100090675055\n",
      "train loss:0.346945702745534\n",
      "train loss:0.35090287993728864\n",
      "train loss:0.3634068204230767\n",
      "train loss:0.3588437572451024\n",
      "train loss:0.3664124636338731\n",
      "train loss:0.2932236620526876\n",
      "train loss:0.43118127236360626\n",
      "train loss:0.260150574291176\n",
      "train loss:0.46796292080961194\n",
      "train loss:0.5353296903815977\n",
      "train loss:0.4021464838557045\n",
      "train loss:0.4001357717160874\n",
      "train loss:0.5275524745637905\n",
      "train loss:0.40536786903892563\n",
      "train loss:0.3394958879359485\n",
      "train loss:0.43558907439454586\n",
      "train loss:0.2147212538589299\n",
      "train loss:0.27298663631612624\n",
      "train loss:0.3826818036443077\n",
      "train loss:0.49535171406775036\n",
      "train loss:0.2865231560084751\n",
      "train loss:0.23240649161183297\n",
      "train loss:0.3335771516410895\n",
      "train loss:0.5002523883581129\n",
      "train loss:0.31578079333540204\n",
      "train loss:0.27233022480012203\n",
      "train loss:0.28464346270905483\n",
      "train loss:0.42092777112485696\n",
      "train loss:0.432909091388453\n",
      "train loss:0.3775081428689132\n",
      "train loss:0.28912467062395025\n",
      "train loss:0.23698224974720725\n",
      "train loss:0.24347047870859323\n",
      "train loss:0.3752947536866006\n",
      "train loss:0.2598228189487433\n",
      "train loss:0.39717985910512466\n",
      "train loss:0.22822565958554575\n",
      "train loss:0.37119636495991015\n",
      "train loss:0.4590308555530016\n",
      "train loss:0.1700716814903753\n",
      "train loss:0.22897902818050245\n",
      "train loss:0.467994581091166\n",
      "train loss:0.21260682038712736\n",
      "train loss:0.383168613832079\n",
      "train loss:0.5081468800153474\n",
      "train loss:0.38423145796456754\n",
      "train loss:0.3020047457209572\n",
      "train loss:0.39202120408460045\n",
      "train loss:0.28186943861320707\n",
      "train loss:0.52527470635378\n",
      "train loss:0.3776044648434988\n",
      "train loss:0.342578651637959\n",
      "train loss:0.18737915675127895\n",
      "train loss:0.300355491387554\n",
      "train loss:0.29088731175248883\n",
      "train loss:0.29235291751000037\n",
      "train loss:0.3414138483028772\n",
      "train loss:0.39087488573366225\n",
      "train loss:0.29511587366810454\n",
      "train loss:0.32898233299066193\n",
      "train loss:0.474987889399017\n",
      "train loss:0.21863945407611154\n",
      "train loss:0.48140719634101553\n",
      "train loss:0.24690471078105847\n",
      "train loss:0.4100920911248803\n",
      "train loss:0.2400703483034048\n",
      "train loss:0.38789917206783564\n",
      "train loss:0.27121057606803184\n",
      "train loss:0.33603773551896327\n",
      "train loss:0.4527080100513733\n",
      "train loss:0.3426394262420217\n",
      "train loss:0.32802735824354623\n",
      "train loss:0.3150877059299945\n",
      "train loss:0.42277717287222993\n",
      "train loss:0.3712564270821232\n",
      "train loss:0.25137816674091007\n",
      "train loss:0.4486226085437747\n",
      "train loss:0.2959960338498246\n",
      "train loss:0.3779743765505003\n",
      "train loss:0.20015280560862395\n",
      "train loss:0.4347936434746345\n",
      "train loss:0.18723525692544052\n",
      "train loss:0.2522265183059431\n",
      "train loss:0.3796089101354543\n",
      "train loss:0.27867041977923657\n",
      "train loss:0.40974563617449994\n",
      "train loss:0.23890556116903738\n",
      "train loss:0.3099804437624337\n",
      "train loss:0.13855376901481545\n",
      "train loss:0.2968470344102922\n",
      "train loss:0.2193156875603413\n",
      "train loss:0.2639275574298891\n",
      "train loss:0.3052597804410928\n",
      "train loss:0.18599049313721686\n",
      "train loss:0.29759097092750436\n",
      "train loss:0.20779438312137008\n",
      "train loss:0.32465304521576877\n",
      "train loss:0.228583460581224\n",
      "train loss:0.28432470605830207\n",
      "train loss:0.25635665711264616\n",
      "train loss:0.20287456036336\n",
      "train loss:0.3304271152520436\n",
      "train loss:0.18238528954318844\n",
      "train loss:0.37765814025665784\n",
      "train loss:0.24133117689936273\n",
      "train loss:0.2209886669383305\n",
      "train loss:0.19806190180530883\n",
      "train loss:0.19232660021630277\n",
      "train loss:0.2995689994316\n",
      "train loss:0.13323417365553353\n",
      "train loss:0.3994237673609231\n",
      "train loss:0.38755775775753626\n",
      "train loss:0.278276340720772\n",
      "train loss:0.1697372284293961\n",
      "train loss:0.3605097435863058\n",
      "train loss:0.21957104634878227\n",
      "train loss:0.5365670853621718\n",
      "train loss:0.3565025362007283\n",
      "train loss:0.2789861170261825\n",
      "train loss:0.3046115887797534\n",
      "train loss:0.2187234165757692\n",
      "train loss:0.23282161798805237\n",
      "train loss:0.18663241085735838\n",
      "train loss:0.14858074736970278\n",
      "train loss:0.38141126718560153\n",
      "train loss:0.18984151944171526\n",
      "train loss:0.39574185855411087\n",
      "train loss:0.2440184777802659\n",
      "train loss:0.35313077782673313\n",
      "train loss:0.31243041185576603\n",
      "train loss:0.23007405470494835\n",
      "train loss:0.14682101340211237\n",
      "train loss:0.27777785526128695\n",
      "train loss:0.27388981265282547\n",
      "train loss:0.17476629984282957\n",
      "train loss:0.1621914291765447\n",
      "train loss:0.31033670536485775\n",
      "train loss:0.3387892213132587\n",
      "train loss:0.2913250695919245\n",
      "train loss:0.2587788644499577\n",
      "train loss:0.19588070985124328\n",
      "train loss:0.3657950499878941\n",
      "train loss:0.15917848840291435\n",
      "train loss:0.36591616598461907\n",
      "train loss:0.3657828058556454\n",
      "train loss:0.28806299444290606\n",
      "train loss:0.19416633648231835\n",
      "train loss:0.21111815421658706\n",
      "train loss:0.23323273555486998\n",
      "train loss:0.1873079341137748\n",
      "train loss:0.18775562214515368\n",
      "train loss:0.16081828751732147\n",
      "train loss:0.16507987763633256\n",
      "train loss:0.2327607269659333\n",
      "train loss:0.24336119282851315\n",
      "train loss:0.3462858559424158\n",
      "train loss:0.14745513910381228\n",
      "train loss:0.2574183719283906\n",
      "train loss:0.23028015683712572\n",
      "train loss:0.36486104691902\n",
      "train loss:0.2948113456809764\n",
      "train loss:0.13210235873108594\n",
      "train loss:0.1773564267798317\n",
      "train loss:0.2204195471534302\n",
      "train loss:0.2528026520987528\n",
      "train loss:0.2569896575367586\n",
      "train loss:0.20021934449515136\n",
      "train loss:0.3005997290924139\n",
      "train loss:0.14291763169775284\n",
      "train loss:0.21696484435051505\n",
      "train loss:0.319835615430488\n",
      "train loss:0.29576538988560264\n",
      "train loss:0.377473103567332\n",
      "train loss:0.14994566079659002\n",
      "train loss:0.2204027451983794\n",
      "train loss:0.18440363310390284\n",
      "train loss:0.23908921864204655\n",
      "train loss:0.19820879371451952\n",
      "train loss:0.21231966466142096\n",
      "train loss:0.1244745271915275\n",
      "train loss:0.10113555874131139\n",
      "train loss:0.39357005658671007\n",
      "train loss:0.2422706688273716\n",
      "train loss:0.2851540729756124\n",
      "train loss:0.17393843369761627\n",
      "train loss:0.1963053127027065\n",
      "train loss:0.19993829602935229\n",
      "train loss:0.1600193859072872\n",
      "train loss:0.1284225260685012\n",
      "train loss:0.15977155412969835\n",
      "train loss:0.1961695474932743\n",
      "train loss:0.2852907023360961\n",
      "train loss:0.27442470056753787\n",
      "train loss:0.2564688799289006\n",
      "train loss:0.2032398217612997\n",
      "train loss:0.29711272489836893\n",
      "train loss:0.14111679305332905\n",
      "train loss:0.1605310695049629\n",
      "train loss:0.2615198814286611\n",
      "train loss:0.161370982587886\n",
      "train loss:0.2661770765257815\n",
      "train loss:0.15809766671227798\n",
      "train loss:0.11727807634292564\n",
      "train loss:0.17099721070199586\n",
      "train loss:0.1566136399241498\n",
      "train loss:0.23429606382385337\n",
      "train loss:0.32124334615175215\n",
      "train loss:0.12976589546221418\n",
      "train loss:0.23304745179938408\n",
      "train loss:0.27413039146716395\n",
      "train loss:0.22377048167381924\n",
      "train loss:0.17974257012360778\n",
      "train loss:0.12814229723996232\n",
      "train loss:0.1254303073006737\n",
      "train loss:0.1769223940548744\n",
      "train loss:0.22597963117771122\n",
      "train loss:0.24110122670095901\n",
      "train loss:0.13686126440300206\n",
      "train loss:0.15339280699142654\n",
      "train loss:0.24166504132096933\n",
      "train loss:0.316451002170882\n",
      "train loss:0.18337503469043662\n",
      "train loss:0.17106972911081328\n",
      "train loss:0.1349017373135822\n",
      "train loss:0.23616590194662698\n",
      "train loss:0.14464127252201572\n",
      "train loss:0.2712569917757396\n",
      "train loss:0.08481203071209055\n",
      "train loss:0.14613539799182748\n",
      "train loss:0.1293238634485129\n",
      "train loss:0.14487277890659717\n",
      "train loss:0.22155185481425532\n",
      "train loss:0.15889879694803677\n",
      "train loss:0.15473261584046746\n",
      "train loss:0.12478036758711773\n",
      "train loss:0.1667411762766129\n",
      "train loss:0.22491616599088085\n",
      "train loss:0.21937969199499124\n",
      "train loss:0.1332945225383885\n",
      "train loss:0.13530886870980793\n",
      "train loss:0.14505010839111576\n",
      "train loss:0.14881257291021946\n",
      "train loss:0.11389787589034266\n",
      "train loss:0.12919519472357727\n",
      "train loss:0.25323467752344686\n",
      "train loss:0.15494332363656996\n",
      "train loss:0.30705047363501714\n",
      "train loss:0.21547123849932956\n",
      "train loss:0.12005813436592928\n",
      "train loss:0.17201534234420232\n",
      "train loss:0.2465096956691954\n",
      "train loss:0.12845943545131727\n",
      "train loss:0.2023225176842154\n",
      "train loss:0.13485864530438632\n",
      "train loss:0.15935022860711878\n",
      "train loss:0.18174137294730908\n",
      "train loss:0.1862198672732007\n",
      "train loss:0.17733432198684504\n",
      "train loss:0.1671535934448336\n",
      "train loss:0.13191008955961966\n",
      "train loss:0.109162078576929\n",
      "train loss:0.20149780277734156\n",
      "train loss:0.27248525005714597\n",
      "train loss:0.20114078095885302\n",
      "train loss:0.19257530556122193\n",
      "train loss:0.29617073796875665\n",
      "train loss:0.18473120210438496\n",
      "train loss:0.11364636200498851\n",
      "train loss:0.0886018538760547\n",
      "train loss:0.11654142205722649\n",
      "train loss:0.059690723098537866\n",
      "train loss:0.19158315332868514\n",
      "train loss:0.12878933481495097\n",
      "train loss:0.07848558915157876\n",
      "train loss:0.15814159726362678\n",
      "train loss:0.06870840228312226\n",
      "train loss:0.159731896171728\n",
      "train loss:0.09703766579946597\n",
      "train loss:0.2295395819760278\n",
      "train loss:0.1530812279885143\n",
      "train loss:0.13487580176147085\n",
      "train loss:0.131734012771415\n",
      "train loss:0.1680564258925273\n",
      "train loss:0.10809223277720442\n",
      "train loss:0.18145012642549307\n",
      "train loss:0.19250580298833583\n",
      "train loss:0.1736011402470432\n",
      "train loss:0.1954834120478008\n",
      "train loss:0.16271056784924423\n",
      "train loss:0.17808564187896236\n",
      "train loss:0.25948572317951046\n",
      "train loss:0.16850873072307246\n",
      "train loss:0.10636022744740234\n",
      "train loss:0.38536405986666117\n",
      "train loss:0.22792760202826842\n",
      "train loss:0.07029360164192511\n",
      "train loss:0.17643714542640548\n",
      "train loss:0.18161612595312704\n",
      "train loss:0.10295108071717247\n",
      "train loss:0.11673566318181836\n",
      "train loss:0.14202631526534154\n",
      "train loss:0.20417873333351277\n",
      "train loss:0.21740028033298675\n",
      "train loss:0.1057487216234128\n",
      "train loss:0.1936017862214193\n",
      "train loss:0.13831861744503868\n",
      "train loss:0.20343035386090338\n",
      "train loss:0.15047551087452093\n",
      "train loss:0.140816787662475\n",
      "train loss:0.11316210074144316\n",
      "train loss:0.1367518933649976\n",
      "train loss:0.2110986992822735\n",
      "train loss:0.11791867294503833\n",
      "train loss:0.11362713985654613\n",
      "train loss:0.23638437387206834\n",
      "train loss:0.20698780285775858\n",
      "train loss:0.19889544020276811\n",
      "train loss:0.16675767129269503\n",
      "train loss:0.0779519404242508\n",
      "train loss:0.13529394226265026\n",
      "train loss:0.09915079674556748\n",
      "train loss:0.13443361251125052\n",
      "train loss:0.14543390397000383\n",
      "train loss:0.13861147435750779\n",
      "train loss:0.23140278839323458\n",
      "train loss:0.1362721388737054\n",
      "train loss:0.14045657910915277\n",
      "train loss:0.26298297275024807\n",
      "train loss:0.14302617348767138\n",
      "train loss:0.1762689672036839\n",
      "train loss:0.13943091974567376\n",
      "train loss:0.11070116837204777\n",
      "train loss:0.1693889616119682\n",
      "train loss:0.18495000749771542\n",
      "train loss:0.10586054561542531\n",
      "train loss:0.13149980722598165\n",
      "train loss:0.1336686106876759\n",
      "train loss:0.06233822812128647\n",
      "train loss:0.05121462076497678\n",
      "train loss:0.1738239979546507\n",
      "train loss:0.12374241881669146\n",
      "train loss:0.2797673709038642\n",
      "train loss:0.31667273345231295\n",
      "train loss:0.07397629565867504\n",
      "train loss:0.09249309255991761\n",
      "train loss:0.21325119268684578\n",
      "train loss:0.11349624041160469\n",
      "train loss:0.19626832809236996\n",
      "train loss:0.14276346790659677\n",
      "train loss:0.15971433142900168\n",
      "train loss:0.15195280003523323\n",
      "train loss:0.23074663794228645\n",
      "train loss:0.12203643338078547\n",
      "train loss:0.09474535993798319\n",
      "train loss:0.12550681113624734\n",
      "train loss:0.123778628926849\n",
      "train loss:0.24407908392633118\n",
      "train loss:0.14152150736053473\n",
      "train loss:0.1734083445220581\n",
      "train loss:0.14980031862756854\n",
      "train loss:0.1453734264058485\n",
      "train loss:0.13890597082509615\n",
      "train loss:0.0730691665029323\n",
      "train loss:0.14499680662202075\n",
      "train loss:0.132667235615358\n",
      "train loss:0.10849906480407048\n",
      "train loss:0.11443162983808358\n",
      "train loss:0.12407531941486241\n",
      "train loss:0.11343247819643525\n",
      "train loss:0.20480064031111778\n",
      "train loss:0.1525845407717126\n",
      "train loss:0.06544406267513543\n",
      "train loss:0.1206835213516973\n",
      "train loss:0.24236226930561355\n",
      "train loss:0.22382676306007038\n",
      "train loss:0.18468437903412263\n",
      "train loss:0.14831537081127322\n",
      "train loss:0.06708068872086011\n",
      "train loss:0.07766471270852293\n",
      "train loss:0.11498857335817535\n",
      "train loss:0.05024872619975437\n",
      "train loss:0.14876228856375562\n",
      "train loss:0.11554894649538185\n",
      "train loss:0.10073169622074157\n",
      "train loss:0.1535487534385898\n",
      "train loss:0.10635140237433116\n",
      "train loss:0.09816808960807717\n",
      "train loss:0.128200206496369\n",
      "train loss:0.08951186384481813\n",
      "train loss:0.17626941616967184\n",
      "train loss:0.09032154497084206\n",
      "train loss:0.18013330368525415\n",
      "train loss:0.10299477254646293\n",
      "train loss:0.07912432070266158\n",
      "train loss:0.18679567911033326\n",
      "train loss:0.1717954111484527\n",
      "train loss:0.13786751071219494\n",
      "train loss:0.13488116847965056\n",
      "train loss:0.04607085931020902\n",
      "train loss:0.08359521139985406\n",
      "train loss:0.12251612364411311\n",
      "train loss:0.122609955797509\n",
      "train loss:0.05207801277779152\n",
      "train loss:0.13498853897389387\n",
      "train loss:0.09684976793061707\n",
      "train loss:0.2314045409305198\n",
      "train loss:0.12467827901502229\n",
      "train loss:0.10531894128712888\n",
      "train loss:0.10019155422257033\n",
      "train loss:0.06902880873110537\n",
      "train loss:0.06717213934408439\n",
      "train loss:0.057897689318420535\n",
      "train loss:0.10722575215490839\n",
      "train loss:0.13821298137665802\n",
      "train loss:0.09296731197753878\n",
      "train loss:0.09617294621565423\n",
      "train loss:0.07784121353007262\n",
      "train loss:0.1258603857482807\n",
      "train loss:0.15419456302375953\n",
      "train loss:0.11990749806180252\n",
      "train loss:0.05506600823433433\n",
      "train loss:0.191912965597832\n",
      "train loss:0.09310592653547729\n",
      "train loss:0.13075410140403856\n",
      "train loss:0.07079206896151806\n",
      "train loss:0.10691335031726384\n",
      "train loss:0.16746345962470194\n",
      "train loss:0.08324863817040905\n",
      "train loss:0.09851453695695808\n",
      "train loss:0.27880678495177363\n",
      "train loss:0.2001670258573576\n",
      "train loss:0.04129351432066311\n",
      "train loss:0.08931906367773156\n",
      "train loss:0.14404006117575727\n",
      "train loss:0.19000890595526262\n",
      "train loss:0.0441670243960261\n",
      "train loss:0.11640831355864398\n",
      "train loss:0.20476344678146238\n",
      "train loss:0.13713758842502502\n",
      "train loss:0.13556272004113723\n",
      "train loss:0.13622508768470284\n",
      "train loss:0.16892226965945217\n",
      "train loss:0.073714275707197\n",
      "train loss:0.0632591328012376\n",
      "train loss:0.0694633004140428\n",
      "train loss:0.2398912157206884\n",
      "train loss:0.16021994886897076\n",
      "train loss:0.15654156882398176\n",
      "train loss:0.07743350632035469\n",
      "train loss:0.11318697307423659\n",
      "train loss:0.08836201856552421\n",
      "train loss:0.180465763929358\n",
      "train loss:0.20730764619466988\n",
      "train loss:0.12078780069407108\n",
      "train loss:0.07157088641865168\n",
      "train loss:0.10516928751534468\n",
      "train loss:0.11629124642140036\n",
      "train loss:0.06790323265555728\n",
      "train loss:0.23596261051873835\n",
      "train loss:0.08626940405582186\n",
      "train loss:0.0843773948858942\n",
      "train loss:0.1035388580436226\n",
      "train loss:0.07464576933447083\n",
      "train loss:0.14070364702081914\n",
      "train loss:0.06590033182052793\n",
      "train loss:0.15139100159561664\n",
      "train loss:0.04748337511566272\n",
      "train loss:0.1979747080680572\n",
      "train loss:0.20363655910958783\n",
      "train loss:0.07438900895341678\n",
      "train loss:0.10854171408642316\n",
      "train loss:0.07524068157951026\n",
      "train loss:0.15542927031185555\n",
      "train loss:0.07014451782275918\n",
      "train loss:0.28569571245160164\n",
      "train loss:0.10648787573423896\n",
      "train loss:0.06939859986943485\n",
      "train loss:0.20363510720681752\n",
      "train loss:0.030749446710636733\n",
      "train loss:0.1607864816293219\n",
      "train loss:0.1359511426970463\n",
      "train loss:0.116266279081118\n",
      "train loss:0.19539875656329392\n",
      "train loss:0.2101903318104134\n",
      "train loss:0.10578501155854583\n",
      "train loss:0.07733245534593132\n",
      "train loss:0.12452676671303703\n",
      "train loss:0.11464750458133027\n",
      "train loss:0.22481192302833525\n",
      "train loss:0.1404860611955836\n",
      "train loss:0.07662362236166798\n",
      "train loss:0.08361600783637987\n",
      "train loss:0.07345194964674322\n",
      "train loss:0.049585178945731306\n",
      "train loss:0.16927500373658738\n",
      "train loss:0.14726776166989586\n",
      "train loss:0.1437262748496411\n",
      "train loss:0.11618061468325686\n",
      "train loss:0.13990663937623193\n",
      "train loss:0.210912683663055\n",
      "train loss:0.12298536886194884\n",
      "train loss:0.05117282263995268\n",
      "train loss:0.1232020410034555\n",
      "train loss:0.15870528943446593\n",
      "train loss:0.04835521753609398\n",
      "train loss:0.1243693101109606\n",
      "train loss:0.25021391925339426\n",
      "train loss:0.038503709069775426\n",
      "train loss:0.15983210526701921\n",
      "train loss:0.16174053401666627\n",
      "train loss:0.054799566235644324\n",
      "train loss:0.08557935029379728\n",
      "train loss:0.06111638960305167\n",
      "train loss:0.11108803732531554\n",
      "train loss:0.03747542508612062\n",
      "train loss:0.08133214696886315\n",
      "train loss:0.169776524103603\n",
      "train loss:0.16056625956774845\n",
      "train loss:0.11743978135499855\n",
      "=== epoch:2, train acc:0.955, test acc:0.965 ===\n",
      "train loss:0.08104114979137664\n",
      "train loss:0.07356571001640376\n",
      "train loss:0.1618310719366669\n",
      "train loss:0.0785719527299032\n",
      "train loss:0.09512855353898508\n",
      "train loss:0.05144898368518329\n",
      "train loss:0.1169501953156043\n",
      "train loss:0.05842378631279313\n",
      "train loss:0.06829488936144135\n",
      "train loss:0.1610788427631754\n",
      "train loss:0.05257596531902669\n",
      "train loss:0.19866144536948846\n",
      "train loss:0.11780023696447724\n",
      "train loss:0.12616700769658906\n",
      "train loss:0.07632640429875212\n",
      "train loss:0.049575980878500625\n",
      "train loss:0.06536903187189412\n",
      "train loss:0.06134776910842711\n",
      "train loss:0.1149576949855338\n",
      "train loss:0.07832675214165268\n",
      "train loss:0.15749022084362557\n",
      "train loss:0.12639565378460457\n",
      "train loss:0.212433573998812\n",
      "train loss:0.07629519681212908\n",
      "train loss:0.1235172839438378\n",
      "train loss:0.18971712064916574\n",
      "train loss:0.1715150926437758\n",
      "train loss:0.04158230720120568\n",
      "train loss:0.10022364835548413\n",
      "train loss:0.052263446471079236\n",
      "train loss:0.062208734758821035\n",
      "train loss:0.05619585874883985\n",
      "train loss:0.05808252142894015\n",
      "train loss:0.04634538024162538\n",
      "train loss:0.06899476993992178\n",
      "train loss:0.10760992810910366\n",
      "train loss:0.25985456229854104\n",
      "train loss:0.10879796834093401\n",
      "train loss:0.1625367820627295\n",
      "train loss:0.051866159016246444\n",
      "train loss:0.03995200501281916\n",
      "train loss:0.053137220834740505\n",
      "train loss:0.11098273489830619\n",
      "train loss:0.13168024446104845\n",
      "train loss:0.1416199778920131\n",
      "train loss:0.12202687920728873\n",
      "train loss:0.04781443111942557\n",
      "train loss:0.12066838398744262\n",
      "train loss:0.06044733148403416\n",
      "train loss:0.16871891053959184\n",
      "train loss:0.1792291900740054\n",
      "train loss:0.1923055069329517\n",
      "train loss:0.11562142317928915\n",
      "train loss:0.07169815971318462\n",
      "train loss:0.09731421822732259\n",
      "train loss:0.11368387502307323\n",
      "train loss:0.08110776211992597\n",
      "train loss:0.13543681237015687\n",
      "train loss:0.09687839015557334\n",
      "train loss:0.0696481858515521\n",
      "train loss:0.08188838381603784\n",
      "train loss:0.17555195795990863\n",
      "train loss:0.0563220376996897\n",
      "train loss:0.14586904475933893\n",
      "train loss:0.13202966669256727\n",
      "train loss:0.1175864357814485\n",
      "train loss:0.04479951907454595\n",
      "train loss:0.1247932763886885\n",
      "train loss:0.06527756958729468\n",
      "train loss:0.07792658566670459\n",
      "train loss:0.10767800297198943\n",
      "train loss:0.1264093825960724\n",
      "train loss:0.18497791105829314\n",
      "train loss:0.07575913082235443\n",
      "train loss:0.08878082631300094\n",
      "train loss:0.09073053164001062\n",
      "train loss:0.07355442855622575\n",
      "train loss:0.02520266165382315\n",
      "train loss:0.06972224283451572\n",
      "train loss:0.11480090819149108\n",
      "train loss:0.050936733570184696\n",
      "train loss:0.06422165689170022\n",
      "train loss:0.07015123799162676\n",
      "train loss:0.14172295589799266\n",
      "train loss:0.1059712199083123\n",
      "train loss:0.10594928377535102\n",
      "train loss:0.038123680227327365\n",
      "train loss:0.04959086050958365\n",
      "train loss:0.1497030548255152\n",
      "train loss:0.08131412488147367\n",
      "train loss:0.038273748807877414\n",
      "train loss:0.12962459644538346\n",
      "train loss:0.1932895231984552\n",
      "train loss:0.08931448453860787\n",
      "train loss:0.02417473041162392\n",
      "train loss:0.10726665810688858\n",
      "train loss:0.06980587555121019\n",
      "train loss:0.09875693027182074\n",
      "train loss:0.18596962740034823\n",
      "train loss:0.11483026194339323\n",
      "train loss:0.05702941786584766\n",
      "train loss:0.20063366202184998\n",
      "train loss:0.22928855481524504\n",
      "train loss:0.04823878480361384\n",
      "train loss:0.055724681058924065\n",
      "train loss:0.039191659286015555\n",
      "train loss:0.1457898303937602\n",
      "train loss:0.039477561703461006\n",
      "train loss:0.0787719798057368\n",
      "train loss:0.038921504491204344\n",
      "train loss:0.08444140857969366\n",
      "train loss:0.10751152573547941\n",
      "train loss:0.09231304234792487\n",
      "train loss:0.1099029762463496\n",
      "train loss:0.1691852892530353\n",
      "train loss:0.11815377498246134\n",
      "train loss:0.17838236033803415\n",
      "train loss:0.08403666247547256\n",
      "train loss:0.05001927380087693\n",
      "train loss:0.058853195314179374\n",
      "train loss:0.09870085311239231\n",
      "train loss:0.08103607016386805\n",
      "train loss:0.1343737958986353\n",
      "train loss:0.08828684103242052\n",
      "train loss:0.04358548613121026\n",
      "train loss:0.09249671884807195\n",
      "train loss:0.12871686061670087\n",
      "train loss:0.04230333525498153\n",
      "train loss:0.04367892158240488\n",
      "train loss:0.14862603670170177\n",
      "train loss:0.13107294677549053\n",
      "train loss:0.14851059248838996\n",
      "train loss:0.06042590426010782\n",
      "train loss:0.08205438800337818\n",
      "train loss:0.055367077411977\n",
      "train loss:0.13505745654530402\n",
      "train loss:0.17683601849841477\n",
      "train loss:0.065465397035852\n",
      "train loss:0.07428586831376394\n",
      "train loss:0.18233353941491903\n",
      "train loss:0.07189047685974502\n",
      "train loss:0.09277501742661183\n",
      "train loss:0.03835037449852884\n",
      "train loss:0.08611880722778861\n",
      "train loss:0.1198268888033954\n",
      "train loss:0.1265395616843446\n",
      "train loss:0.13454907435656818\n",
      "train loss:0.10407058900187181\n",
      "train loss:0.14290995374919738\n",
      "train loss:0.13084029388571744\n",
      "train loss:0.133530901520805\n",
      "train loss:0.05113992937302987\n",
      "train loss:0.05530427323973597\n",
      "train loss:0.025930257006213483\n",
      "train loss:0.09889166372946434\n",
      "train loss:0.06249410326159337\n",
      "train loss:0.11513078583680716\n",
      "train loss:0.12937696597088424\n",
      "train loss:0.08316924486663416\n",
      "train loss:0.06763960611913047\n",
      "train loss:0.06093727017282467\n",
      "train loss:0.06777327159248571\n",
      "train loss:0.13019425004442842\n",
      "train loss:0.09157230092371853\n",
      "train loss:0.21266617703707852\n",
      "train loss:0.06779292231709654\n",
      "train loss:0.0971331317724243\n",
      "train loss:0.07644684076030123\n",
      "train loss:0.0768937842931495\n",
      "train loss:0.03513239769612276\n",
      "train loss:0.1481916378803233\n",
      "train loss:0.046966141359228615\n",
      "train loss:0.036607408932532545\n",
      "train loss:0.03261493967271234\n",
      "train loss:0.10175058991195358\n",
      "train loss:0.10333724162763179\n",
      "train loss:0.06916633388240505\n",
      "train loss:0.10088859295012481\n",
      "train loss:0.11316084504248256\n",
      "train loss:0.05659360734199262\n",
      "train loss:0.06987468447187184\n",
      "train loss:0.06632780784297593\n",
      "train loss:0.07992738524466952\n",
      "train loss:0.04856023227445662\n",
      "train loss:0.0775026748727634\n",
      "train loss:0.1052864590666127\n",
      "train loss:0.21193647970927\n",
      "train loss:0.09530540115582994\n",
      "train loss:0.12360181076654815\n",
      "train loss:0.030319719504207417\n",
      "train loss:0.16194668722934655\n",
      "train loss:0.0431064135559024\n",
      "train loss:0.13691854119104668\n",
      "train loss:0.07060522328574928\n",
      "train loss:0.06724001236738789\n",
      "train loss:0.06525367303767517\n",
      "train loss:0.12841512534582158\n",
      "train loss:0.11336307439653441\n",
      "train loss:0.07096807933190089\n",
      "train loss:0.02961386396940975\n",
      "train loss:0.0760600677383398\n",
      "train loss:0.06566340244253309\n",
      "train loss:0.11739316432116055\n",
      "train loss:0.04410744326336477\n",
      "train loss:0.15708219279808314\n",
      "train loss:0.13182610261174996\n",
      "train loss:0.07806151945181912\n",
      "train loss:0.1198457487120346\n",
      "train loss:0.041161918506881154\n",
      "train loss:0.0499852679513927\n",
      "train loss:0.07100641375554907\n",
      "train loss:0.08808451956876873\n",
      "train loss:0.132490202816344\n",
      "train loss:0.14006011265922155\n",
      "train loss:0.08605203215786732\n",
      "train loss:0.1027755712876678\n",
      "train loss:0.1816340422928321\n",
      "train loss:0.08129142867241884\n",
      "train loss:0.054893430546238575\n",
      "train loss:0.17185209465636542\n",
      "train loss:0.0824809975193397\n",
      "train loss:0.170359530001026\n",
      "train loss:0.13286726171308916\n",
      "train loss:0.03438645164498663\n",
      "train loss:0.06806982296951633\n",
      "train loss:0.027465859342402844\n",
      "train loss:0.12839643925479094\n",
      "train loss:0.13798546730860703\n",
      "train loss:0.09746062491583325\n",
      "train loss:0.05718715511100175\n",
      "train loss:0.14251950166104535\n",
      "train loss:0.031507003368451934\n",
      "train loss:0.10041276517584725\n",
      "train loss:0.20122673114668102\n",
      "train loss:0.0963330450637379\n",
      "train loss:0.11007399425090186\n",
      "train loss:0.06973201322860438\n",
      "train loss:0.11460442595136922\n",
      "train loss:0.1308558732321173\n",
      "train loss:0.07902399789206749\n",
      "train loss:0.044936371613224176\n",
      "train loss:0.032402245804124465\n",
      "train loss:0.056776488711459044\n",
      "train loss:0.03361279659191985\n",
      "train loss:0.07426752883696909\n",
      "train loss:0.03164184561048161\n",
      "train loss:0.07437496678776034\n",
      "train loss:0.052812557147055905\n",
      "train loss:0.055311737673641774\n",
      "train loss:0.06208888091731553\n",
      "train loss:0.035109650556073436\n",
      "train loss:0.07140457453074356\n",
      "train loss:0.09786341798686798\n",
      "train loss:0.034435570359059475\n",
      "train loss:0.038266085233248176\n",
      "train loss:0.024989572209084664\n",
      "train loss:0.11528750767045383\n",
      "train loss:0.052973951108072105\n",
      "train loss:0.10675824307637226\n",
      "train loss:0.04625403599071472\n",
      "train loss:0.10890408513698681\n",
      "train loss:0.036737401750322925\n",
      "train loss:0.11789184729961327\n",
      "train loss:0.10673930414339987\n",
      "train loss:0.08647394247141518\n",
      "train loss:0.044979056784983366\n",
      "train loss:0.042009742150033634\n",
      "train loss:0.07032389497661551\n",
      "train loss:0.051987384590138144\n",
      "train loss:0.09162251907865515\n",
      "train loss:0.09292180009053551\n",
      "train loss:0.025647712119998962\n",
      "train loss:0.050296578888565736\n",
      "train loss:0.1748859175750722\n",
      "train loss:0.11582606928388542\n",
      "train loss:0.17756879928438093\n",
      "train loss:0.06577504653661494\n",
      "train loss:0.024189660207821987\n",
      "train loss:0.10045154105646349\n",
      "train loss:0.038955301174723615\n",
      "train loss:0.04155208635109005\n",
      "train loss:0.15054838235014442\n",
      "train loss:0.02286206855784805\n",
      "train loss:0.08778855735829362\n",
      "train loss:0.10257830834263752\n",
      "train loss:0.031575865765351215\n",
      "train loss:0.18652034642072113\n",
      "train loss:0.09431962139291876\n",
      "train loss:0.027449793943966686\n",
      "train loss:0.03488610681549137\n",
      "train loss:0.06020331353688021\n",
      "train loss:0.04900397859924187\n",
      "train loss:0.043369901256371926\n",
      "train loss:0.05487781858536286\n",
      "train loss:0.06927991564598066\n",
      "train loss:0.08333686749666996\n",
      "train loss:0.08414064657824227\n",
      "train loss:0.02700724459411101\n",
      "train loss:0.07018951423169495\n",
      "train loss:0.03231416264510505\n",
      "train loss:0.10152933406124934\n",
      "train loss:0.051887932900464735\n",
      "train loss:0.07315621031435508\n",
      "train loss:0.11215623057536711\n",
      "train loss:0.107310843020417\n",
      "train loss:0.03633324050157304\n",
      "train loss:0.11314986895642606\n",
      "train loss:0.05247040587206188\n",
      "train loss:0.09167615156371128\n",
      "train loss:0.04481084938712969\n",
      "train loss:0.10881700138225575\n",
      "train loss:0.0451608841634081\n",
      "train loss:0.07305833895508995\n",
      "train loss:0.015963549192928722\n",
      "train loss:0.06102301128435125\n",
      "train loss:0.12007541380348125\n",
      "train loss:0.09056645531584383\n",
      "train loss:0.1374029651707841\n",
      "train loss:0.048962271602074746\n",
      "train loss:0.07215400247229657\n",
      "train loss:0.07549016109041314\n",
      "train loss:0.10519132453580976\n",
      "train loss:0.021795973315599432\n",
      "train loss:0.07860304348468511\n",
      "train loss:0.03697987310933731\n",
      "train loss:0.22536112988058116\n",
      "train loss:0.0956513634702495\n",
      "train loss:0.047394271677483495\n",
      "train loss:0.031181617734751792\n",
      "train loss:0.0801626430773969\n",
      "train loss:0.0376468596315993\n",
      "train loss:0.07976800990232986\n",
      "train loss:0.08787833376382533\n",
      "train loss:0.04217361662610673\n",
      "train loss:0.09852329429732187\n",
      "train loss:0.07507186206915652\n",
      "train loss:0.03812317327748278\n",
      "train loss:0.027150263587246985\n",
      "train loss:0.10652302808038083\n",
      "train loss:0.045587831451010745\n",
      "train loss:0.08574401933365161\n",
      "train loss:0.14924487862399255\n",
      "train loss:0.11207488042194601\n",
      "train loss:0.07134024254379681\n",
      "train loss:0.051585512821958945\n",
      "train loss:0.13879696469585093\n",
      "train loss:0.01832432813271273\n",
      "train loss:0.04290560130334359\n",
      "train loss:0.04597188922797141\n",
      "train loss:0.06461726952977755\n",
      "train loss:0.07540741917414505\n",
      "train loss:0.05841845813917614\n",
      "train loss:0.1032736503656864\n",
      "train loss:0.07115610014393621\n",
      "train loss:0.0765899115249664\n",
      "train loss:0.08994118501170895\n",
      "train loss:0.018778517335187535\n",
      "train loss:0.16922257774755803\n",
      "train loss:0.08103532252777373\n",
      "train loss:0.04312724985745789\n",
      "train loss:0.10842834385184727\n",
      "train loss:0.037812450048780887\n",
      "train loss:0.2486879535981852\n",
      "train loss:0.08847503127656538\n",
      "train loss:0.0784195012641276\n",
      "train loss:0.06711537095809958\n",
      "train loss:0.08532296219997555\n",
      "train loss:0.05688217282773709\n",
      "train loss:0.09471282957749536\n",
      "train loss:0.1448228856766364\n",
      "train loss:0.05744503814223201\n",
      "train loss:0.07429445727433014\n",
      "train loss:0.06455462194652263\n",
      "train loss:0.08438478920671719\n",
      "train loss:0.036838324049541994\n",
      "train loss:0.081758241124719\n",
      "train loss:0.12108520903538775\n",
      "train loss:0.09866776874960598\n",
      "train loss:0.0955819566587261\n",
      "train loss:0.05569902797267762\n",
      "train loss:0.052631861235440204\n",
      "train loss:0.022232628822399354\n",
      "train loss:0.08205041920081792\n",
      "train loss:0.025275531179433052\n",
      "train loss:0.0297709998657784\n",
      "train loss:0.03465654103978354\n",
      "train loss:0.06080342229547199\n",
      "train loss:0.0735895340036995\n",
      "train loss:0.03374679954437868\n",
      "train loss:0.08251214539715682\n",
      "train loss:0.039916364013996876\n",
      "train loss:0.05809898070302443\n",
      "train loss:0.062355884890330365\n",
      "train loss:0.03159894887151903\n",
      "train loss:0.058672550822769204\n",
      "train loss:0.05976124389013027\n",
      "train loss:0.05884723395428778\n",
      "train loss:0.1120233870681017\n",
      "train loss:0.09272751194782364\n",
      "train loss:0.054191456043723794\n",
      "train loss:0.06710155088706124\n",
      "train loss:0.03578829860122359\n",
      "train loss:0.10292878083487218\n",
      "train loss:0.07203063720441555\n",
      "train loss:0.12630518175348196\n",
      "train loss:0.03466542967245167\n",
      "train loss:0.027364794956878876\n",
      "train loss:0.05352578876780389\n",
      "train loss:0.06214498766692803\n",
      "train loss:0.06243259552781785\n",
      "train loss:0.04729038704074376\n",
      "train loss:0.1216106506429308\n",
      "train loss:0.08425638303245962\n",
      "train loss:0.10199621418195712\n",
      "train loss:0.02097041187186497\n",
      "train loss:0.04454830044550166\n",
      "train loss:0.012158553289794096\n",
      "train loss:0.03213333996851783\n",
      "train loss:0.08294017722095988\n",
      "train loss:0.10901604132725548\n",
      "train loss:0.048942299941090076\n",
      "train loss:0.06063008460706624\n",
      "train loss:0.056719639490919134\n",
      "train loss:0.049864570891104326\n",
      "train loss:0.10682067617535529\n",
      "train loss:0.02487583540595278\n",
      "train loss:0.06950835957891352\n",
      "train loss:0.12118427150240187\n",
      "train loss:0.07745240835905597\n",
      "train loss:0.04367578266885179\n",
      "train loss:0.03716372785935415\n",
      "train loss:0.04663212881508543\n",
      "train loss:0.13425624105891928\n",
      "train loss:0.05011891069086739\n",
      "train loss:0.04340746335202875\n",
      "train loss:0.04000614926643425\n",
      "train loss:0.11092506179410566\n",
      "train loss:0.05060465757347706\n",
      "train loss:0.05510735287916492\n",
      "train loss:0.09873238601419056\n",
      "train loss:0.0786031843693325\n",
      "train loss:0.032621959676524655\n",
      "train loss:0.022970479179893716\n",
      "train loss:0.04861351331038774\n",
      "train loss:0.06247786478042631\n",
      "train loss:0.12956071316261006\n",
      "train loss:0.040090884807849586\n",
      "train loss:0.052662072329619065\n",
      "train loss:0.18958398759900014\n",
      "train loss:0.0828862827305305\n",
      "train loss:0.03153323547435391\n",
      "train loss:0.06449831486205654\n",
      "train loss:0.07982955823575064\n",
      "train loss:0.08216709504090015\n",
      "train loss:0.09577546906202121\n",
      "train loss:0.06087059533491737\n",
      "train loss:0.050881159600587145\n",
      "train loss:0.031189045171663817\n",
      "train loss:0.13886001889843494\n",
      "train loss:0.05642748315019085\n",
      "train loss:0.03099711661620015\n",
      "train loss:0.06688886546685072\n",
      "train loss:0.03704379464261292\n",
      "train loss:0.0772200780623758\n",
      "train loss:0.11003130956228606\n",
      "train loss:0.046569576652209344\n",
      "train loss:0.02891019369654172\n",
      "train loss:0.062114028820992\n",
      "train loss:0.04171924977535127\n",
      "train loss:0.052763992607316276\n",
      "train loss:0.06982406212551613\n",
      "train loss:0.07433788322816168\n",
      "train loss:0.04966113470132291\n",
      "train loss:0.02479104550612311\n",
      "train loss:0.0395766540984054\n",
      "train loss:0.09711305220343804\n",
      "train loss:0.038393649264990226\n",
      "train loss:0.021063017704606203\n",
      "train loss:0.016360632310270656\n",
      "train loss:0.0265827956570493\n",
      "train loss:0.09444421874246307\n",
      "train loss:0.1539102916870506\n",
      "train loss:0.02847953290416376\n",
      "train loss:0.02598929097291133\n",
      "train loss:0.039230827954906664\n",
      "train loss:0.04012704297887538\n",
      "train loss:0.07770556144613969\n",
      "train loss:0.08658700473529388\n",
      "train loss:0.09891296962740183\n",
      "train loss:0.05269837418744078\n",
      "train loss:0.06514116487496727\n",
      "train loss:0.08755622180032825\n",
      "train loss:0.08826391664048196\n",
      "train loss:0.029584061704841923\n",
      "train loss:0.08569313713538645\n",
      "train loss:0.06081348588573885\n",
      "train loss:0.1268392904794187\n",
      "train loss:0.18635816069271346\n",
      "train loss:0.034517921670285154\n",
      "train loss:0.06572880464864234\n",
      "train loss:0.023303017143303673\n",
      "train loss:0.16094659416016124\n",
      "train loss:0.08319400763716732\n",
      "train loss:0.08749724354271196\n",
      "train loss:0.06879681734197605\n",
      "train loss:0.061767874582571755\n",
      "train loss:0.1570599670070026\n",
      "train loss:0.05648823137752725\n",
      "train loss:0.028185725702425158\n",
      "train loss:0.02874626242060112\n",
      "train loss:0.010296540786786485\n",
      "train loss:0.03704744891898086\n",
      "train loss:0.05936004490398657\n",
      "train loss:0.08793367097050271\n",
      "train loss:0.0635608186506226\n",
      "train loss:0.1203344249365906\n",
      "train loss:0.07400890593020583\n",
      "train loss:0.025114823155202647\n",
      "train loss:0.0582848395652292\n",
      "train loss:0.04730179825715461\n",
      "train loss:0.026707963811085172\n",
      "train loss:0.029456140822465685\n",
      "train loss:0.07725500334170429\n",
      "train loss:0.02434440520924187\n",
      "train loss:0.06518818932253792\n",
      "train loss:0.07398622114568823\n",
      "train loss:0.14626385217832466\n",
      "train loss:0.08337303269952763\n",
      "train loss:0.13317355842832448\n",
      "train loss:0.06097282963312226\n",
      "train loss:0.051576426326372535\n",
      "train loss:0.04227547654814186\n",
      "train loss:0.027516030414800885\n",
      "train loss:0.06950416520148008\n",
      "train loss:0.04858290812640222\n",
      "train loss:0.07690081004192201\n",
      "train loss:0.046011270352055614\n",
      "train loss:0.030750945412721147\n",
      "train loss:0.04332305284118501\n",
      "train loss:0.03864932787769482\n",
      "train loss:0.056803321099681156\n",
      "train loss:0.03848575648604072\n",
      "train loss:0.04799771354894963\n",
      "train loss:0.08985161989349776\n",
      "train loss:0.03241539823998571\n",
      "train loss:0.055476017739353435\n",
      "train loss:0.07441102744196088\n",
      "train loss:0.0845958820973845\n",
      "train loss:0.0990568316566507\n",
      "train loss:0.026418201303362046\n",
      "train loss:0.071889379577727\n",
      "train loss:0.01699635475010172\n",
      "train loss:0.04538550084442328\n",
      "train loss:0.02961430702949749\n",
      "train loss:0.014179316944374916\n",
      "train loss:0.0569903492536277\n",
      "train loss:0.08663586861076335\n",
      "train loss:0.1260797475112232\n",
      "train loss:0.029916727406190467\n",
      "train loss:0.06562859491442918\n",
      "train loss:0.07586737912994275\n",
      "train loss:0.08415909960707096\n",
      "train loss:0.06674933790105415\n",
      "train loss:0.03228752705400799\n",
      "train loss:0.06643590184773857\n",
      "train loss:0.06220802155795336\n",
      "train loss:0.020389551462093834\n",
      "train loss:0.08478499821530155\n",
      "train loss:0.030118691975067894\n",
      "train loss:0.060341270446250386\n",
      "train loss:0.09216620533725006\n",
      "train loss:0.0882800507876914\n",
      "train loss:0.06682460992055927\n",
      "train loss:0.07033958584485073\n",
      "train loss:0.06665543745566961\n",
      "train loss:0.05223006036251907\n",
      "train loss:0.03955015916487016\n",
      "train loss:0.05000023841901641\n",
      "train loss:0.045218396863131\n",
      "train loss:0.03729983793680234\n",
      "train loss:0.024984035344055692\n",
      "train loss:0.023074551242546627\n",
      "train loss:0.04035565146263122\n",
      "train loss:0.05267840736793319\n",
      "train loss:0.1248132064806114\n",
      "train loss:0.01949053724908215\n",
      "train loss:0.09584999587476978\n",
      "train loss:0.058237743941404636\n",
      "train loss:0.06149248799199697\n",
      "train loss:0.1285946811008501\n",
      "train loss:0.0639644742628818\n",
      "train loss:0.05925605498083798\n",
      "train loss:0.037704528153439214\n",
      "train loss:0.02603689824144262\n",
      "train loss:0.06892456755351516\n",
      "train loss:0.04679956505951987\n",
      "train loss:0.028540645005655275\n",
      "train loss:0.09883768232702471\n",
      "train loss:0.01878853410822144\n",
      "train loss:0.04042634356076926\n",
      "=== epoch:3, train acc:0.981, test acc:0.978 ===\n",
      "train loss:0.03369273103325702\n",
      "train loss:0.039235088674569416\n",
      "train loss:0.040283748704327105\n",
      "train loss:0.14192289510750705\n",
      "train loss:0.017816177542400426\n",
      "train loss:0.03597466761115262\n",
      "train loss:0.028873369961639424\n",
      "train loss:0.07533561846318086\n",
      "train loss:0.11183370290343632\n",
      "train loss:0.05725804311801234\n",
      "train loss:0.02675407981690771\n",
      "train loss:0.039290168663607926\n",
      "train loss:0.07793651477241398\n",
      "train loss:0.1233949775696416\n",
      "train loss:0.025309083421219635\n",
      "train loss:0.10387284088853006\n",
      "train loss:0.13677655805592287\n",
      "train loss:0.05125354485723748\n",
      "train loss:0.022406411246671105\n",
      "train loss:0.1113980315725061\n",
      "train loss:0.02654017196242758\n",
      "train loss:0.029686832314774078\n",
      "train loss:0.06918999252223966\n",
      "train loss:0.030524886539569904\n",
      "train loss:0.021617431709464067\n",
      "train loss:0.04269042119262742\n",
      "train loss:0.049750294052425925\n",
      "train loss:0.0528628608623247\n",
      "train loss:0.03309675924028459\n",
      "train loss:0.02094129366954323\n",
      "train loss:0.10922521175666704\n",
      "train loss:0.1334612435021967\n",
      "train loss:0.0600401466542511\n",
      "train loss:0.051959040895856345\n",
      "train loss:0.046100887238110094\n",
      "train loss:0.017536715855945403\n",
      "train loss:0.05776536439815119\n",
      "train loss:0.028931994380671847\n",
      "train loss:0.060444145163880865\n",
      "train loss:0.045765708304211145\n",
      "train loss:0.044499183020384775\n",
      "train loss:0.03152349921579506\n",
      "train loss:0.06002451923769345\n",
      "train loss:0.07850315265905188\n",
      "train loss:0.1434422372485304\n",
      "train loss:0.09764727808861824\n",
      "train loss:0.03145901675752757\n",
      "train loss:0.09877387893302325\n",
      "train loss:0.036294354240171384\n",
      "train loss:0.0568588272565292\n",
      "train loss:0.01834825991703749\n",
      "train loss:0.018948730748513793\n",
      "train loss:0.0824052168353608\n",
      "train loss:0.019425492301706107\n",
      "train loss:0.06265406868000081\n",
      "train loss:0.04411821713338527\n",
      "train loss:0.035755494384842906\n",
      "train loss:0.013440410541864234\n",
      "train loss:0.1210415689318746\n",
      "train loss:0.03510284760447684\n",
      "train loss:0.01734992145401757\n",
      "train loss:0.03676837197988263\n",
      "train loss:0.09539746493505975\n",
      "train loss:0.02466937373542474\n",
      "train loss:0.04337738242698003\n",
      "train loss:0.01733838247961029\n",
      "train loss:0.030994300270000587\n",
      "train loss:0.10921400003383092\n",
      "train loss:0.050667703546770006\n",
      "train loss:0.02730177578674348\n",
      "train loss:0.13755286934189606\n",
      "train loss:0.05858736756144954\n",
      "train loss:0.09108602901415594\n",
      "train loss:0.019048188425874947\n",
      "train loss:0.016312400915921323\n",
      "train loss:0.05230970252277825\n",
      "train loss:0.028865808733023312\n",
      "train loss:0.06363094269535105\n",
      "train loss:0.0716145313660732\n",
      "train loss:0.02948544741027643\n",
      "train loss:0.05457803208106229\n",
      "train loss:0.036209224075854404\n",
      "train loss:0.01228768280129931\n",
      "train loss:0.02235169063318981\n",
      "train loss:0.049125536918406876\n",
      "train loss:0.06899865557777943\n",
      "train loss:0.09822174577050757\n",
      "train loss:0.01825693385720999\n",
      "train loss:0.056509319356504495\n",
      "train loss:0.05810925416483028\n",
      "train loss:0.06477906173036556\n",
      "train loss:0.010262094861449878\n",
      "train loss:0.03351882604887462\n",
      "train loss:0.0342373285942566\n",
      "train loss:0.022691418232922866\n",
      "train loss:0.09326859084422814\n",
      "train loss:0.06707730829193605\n",
      "train loss:0.0622269002176724\n",
      "train loss:0.06775267350129814\n",
      "train loss:0.05014761154037872\n",
      "train loss:0.12590070222430477\n",
      "train loss:0.02710243924112917\n",
      "train loss:0.03806885774610949\n",
      "train loss:0.061960521761157\n",
      "train loss:0.07156554559244942\n",
      "train loss:0.08012602292058213\n",
      "train loss:0.06278935825136993\n",
      "train loss:0.09527403105341962\n",
      "train loss:0.01723660424168251\n",
      "train loss:0.02342047282678865\n",
      "train loss:0.03729067907844236\n",
      "train loss:0.03383498942621728\n",
      "train loss:0.13111513968636854\n",
      "train loss:0.044685536870059585\n",
      "train loss:0.01935741265239522\n",
      "train loss:0.12588294956460072\n",
      "train loss:0.01655041079726927\n",
      "train loss:0.046274020206581314\n",
      "train loss:0.03813388150562849\n",
      "train loss:0.1348873148532556\n",
      "train loss:0.04280274966978501\n",
      "train loss:0.04988846757977029\n",
      "train loss:0.04891160751611903\n",
      "train loss:0.04333556197836172\n",
      "train loss:0.0576018912488312\n",
      "train loss:0.05490407038965811\n",
      "train loss:0.06680836716236312\n",
      "train loss:0.02390967832501386\n",
      "train loss:0.09230061120104713\n",
      "train loss:0.02049651050898558\n",
      "train loss:0.048106657732425714\n",
      "train loss:0.018935666256471327\n",
      "train loss:0.073861079898704\n",
      "train loss:0.0845452035029108\n",
      "train loss:0.05121138759786129\n",
      "train loss:0.032896409506133026\n",
      "train loss:0.04019216861561757\n",
      "train loss:0.01823790349516273\n",
      "train loss:0.024209007369853656\n",
      "train loss:0.04718794510178442\n",
      "train loss:0.022380279475258627\n",
      "train loss:0.03326140132018139\n",
      "train loss:0.024412533299507908\n",
      "train loss:0.14713306600331547\n",
      "train loss:0.08669087207280059\n",
      "train loss:0.11713186003031612\n",
      "train loss:0.08621501695649465\n",
      "train loss:0.02759700800804713\n",
      "train loss:0.029511767365286136\n",
      "train loss:0.02963301976574362\n",
      "train loss:0.05366273560494772\n",
      "train loss:0.10769365127937947\n",
      "train loss:0.0386962680185886\n",
      "train loss:0.04076851014090461\n",
      "train loss:0.034194226902468185\n",
      "train loss:0.03187194040362907\n",
      "train loss:0.014805024682218974\n",
      "train loss:0.06177564618779775\n",
      "train loss:0.011231728976698843\n",
      "train loss:0.07131357563674336\n",
      "train loss:0.06921236953111311\n",
      "train loss:0.06327357360950998\n",
      "train loss:0.1355745999949799\n",
      "train loss:0.03576744391773876\n",
      "train loss:0.02714219856386752\n",
      "train loss:0.05391219996837739\n",
      "train loss:0.0914435185844984\n",
      "train loss:0.055730653775876424\n",
      "train loss:0.010758114289880494\n",
      "train loss:0.02619818178513262\n",
      "train loss:0.04963614500362738\n",
      "train loss:0.08473794255450655\n",
      "train loss:0.10154480328549971\n",
      "train loss:0.06813075567171274\n",
      "train loss:0.04225152957228607\n",
      "train loss:0.07282302785239538\n",
      "train loss:0.022245528376241434\n",
      "train loss:0.055702274105225734\n",
      "train loss:0.016365248490797395\n",
      "train loss:0.04148515070362996\n",
      "train loss:0.011387074023320079\n",
      "train loss:0.012188421153215218\n",
      "train loss:0.0791146435786193\n",
      "train loss:0.040347825590447375\n",
      "train loss:0.031034611555604087\n",
      "train loss:0.03737848691421031\n",
      "train loss:0.04781564255246366\n",
      "train loss:0.14527314020772228\n",
      "train loss:0.042351237529689535\n",
      "train loss:0.010782440133137741\n",
      "train loss:0.06118926195719788\n",
      "train loss:0.02329743158312184\n",
      "train loss:0.11789884253619148\n",
      "train loss:0.10853622165905875\n",
      "train loss:0.01659854521226756\n",
      "train loss:0.04334178823793236\n",
      "train loss:0.038370053721488946\n",
      "train loss:0.026927662833346397\n",
      "train loss:0.05659406144211821\n",
      "train loss:0.020122376439043833\n",
      "train loss:0.05215661559834261\n",
      "train loss:0.10624508384019263\n",
      "train loss:0.04226783016535795\n",
      "train loss:0.028038316579048653\n",
      "train loss:0.014079752302325207\n",
      "train loss:0.037277052685493216\n",
      "train loss:0.03283621231961963\n",
      "train loss:0.0694985142010086\n",
      "train loss:0.014260338878400615\n",
      "train loss:0.03729389534128261\n",
      "train loss:0.04785787234015922\n",
      "train loss:0.030761132576930614\n",
      "train loss:0.048736922700441776\n",
      "train loss:0.046389206030891986\n",
      "train loss:0.0469424890877945\n",
      "train loss:0.015546700768301717\n",
      "train loss:0.05023925451591439\n",
      "train loss:0.0076323129745156015\n",
      "train loss:0.03624762579768783\n",
      "train loss:0.04283884504761366\n",
      "train loss:0.029640230613719277\n",
      "train loss:0.02684916258846324\n",
      "train loss:0.056267905754781716\n",
      "train loss:0.045854064490285326\n",
      "train loss:0.06588675884123717\n",
      "train loss:0.03942631856106696\n",
      "train loss:0.0496226065255423\n",
      "train loss:0.012461904480715373\n",
      "train loss:0.07628846034022278\n",
      "train loss:0.05219708669974039\n",
      "train loss:0.026484333416377476\n",
      "train loss:0.05451955018021735\n",
      "train loss:0.06572028461997634\n",
      "train loss:0.007178629324304928\n",
      "train loss:0.05340678887090968\n",
      "train loss:0.022479733451016632\n",
      "train loss:0.05649601087534442\n",
      "train loss:0.1023922415455753\n",
      "train loss:0.0448824740228935\n",
      "train loss:0.05510554166426118\n",
      "train loss:0.01630242198796825\n",
      "train loss:0.04587651193597051\n",
      "train loss:0.03932289535539536\n",
      "train loss:0.02704166873363129\n",
      "train loss:0.013333637676089354\n",
      "train loss:0.035825260499351405\n",
      "train loss:0.05771017985148845\n",
      "train loss:0.033163721925296145\n",
      "train loss:0.01873496159708359\n",
      "train loss:0.03253280270914945\n",
      "train loss:0.04382315300150113\n",
      "train loss:0.07993198760115187\n",
      "train loss:0.07097255493092615\n",
      "train loss:0.02396378741486114\n",
      "train loss:0.008683501737561317\n",
      "train loss:0.011526401571817488\n",
      "train loss:0.01858967917075922\n",
      "train loss:0.06110167737287025\n",
      "train loss:0.011041736323772871\n",
      "train loss:0.04608795452247258\n",
      "train loss:0.035072747787873386\n",
      "train loss:0.020592726928198104\n",
      "train loss:0.018381387770218992\n",
      "train loss:0.038875830576636024\n",
      "train loss:0.041564864258674276\n",
      "train loss:0.02585210502262474\n",
      "train loss:0.010472593132601803\n",
      "train loss:0.051671514709001054\n",
      "train loss:0.04222944117080219\n",
      "train loss:0.07235673967137811\n",
      "train loss:0.041161042485890045\n",
      "train loss:0.05024695856029321\n",
      "train loss:0.05763009388155565\n",
      "train loss:0.052896302545226925\n",
      "train loss:0.010164064168797808\n",
      "train loss:0.06551985608096894\n",
      "train loss:0.032054113515194674\n",
      "train loss:0.041141447223058306\n",
      "train loss:0.01451581371941884\n",
      "train loss:0.024905665546282024\n",
      "train loss:0.0276950106835535\n",
      "train loss:0.12372745414791686\n",
      "train loss:0.06384527433437295\n",
      "train loss:0.06563672250284806\n",
      "train loss:0.051983179166034794\n",
      "train loss:0.08143981189150297\n",
      "train loss:0.06198473328553906\n",
      "train loss:0.03930817834599615\n",
      "train loss:0.01958984032161418\n",
      "train loss:0.05647198111911462\n",
      "train loss:0.042707074206458\n",
      "train loss:0.10346523264805921\n",
      "train loss:0.017267139253238507\n",
      "train loss:0.036073944844586966\n",
      "train loss:0.013290451166735915\n",
      "train loss:0.018245773467177134\n",
      "train loss:0.08364263682030065\n",
      "train loss:0.05497759958969354\n",
      "train loss:0.04835809073127524\n",
      "train loss:0.01659941950625795\n",
      "train loss:0.01867119436452991\n",
      "train loss:0.023441720196577785\n",
      "train loss:0.008128141522298668\n",
      "train loss:0.00945849461478027\n",
      "train loss:0.038072214907442115\n",
      "train loss:0.027067347218257386\n",
      "train loss:0.010098319899957903\n",
      "train loss:0.006236261610784413\n",
      "train loss:0.0785253962251583\n",
      "train loss:0.07613564431380242\n",
      "train loss:0.09258619630519754\n",
      "train loss:0.14459535090140183\n",
      "train loss:0.02330649062665037\n",
      "train loss:0.16697739040045412\n",
      "train loss:0.03661614614662451\n",
      "train loss:0.008654940345576553\n",
      "train loss:0.030767266651653823\n",
      "train loss:0.03500537052606617\n",
      "train loss:0.08759475854006277\n",
      "train loss:0.017114218426029903\n",
      "train loss:0.10445635296429526\n",
      "train loss:0.04359498620234618\n",
      "train loss:0.029422937637367978\n",
      "train loss:0.015029048689576406\n",
      "train loss:0.07203448799560015\n",
      "train loss:0.057332021902919396\n",
      "train loss:0.029085124783177464\n",
      "train loss:0.08466208625036499\n",
      "train loss:0.06238972338877533\n",
      "train loss:0.10819335484753974\n",
      "train loss:0.05860157062150119\n",
      "train loss:0.02615547304604555\n",
      "train loss:0.026676956788661204\n",
      "train loss:0.0606504158229263\n",
      "train loss:0.11970126786651543\n",
      "train loss:0.010255343434536825\n",
      "train loss:0.04661831030135357\n",
      "train loss:0.04416044010146245\n",
      "train loss:0.06980888560558186\n",
      "train loss:0.06784585165736062\n",
      "train loss:0.0672513809850695\n",
      "train loss:0.04749923468368279\n",
      "train loss:0.041543869406554725\n",
      "train loss:0.0603335870456979\n",
      "train loss:0.048628573947815855\n",
      "train loss:0.025328223423997084\n",
      "train loss:0.03301896084078238\n",
      "train loss:0.03181511049479972\n",
      "train loss:0.045965627096617834\n",
      "train loss:0.07309508349632629\n",
      "train loss:0.06754306397202431\n",
      "train loss:0.05992931868488584\n",
      "train loss:0.009520156407749366\n",
      "train loss:0.041537521956270744\n",
      "train loss:0.04321810953246807\n",
      "train loss:0.035187159799388315\n",
      "train loss:0.03609333277160166\n",
      "train loss:0.10519954678588211\n",
      "train loss:0.1700903555240033\n",
      "train loss:0.048769282584873924\n",
      "train loss:0.03890055521222542\n",
      "train loss:0.06515697892382541\n",
      "train loss:0.05430752636859693\n",
      "train loss:0.0673796066360609\n",
      "train loss:0.010257386535874992\n",
      "train loss:0.06313042328822047\n",
      "train loss:0.03973554170498451\n",
      "train loss:0.07837777658447753\n",
      "train loss:0.041912264608032684\n",
      "train loss:0.017874940022891223\n",
      "train loss:0.09622226771469286\n",
      "train loss:0.07983008736625871\n",
      "train loss:0.03412042420704809\n",
      "train loss:0.08305667859367269\n",
      "train loss:0.017663917011325626\n",
      "train loss:0.11539591530968002\n",
      "train loss:0.051916870806644325\n",
      "train loss:0.06578432405188188\n",
      "train loss:0.06465787687397101\n",
      "train loss:0.08013464999627892\n",
      "train loss:0.05731976240110481\n",
      "train loss:0.11389716581220244\n",
      "train loss:0.05439943188908644\n",
      "train loss:0.06389892293981464\n",
      "train loss:0.05304657361162951\n",
      "train loss:0.011860058941290165\n",
      "train loss:0.01999932216499437\n",
      "train loss:0.04604603554755451\n",
      "train loss:0.07007943493797289\n",
      "train loss:0.014366618662707085\n",
      "train loss:0.11015546333127522\n",
      "train loss:0.044644260814490994\n",
      "train loss:0.06257759234269694\n",
      "train loss:0.06025594575571451\n",
      "train loss:0.07623575805670142\n",
      "train loss:0.03267260233573192\n",
      "train loss:0.10335233837715489\n",
      "train loss:0.017719932718471106\n",
      "train loss:0.051488276491412854\n",
      "train loss:0.0583770502243871\n",
      "train loss:0.06294751432811738\n",
      "train loss:0.016736574882236063\n",
      "train loss:0.06209017017091849\n",
      "train loss:0.06259371065461637\n",
      "train loss:0.037291092154619496\n",
      "train loss:0.030855041827843127\n",
      "train loss:0.03560024635437766\n",
      "train loss:0.07945583665557743\n",
      "train loss:0.09382792616897608\n",
      "train loss:0.07402117583652637\n",
      "train loss:0.02592143051730388\n",
      "train loss:0.015600333245118874\n",
      "train loss:0.05141943451859848\n",
      "train loss:0.012696039988051465\n",
      "train loss:0.03703590667072745\n",
      "train loss:0.018416587883184583\n",
      "train loss:0.023032014125053513\n",
      "train loss:0.059982341520265055\n",
      "train loss:0.027838987242643692\n",
      "train loss:0.07133672557569967\n",
      "train loss:0.06516983687222862\n",
      "train loss:0.038192738755126986\n",
      "train loss:0.01374733337410914\n",
      "train loss:0.041749913713253456\n",
      "train loss:0.04929420104855965\n",
      "train loss:0.047090137232710855\n",
      "train loss:0.030688227885764478\n",
      "train loss:0.008716654537347174\n",
      "train loss:0.008950679852282638\n",
      "train loss:0.032420351838780115\n",
      "train loss:0.03818742513520208\n",
      "train loss:0.02802244659813955\n",
      "train loss:0.019289885850988203\n",
      "train loss:0.06452655530246906\n",
      "train loss:0.06951463331319893\n",
      "train loss:0.08281630581958117\n",
      "train loss:0.0735813538513553\n",
      "train loss:0.12534080446315557\n",
      "train loss:0.03448786457740887\n",
      "train loss:0.019261454821251477\n",
      "train loss:0.020229932491913426\n",
      "train loss:0.04417159156186393\n",
      "train loss:0.07104551500850605\n",
      "train loss:0.06328020866096619\n",
      "train loss:0.03816997547597348\n",
      "train loss:0.01859947969318873\n",
      "train loss:0.013000212543709344\n",
      "train loss:0.02222244579406385\n",
      "train loss:0.03502621953905235\n",
      "train loss:0.021844128120561964\n",
      "train loss:0.04338134464647821\n",
      "train loss:0.034955315668225434\n",
      "train loss:0.020806469569727915\n",
      "train loss:0.008937053890407123\n",
      "train loss:0.006204713173164395\n",
      "train loss:0.034482314534600905\n",
      "train loss:0.022405020460402346\n",
      "train loss:0.03619619506933616\n",
      "train loss:0.019568439476658275\n",
      "train loss:0.03177668752823117\n",
      "train loss:0.04175241611577956\n",
      "train loss:0.02266320262281959\n",
      "train loss:0.02599761743769259\n",
      "train loss:0.026061653023813473\n",
      "train loss:0.012643954420910963\n",
      "train loss:0.044222638571109474\n",
      "train loss:0.027986673282031513\n",
      "train loss:0.05471739057525707\n",
      "train loss:0.09734535284141814\n",
      "train loss:0.013601161892511043\n",
      "train loss:0.08656569772191805\n",
      "train loss:0.038726690328084706\n",
      "train loss:0.010338551434411076\n",
      "train loss:0.04236405790930034\n",
      "train loss:0.04627087977423398\n",
      "train loss:0.08092028305075044\n",
      "train loss:0.048710654334019846\n",
      "train loss:0.053901192681805765\n",
      "train loss:0.07229450163544363\n",
      "train loss:0.04253339244926954\n",
      "train loss:0.009492513508023664\n",
      "train loss:0.034926756428723046\n",
      "train loss:0.012546281577616026\n",
      "train loss:0.020689133865565347\n",
      "train loss:0.025886368410434454\n",
      "train loss:0.023887602956053633\n",
      "train loss:0.08688273054928444\n",
      "train loss:0.03580694575745552\n",
      "train loss:0.014735472718395946\n",
      "train loss:0.02379120018874289\n",
      "train loss:0.02640775194416063\n",
      "train loss:0.029577650883664597\n",
      "train loss:0.03437573073329656\n",
      "train loss:0.02629450137986604\n",
      "train loss:0.0492912700175836\n",
      "train loss:0.06546271485436986\n",
      "train loss:0.02153877896171831\n",
      "train loss:0.1130480396041825\n",
      "train loss:0.02305759896577883\n",
      "train loss:0.008593865046424733\n",
      "train loss:0.06021113109485343\n",
      "train loss:0.04065510722316346\n",
      "train loss:0.05977513520337175\n",
      "train loss:0.02409633559821622\n",
      "train loss:0.03995329257120908\n",
      "train loss:0.017863439535762363\n",
      "train loss:0.028459510828101463\n",
      "train loss:0.02392896452997462\n",
      "train loss:0.031490490223351174\n",
      "train loss:0.02951778117158731\n",
      "train loss:0.021179133594699896\n",
      "train loss:0.11680902824811382\n",
      "train loss:0.02819128514033082\n",
      "train loss:0.013569120973713019\n",
      "train loss:0.03570402410749954\n",
      "train loss:0.0872857895997388\n",
      "train loss:0.15341401388153406\n",
      "train loss:0.060670194757970794\n",
      "train loss:0.05292293246479928\n",
      "train loss:0.02474924193046227\n",
      "train loss:0.023102996887200362\n",
      "train loss:0.015254852536453223\n",
      "train loss:0.008471962635943542\n",
      "train loss:0.04460689548139482\n",
      "train loss:0.03352962367155113\n",
      "train loss:0.021503037189201706\n",
      "train loss:0.020571510011357895\n",
      "train loss:0.012436309328556765\n",
      "train loss:0.041545916870850116\n",
      "train loss:0.03177397639918784\n",
      "train loss:0.07046912313838848\n",
      "train loss:0.02068779338800718\n",
      "train loss:0.09410736660272181\n",
      "train loss:0.02572678779019668\n",
      "train loss:0.05223278669829002\n",
      "train loss:0.030631284316144577\n",
      "train loss:0.015957675446334592\n",
      "train loss:0.020646697834310005\n",
      "train loss:0.05185681213938359\n",
      "train loss:0.02879587065273199\n",
      "train loss:0.02022589825878092\n",
      "train loss:0.013223187395296352\n",
      "train loss:0.03877725870381219\n",
      "train loss:0.041155287618550404\n",
      "train loss:0.06896632198331454\n",
      "train loss:0.03155975863616417\n",
      "train loss:0.14502163798049159\n",
      "train loss:0.0718187542106335\n",
      "train loss:0.020650060112327662\n",
      "train loss:0.009376594107319147\n",
      "train loss:0.037692734311140924\n",
      "train loss:0.03841365429053219\n",
      "train loss:0.02294714240500295\n",
      "train loss:0.022406297792293195\n",
      "train loss:0.018012367890495987\n",
      "train loss:0.02845749982026293\n",
      "train loss:0.016614469788883323\n",
      "train loss:0.04885750846857502\n",
      "train loss:0.006361367605770036\n",
      "train loss:0.04061667285512383\n",
      "train loss:0.04046536191457193\n",
      "train loss:0.09849622438478355\n",
      "train loss:0.036301390504233796\n",
      "train loss:0.01738037755795449\n",
      "train loss:0.029179937167411497\n",
      "train loss:0.036210324713176846\n",
      "train loss:0.042072123066333796\n",
      "train loss:0.11633284479666912\n",
      "train loss:0.07856560852235421\n",
      "train loss:0.0540214014876081\n",
      "train loss:0.04510732828767666\n",
      "train loss:0.028877920249256867\n",
      "train loss:0.07832326778465905\n",
      "train loss:0.021269042641453663\n",
      "train loss:0.020077452222576467\n",
      "train loss:0.023608978604999456\n",
      "train loss:0.025407049065604505\n",
      "train loss:0.02237384587606544\n",
      "train loss:0.05136842647845549\n",
      "train loss:0.0647872127194615\n",
      "train loss:0.11490506472473123\n",
      "train loss:0.032364719055743854\n",
      "train loss:0.04448165046092998\n",
      "train loss:0.01209197285835844\n",
      "train loss:0.06556802241167926\n",
      "train loss:0.10999053129582945\n",
      "train loss:0.12456329523661071\n",
      "train loss:0.040149991451204986\n",
      "train loss:0.023273117771813137\n",
      "train loss:0.0067903862780288515\n",
      "train loss:0.009913739987170893\n",
      "train loss:0.021732428679936605\n",
      "train loss:0.015843193719758678\n",
      "train loss:0.05142506913103903\n",
      "train loss:0.05697757628588377\n",
      "train loss:0.042507344901163\n",
      "train loss:0.02673259675195495\n",
      "train loss:0.056425119803625315\n",
      "train loss:0.03457179984642145\n",
      "train loss:0.03414959978706158\n",
      "=== epoch:4, train acc:0.985, test acc:0.983 ===\n",
      "train loss:0.022509069827215244\n",
      "train loss:0.03627394861008743\n",
      "train loss:0.03146196008774935\n",
      "train loss:0.017570974322342087\n",
      "train loss:0.027269685031142864\n",
      "train loss:0.06711535250514218\n",
      "train loss:0.015774306290118337\n",
      "train loss:0.06324076767878832\n",
      "train loss:0.03151732657648538\n",
      "train loss:0.00599133405905265\n",
      "train loss:0.014052667376438637\n",
      "train loss:0.022492175881391026\n",
      "train loss:0.018942070490375062\n",
      "train loss:0.05643648179194941\n",
      "train loss:0.10071155212233124\n",
      "train loss:0.025464481606999594\n",
      "train loss:0.040111140227596875\n",
      "train loss:0.11321598398801257\n",
      "train loss:0.02364974390509229\n",
      "train loss:0.026081059155705976\n",
      "train loss:0.06311043719551417\n",
      "train loss:0.012011262191590946\n",
      "train loss:0.04067249311517525\n",
      "train loss:0.0440929223167324\n",
      "train loss:0.09643837993011138\n",
      "train loss:0.02299452393076905\n",
      "train loss:0.08580189112320605\n",
      "train loss:0.0095450702259653\n",
      "train loss:0.050561927393017306\n",
      "train loss:0.008641828148532761\n",
      "train loss:0.04886744474389793\n",
      "train loss:0.013815993557620204\n",
      "train loss:0.040608592393114866\n",
      "train loss:0.016763425139043085\n",
      "train loss:0.10087309444795016\n",
      "train loss:0.009924406672142682\n",
      "train loss:0.035353296030109616\n",
      "train loss:0.0634426578271633\n",
      "train loss:0.03292869956771796\n",
      "train loss:0.02697421373819302\n",
      "train loss:0.01696248972909765\n",
      "train loss:0.009470445937452887\n",
      "train loss:0.01530984858289588\n",
      "train loss:0.056632723355254946\n",
      "train loss:0.02807356885407595\n",
      "train loss:0.047661720207683486\n",
      "train loss:0.010652195706553786\n",
      "train loss:0.016968376454787028\n",
      "train loss:0.056924294414794324\n",
      "train loss:0.007931843793678716\n",
      "train loss:0.028194686923039773\n",
      "train loss:0.024446997996350875\n",
      "train loss:0.07206189670304844\n",
      "train loss:0.04862318351079955\n",
      "train loss:0.02048488664443533\n",
      "train loss:0.029233262637809215\n",
      "train loss:0.0147450476392575\n",
      "train loss:0.0063539950323911795\n",
      "train loss:0.045658866387393096\n",
      "train loss:0.03115834610033195\n",
      "train loss:0.05634672591918096\n",
      "train loss:0.0488706689237607\n",
      "train loss:0.03896567794568759\n",
      "train loss:0.04537668138051495\n",
      "train loss:0.029299183326176724\n",
      "train loss:0.0541775674569581\n",
      "train loss:0.012093676904780939\n",
      "train loss:0.06137666240492706\n",
      "train loss:0.011684134772761789\n",
      "train loss:0.03810516850212541\n",
      "train loss:0.013301970930233983\n",
      "train loss:0.035111207729149094\n",
      "train loss:0.015593667420773111\n",
      "train loss:0.0847905064181745\n",
      "train loss:0.040184658936800656\n",
      "train loss:0.01640106968118777\n",
      "train loss:0.010748962507077846\n",
      "train loss:0.08173465145595024\n",
      "train loss:0.02218039635878219\n",
      "train loss:0.06315522967955216\n",
      "train loss:0.04464149281417682\n",
      "train loss:0.025298916021963963\n",
      "train loss:0.029568788867694127\n",
      "train loss:0.016920495732516277\n",
      "train loss:0.09755341667184249\n",
      "train loss:0.06517407191438221\n",
      "train loss:0.015857644554482832\n",
      "train loss:0.04736709453278823\n",
      "train loss:0.058151288010783814\n",
      "train loss:0.04802381193077101\n",
      "train loss:0.046264428399718206\n",
      "train loss:0.0352044244850702\n",
      "train loss:0.020507371705663524\n",
      "train loss:0.036085018283941776\n",
      "train loss:0.011879716414482312\n",
      "train loss:0.0097805482204409\n",
      "train loss:0.03549979240358889\n",
      "train loss:0.06427466874081007\n",
      "train loss:0.06572541019547842\n",
      "train loss:0.018346540827262586\n",
      "train loss:0.03464678783337368\n",
      "train loss:0.04953770890178661\n",
      "train loss:0.02420630948237404\n",
      "train loss:0.018227234834322818\n",
      "train loss:0.0744966228356458\n",
      "train loss:0.006933913672136574\n",
      "train loss:0.049132142657120535\n",
      "train loss:0.04183376139152192\n",
      "train loss:0.042606701739706654\n",
      "train loss:0.008775807211275183\n",
      "train loss:0.06355698146072757\n",
      "train loss:0.02104672861471858\n",
      "train loss:0.021251425483550367\n",
      "train loss:0.053104901897019816\n",
      "train loss:0.07094724906704243\n",
      "train loss:0.043519822308827935\n",
      "train loss:0.046163597202961766\n",
      "train loss:0.014620714044794642\n",
      "train loss:0.04218459843385868\n",
      "train loss:0.08601050704863768\n",
      "train loss:0.03396179517798517\n",
      "train loss:0.08715282110816808\n",
      "train loss:0.042500139735505316\n",
      "train loss:0.05838438893346581\n",
      "train loss:0.006331168693422358\n",
      "train loss:0.037028052407178484\n",
      "train loss:0.04349167402522691\n",
      "train loss:0.053005289708701685\n",
      "train loss:0.022345229556232468\n",
      "train loss:0.04172339543979075\n",
      "train loss:0.021674783491254495\n",
      "train loss:0.028742025121901393\n",
      "train loss:0.09523901649808376\n",
      "train loss:0.06315232596158073\n",
      "train loss:0.04052729878549775\n",
      "train loss:0.04339540886454968\n",
      "train loss:0.011760395450097008\n",
      "train loss:0.010695205017888043\n",
      "train loss:0.03572783383837463\n",
      "train loss:0.03207982691331064\n",
      "train loss:0.041566792258728696\n",
      "train loss:0.02575724213472302\n",
      "train loss:0.04080550601426973\n",
      "train loss:0.019264524275296995\n",
      "train loss:0.01997524900829818\n",
      "train loss:0.08239789764884842\n",
      "train loss:0.06296209867246974\n",
      "train loss:0.022208500733927584\n",
      "train loss:0.022671590128748417\n",
      "train loss:0.10520284905917965\n",
      "train loss:0.04748982861238193\n",
      "train loss:0.008263008907486739\n",
      "train loss:0.023380994547810254\n",
      "train loss:0.060287863523399696\n",
      "train loss:0.116896463741595\n",
      "train loss:0.020364359060242955\n",
      "train loss:0.06726593452220524\n",
      "train loss:0.0134063399730897\n",
      "train loss:0.06847211466399636\n",
      "train loss:0.031046156377744265\n",
      "train loss:0.015811698072245882\n",
      "train loss:0.023426187149388086\n",
      "train loss:0.03581431120510488\n",
      "train loss:0.014084386092469267\n",
      "train loss:0.014961506432592359\n",
      "train loss:0.03150891545853995\n",
      "train loss:0.06537167381757303\n",
      "train loss:0.0148829573838435\n",
      "train loss:0.023807860632880082\n",
      "train loss:0.011512916313608285\n",
      "train loss:0.03883793760378876\n",
      "train loss:0.038983870762341534\n",
      "train loss:0.026688051990597983\n",
      "train loss:0.008475684173178089\n",
      "train loss:0.02877293708648213\n",
      "train loss:0.02438270774824555\n",
      "train loss:0.08909111564309384\n",
      "train loss:0.020002819686792957\n",
      "train loss:0.00447332489099674\n",
      "train loss:0.040074378465433824\n",
      "train loss:0.023388564261902355\n",
      "train loss:0.0616640876243797\n",
      "train loss:0.06650198821681803\n",
      "train loss:0.02413748252919183\n",
      "train loss:0.02117088305160086\n",
      "train loss:0.03472417920501429\n",
      "train loss:0.03943984817875219\n",
      "train loss:0.011896540589125724\n",
      "train loss:0.009042597808836723\n",
      "train loss:0.017402485537461033\n",
      "train loss:0.02739845622887892\n",
      "train loss:0.20625604583859336\n",
      "train loss:0.0894681021886249\n",
      "train loss:0.013545430714953278\n",
      "train loss:0.05268311431358489\n",
      "train loss:0.014930645046940054\n",
      "train loss:0.03845052578581447\n",
      "train loss:0.026735699009647007\n",
      "train loss:0.1202269727108479\n",
      "train loss:0.03366358937245937\n",
      "train loss:0.018334634187981022\n",
      "train loss:0.011151720222714096\n",
      "train loss:0.05199619217900702\n",
      "train loss:0.012222946708443072\n",
      "train loss:0.027697434137654547\n",
      "train loss:0.016005497384246548\n",
      "train loss:0.047314727741044234\n",
      "train loss:0.017793131164800975\n",
      "train loss:0.04052995890612193\n",
      "train loss:0.014750561782769756\n",
      "train loss:0.05652668046399595\n",
      "train loss:0.05000778969052456\n",
      "train loss:0.06690414163761471\n",
      "train loss:0.03102386061408551\n",
      "train loss:0.03843260240866503\n",
      "train loss:0.05237098785539351\n",
      "train loss:0.053124514497240975\n",
      "train loss:0.018472038615047304\n",
      "train loss:0.025259355678368674\n",
      "train loss:0.11022297291560344\n",
      "train loss:0.014879350626487034\n",
      "train loss:0.007473835139781673\n",
      "train loss:0.03719922862091884\n",
      "train loss:0.043143340536981246\n",
      "train loss:0.07434779896970682\n",
      "train loss:0.0062074602401855335\n",
      "train loss:0.014267864819128036\n",
      "train loss:0.015059310367522194\n",
      "train loss:0.019963103150048834\n",
      "train loss:0.011520857356420507\n",
      "train loss:0.05263664768374521\n",
      "train loss:0.025221836600690894\n",
      "train loss:0.06542406966317334\n",
      "train loss:0.008840410290607606\n",
      "train loss:0.035815998945859955\n",
      "train loss:0.03876594337166443\n",
      "train loss:0.030689150805635407\n",
      "train loss:0.08314459467106523\n",
      "train loss:0.014319364007375492\n",
      "train loss:0.031930416069997164\n",
      "train loss:0.05158660823042308\n",
      "train loss:0.023556668499470447\n",
      "train loss:0.10839855918520332\n",
      "train loss:0.007909013179100923\n",
      "train loss:0.039257048986451874\n",
      "train loss:0.024540258077241594\n",
      "train loss:0.02202996682899799\n",
      "train loss:0.02482809646258171\n",
      "train loss:0.004157766208817413\n",
      "train loss:0.09564013497040148\n",
      "train loss:0.12893034978731477\n",
      "train loss:0.008728064467921182\n",
      "train loss:0.012869589384081628\n",
      "train loss:0.046904992405186335\n",
      "train loss:0.028728259469562364\n",
      "train loss:0.05312992181470641\n",
      "train loss:0.012204053648194825\n",
      "train loss:0.008552859538001466\n",
      "train loss:0.07106287639955933\n",
      "train loss:0.011688607694270672\n",
      "train loss:0.04532346054860717\n",
      "train loss:0.09718769707225819\n",
      "train loss:0.027290752604533442\n",
      "train loss:0.09253067149196886\n",
      "train loss:0.0029389814773719647\n",
      "train loss:0.015949907239314883\n",
      "train loss:0.03595899839042095\n",
      "train loss:0.05802693014013377\n",
      "train loss:0.057106947536114186\n",
      "train loss:0.04470169832748761\n",
      "train loss:0.04377773416107734\n",
      "train loss:0.08462178407784941\n",
      "train loss:0.04704222144746377\n",
      "train loss:0.016661930101691785\n",
      "train loss:0.05011003276277301\n",
      "train loss:0.03539493450216953\n",
      "train loss:0.05962199975439763\n",
      "train loss:0.03301545631107682\n",
      "train loss:0.056075538523783476\n",
      "train loss:0.020131542986383203\n",
      "train loss:0.008203962467187065\n",
      "train loss:0.020145063649455276\n",
      "train loss:0.06409940637386431\n",
      "train loss:0.020647018283561334\n",
      "train loss:0.051535933996415116\n",
      "train loss:0.10669335848156493\n",
      "train loss:0.039263842339847796\n",
      "train loss:0.04652119526931161\n",
      "train loss:0.014187308024916268\n",
      "train loss:0.01618473944208677\n",
      "train loss:0.009343813275285147\n",
      "train loss:0.017238408046362876\n",
      "train loss:0.01697666245032925\n",
      "train loss:0.020014590103229965\n",
      "train loss:0.03314117012731288\n",
      "train loss:0.010809413387394553\n",
      "train loss:0.016282941535426334\n",
      "train loss:0.008973739967405053\n",
      "train loss:0.018266854779334114\n",
      "train loss:0.016507265485232094\n",
      "train loss:0.019668121622860257\n",
      "train loss:0.0069967643785424005\n",
      "train loss:0.029779979026047704\n",
      "train loss:0.046373293596353636\n",
      "train loss:0.0028505904401726367\n",
      "train loss:0.06175975086168735\n",
      "train loss:0.013668382934995586\n",
      "train loss:0.008270645073548504\n",
      "train loss:0.014309822406391275\n",
      "train loss:0.013033966022169597\n",
      "train loss:0.01080724547844275\n",
      "train loss:0.008753630336804851\n",
      "train loss:0.02124820171158822\n",
      "train loss:0.008963166606491737\n",
      "train loss:0.031233479023205068\n",
      "train loss:0.04164720571325235\n",
      "train loss:0.024192948616228137\n",
      "train loss:0.011991949784684706\n",
      "train loss:0.019811029819959677\n",
      "train loss:0.020959422572376814\n",
      "train loss:0.03921063174458643\n",
      "train loss:0.02483254866259065\n",
      "train loss:0.011561619420266242\n",
      "train loss:0.024431766897907322\n",
      "train loss:0.04904316256576947\n",
      "train loss:0.0473835019880962\n",
      "train loss:0.06247182544257033\n",
      "train loss:0.021800370829620094\n",
      "train loss:0.056797330991593356\n",
      "train loss:0.015135929208277533\n",
      "train loss:0.006858356559135099\n",
      "train loss:0.028977715647256104\n",
      "train loss:0.018848494565710246\n",
      "train loss:0.044040405481649066\n",
      "train loss:0.01345745592029512\n",
      "train loss:0.043657439006896795\n",
      "train loss:0.01541323884870641\n",
      "train loss:0.04575718669964171\n",
      "train loss:0.06563495751655679\n",
      "train loss:0.041726177966698745\n",
      "train loss:0.015381998948159973\n",
      "train loss:0.02080511188479038\n",
      "train loss:0.023512076420091347\n",
      "train loss:0.011779367981553808\n",
      "train loss:0.008533131166444812\n",
      "train loss:0.02955966153280837\n",
      "train loss:0.006581139335263846\n",
      "train loss:0.04209182935399282\n",
      "train loss:0.02010420009397273\n",
      "train loss:0.01190560999317383\n",
      "train loss:0.07695221185830241\n",
      "train loss:0.03230947986484723\n",
      "train loss:0.06803587925892546\n",
      "train loss:0.014728796129224625\n",
      "train loss:0.03285975433052763\n",
      "train loss:0.053136048703243316\n",
      "train loss:0.011453848722491273\n",
      "train loss:0.04822687823565639\n",
      "train loss:0.09210054434254708\n",
      "train loss:0.03406623500840276\n",
      "train loss:0.02637366759631072\n",
      "train loss:0.016138487227087106\n",
      "train loss:0.03208542884664963\n",
      "train loss:0.05547961538435048\n",
      "train loss:0.009947147242766961\n",
      "train loss:0.1268614842875245\n",
      "train loss:0.030142865099511647\n",
      "train loss:0.059863714517089904\n",
      "train loss:0.044274353369659215\n",
      "train loss:0.013702309869106939\n",
      "train loss:0.040702340557803494\n",
      "train loss:0.07740614724219984\n",
      "train loss:0.05516795443823063\n",
      "train loss:0.017167502823009047\n",
      "train loss:0.019998564936213208\n",
      "train loss:0.04338307473681198\n",
      "train loss:0.02938321708416177\n",
      "train loss:0.008922436799310205\n",
      "train loss:0.043170329426236095\n",
      "train loss:0.018115008225986284\n",
      "train loss:0.02461188195540016\n",
      "train loss:0.03499442269617273\n",
      "train loss:0.08007859292944969\n",
      "train loss:0.03145655808450964\n",
      "train loss:0.0509622306905909\n",
      "train loss:0.030745036035383186\n",
      "train loss:0.013218580464245282\n",
      "train loss:0.04517220691052635\n",
      "train loss:0.023616426683526644\n",
      "train loss:0.06724459114570161\n",
      "train loss:0.015034912509590128\n",
      "train loss:0.008495652666702103\n",
      "train loss:0.0314190683970167\n",
      "train loss:0.01057328390539439\n",
      "train loss:0.005446121684164637\n",
      "train loss:0.06968433593913742\n",
      "train loss:0.031104250027840466\n",
      "train loss:0.04815055896111244\n",
      "train loss:0.03146797871077077\n",
      "train loss:0.05039807150023402\n",
      "train loss:0.04820098683249741\n",
      "train loss:0.021954928462403354\n",
      "train loss:0.009654268308679145\n",
      "train loss:0.029149734669817455\n",
      "train loss:0.010731384427737056\n",
      "train loss:0.09364617528866796\n",
      "train loss:0.028555756480436848\n",
      "train loss:0.014840445224875178\n",
      "train loss:0.010573847242579317\n",
      "train loss:0.056451598524914645\n",
      "train loss:0.013147498902120415\n",
      "train loss:0.013789285702294754\n",
      "train loss:0.023501579642933507\n",
      "train loss:0.0651573089441764\n",
      "train loss:0.09146485329781177\n",
      "train loss:0.08131710473401756\n",
      "train loss:0.020034995708565838\n",
      "train loss:0.039664562163716124\n",
      "train loss:0.05203109611555019\n",
      "train loss:0.040094165591636644\n",
      "train loss:0.047905741366446625\n",
      "train loss:0.03216935502875348\n",
      "train loss:0.04505835770431644\n",
      "train loss:0.014849929091396288\n",
      "train loss:0.03050373035161748\n",
      "train loss:0.05752528686001805\n",
      "train loss:0.025830321198200282\n",
      "train loss:0.051480610346613095\n",
      "train loss:0.007205095439336293\n",
      "train loss:0.07202295429512652\n",
      "train loss:0.015257334839974329\n",
      "train loss:0.017189244390542143\n",
      "train loss:0.0471508464687029\n",
      "train loss:0.009853592546284139\n",
      "train loss:0.03579229819939074\n",
      "train loss:0.01857837667983182\n",
      "train loss:0.055714108061766146\n",
      "train loss:0.013430392964473552\n",
      "train loss:0.013752626507596778\n",
      "train loss:0.0859940122731604\n",
      "train loss:0.06486530183254194\n",
      "train loss:0.010443055148496557\n",
      "train loss:0.015267204894605545\n",
      "train loss:0.052692852029264554\n",
      "train loss:0.04518072483916818\n",
      "train loss:0.044913903473295706\n",
      "train loss:0.062102671239192324\n",
      "train loss:0.028775594039655746\n",
      "train loss:0.04507042970423446\n",
      "train loss:0.053960062131847925\n",
      "train loss:0.021489037544201693\n",
      "train loss:0.015374629583935874\n",
      "train loss:0.023328971180930354\n",
      "train loss:0.03946247889536196\n",
      "train loss:0.006472335728738644\n",
      "train loss:0.012128059233205105\n",
      "train loss:0.01773155222466502\n",
      "train loss:0.026251505531616634\n",
      "train loss:0.01677291084578239\n",
      "train loss:0.02544532825579946\n",
      "train loss:0.02984848027852847\n",
      "train loss:0.03416984283279324\n",
      "train loss:0.037121890196211635\n",
      "train loss:0.010960154198124223\n",
      "train loss:0.00834725103921356\n",
      "train loss:0.017125761959598088\n",
      "train loss:0.019577726290433525\n",
      "train loss:0.01190764274335949\n",
      "train loss:0.03173286077396475\n",
      "train loss:0.014518041571275397\n",
      "train loss:0.009642142685545444\n",
      "train loss:0.03430168110573003\n",
      "train loss:0.033177737513361956\n",
      "train loss:0.040246804118283866\n",
      "train loss:0.011403936028301767\n",
      "train loss:0.020676643095194066\n",
      "train loss:0.01952940229111965\n",
      "train loss:0.023784751163967183\n",
      "train loss:0.02426334711685687\n",
      "train loss:0.01879465720883336\n",
      "train loss:0.06546502967348466\n",
      "train loss:0.0633844559790836\n",
      "train loss:0.01213148368937852\n",
      "train loss:0.02361606285926431\n",
      "train loss:0.02724276061905949\n",
      "train loss:0.08154905806766381\n",
      "train loss:0.014393701517403297\n",
      "train loss:0.01525402800301101\n",
      "train loss:0.004039555860297504\n",
      "train loss:0.017314920197282414\n",
      "train loss:0.018343969623084818\n",
      "train loss:0.008140133105469547\n",
      "train loss:0.01996264126536659\n",
      "train loss:0.049369797812469904\n",
      "train loss:0.011339218401596391\n",
      "train loss:0.07691709510267246\n",
      "train loss:0.02324983671012232\n",
      "train loss:0.03151973402307834\n",
      "train loss:0.021224264856266054\n",
      "train loss:0.016238128236398787\n",
      "train loss:0.022896619630848263\n",
      "train loss:0.03224294710859673\n",
      "train loss:0.02184761304078011\n",
      "train loss:0.031232819212112566\n",
      "train loss:0.006215788543763384\n",
      "train loss:0.05120947587071876\n",
      "train loss:0.018385625141181118\n",
      "train loss:0.004540361506314879\n",
      "train loss:0.01868124345758938\n",
      "train loss:0.04391948497790096\n",
      "train loss:0.018048766257428135\n",
      "train loss:0.029614098075152247\n",
      "train loss:0.09176659920697547\n",
      "train loss:0.04452724717242721\n",
      "train loss:0.00759684158864545\n",
      "train loss:0.008048227377872974\n",
      "train loss:0.019819830916517935\n",
      "train loss:0.022689478336795212\n",
      "train loss:0.037204414949623385\n",
      "train loss:0.01413167364643928\n",
      "train loss:0.02175186103537856\n",
      "train loss:0.07345780127546242\n",
      "train loss:0.009298423891268082\n",
      "train loss:0.012790413836624819\n",
      "train loss:0.005765558288038959\n",
      "train loss:0.01720348243595004\n",
      "train loss:0.00481161323133143\n",
      "train loss:0.03640664077122573\n",
      "train loss:0.012236860622847399\n",
      "train loss:0.01880436814849682\n",
      "train loss:0.026438383571048614\n",
      "train loss:0.021673124871432903\n",
      "train loss:0.008926582756103491\n",
      "train loss:0.010071326199950038\n",
      "train loss:0.02234365634762484\n",
      "train loss:0.05306979948188345\n",
      "train loss:0.012836640841930069\n",
      "train loss:0.01214015156686901\n",
      "train loss:0.021264613816197882\n",
      "train loss:0.06770903845616479\n",
      "train loss:0.01806424713476609\n",
      "train loss:0.04073710693559507\n",
      "train loss:0.00851699212058098\n",
      "train loss:0.03381834751366513\n",
      "train loss:0.07876160684487847\n",
      "train loss:0.004536656071924125\n",
      "train loss:0.09576200573670743\n",
      "train loss:0.005255079447128982\n",
      "train loss:0.012314233417314191\n",
      "train loss:0.02493313189110631\n",
      "train loss:0.012301535909381624\n",
      "train loss:0.011250266105964697\n",
      "train loss:0.06155603634861305\n",
      "train loss:0.02620795582913292\n",
      "train loss:0.009051515121532176\n",
      "train loss:0.009871490309694367\n",
      "train loss:0.017568531334968635\n",
      "train loss:0.052833305341510234\n",
      "train loss:0.021768381567269294\n",
      "train loss:0.03248917020987643\n",
      "train loss:0.0266326260241843\n",
      "train loss:0.02651746853301719\n",
      "train loss:0.052820085008597015\n",
      "train loss:0.02597595833802553\n",
      "train loss:0.03242969311450106\n",
      "train loss:0.01611802972051486\n",
      "train loss:0.03231655561097395\n",
      "train loss:0.08748339644646023\n",
      "train loss:0.027895142308998006\n",
      "train loss:0.01134709292286857\n",
      "train loss:0.01864376970792809\n",
      "train loss:0.02008702707358666\n",
      "train loss:0.01024182873456559\n",
      "train loss:0.038436665565403004\n",
      "train loss:0.01955327570078674\n",
      "train loss:0.0072355992046122105\n",
      "train loss:0.012839618519227278\n",
      "train loss:0.03866165514297228\n",
      "train loss:0.016666615334831783\n",
      "train loss:0.10528328765185609\n",
      "train loss:0.02379994196483194\n",
      "train loss:0.005153292985148194\n",
      "train loss:0.023269915509303872\n",
      "train loss:0.021506217684869346\n",
      "train loss:0.014047896433554991\n",
      "train loss:0.012698486663252009\n",
      "train loss:0.012573727404692986\n",
      "train loss:0.01834643310037538\n",
      "train loss:0.00839695713153513\n",
      "train loss:0.014026080004790322\n",
      "train loss:0.015448136496207895\n",
      "train loss:0.01581683992982432\n",
      "train loss:0.022084660041398214\n",
      "train loss:0.0450052622174879\n",
      "train loss:0.027863010678283246\n",
      "train loss:0.014058501446942201\n",
      "train loss:0.008854180506266468\n",
      "train loss:0.04535687696821169\n",
      "train loss:0.06491551109736907\n",
      "train loss:0.044681865549831674\n",
      "=== epoch:5, train acc:0.986, test acc:0.984 ===\n",
      "train loss:0.0465646264373122\n",
      "train loss:0.013616271416269041\n",
      "train loss:0.014772996583372035\n",
      "train loss:0.0435349115563295\n",
      "train loss:0.0069404276039868075\n",
      "train loss:0.03184836887974949\n",
      "train loss:0.015271463298855713\n",
      "train loss:0.03446636809094441\n",
      "train loss:0.017231453058017307\n",
      "train loss:0.0032004235251006587\n",
      "train loss:0.008624031908272146\n",
      "train loss:0.01640471742256769\n",
      "train loss:0.018305609657525642\n",
      "train loss:0.014617936352134127\n",
      "train loss:0.013964009282079005\n",
      "train loss:0.01781549670121479\n",
      "train loss:0.015227400927373728\n",
      "train loss:0.01576550923664241\n",
      "train loss:0.07207327536772254\n",
      "train loss:0.009515674675108042\n",
      "train loss:0.013578147496000755\n",
      "train loss:0.011013926490052464\n",
      "train loss:0.007735500287554852\n",
      "train loss:0.009117707011450017\n",
      "train loss:0.017016351071453904\n",
      "train loss:0.011082323873380168\n",
      "train loss:0.011344686462032167\n",
      "train loss:0.05278345938931075\n",
      "train loss:0.02096846939168227\n",
      "train loss:0.023007569205169384\n",
      "train loss:0.039660241123176\n",
      "train loss:0.016075309002240145\n",
      "train loss:0.0245622021426491\n",
      "train loss:0.015469017474925892\n",
      "train loss:0.01561500494760203\n",
      "train loss:0.03523773202181981\n",
      "train loss:0.03156843762305287\n",
      "train loss:0.017226085514120887\n",
      "train loss:0.0051869228872294835\n",
      "train loss:0.018675013398312287\n",
      "train loss:0.0056557767008931495\n",
      "train loss:0.03587246006293854\n",
      "train loss:0.003970006684831967\n",
      "train loss:0.011041996654069599\n",
      "train loss:0.044036382198760105\n",
      "train loss:0.007976117917452443\n",
      "train loss:0.012446236813294438\n",
      "train loss:0.029615210845507202\n",
      "train loss:0.00785898674008592\n",
      "train loss:0.015614883709387793\n",
      "train loss:0.03296510102426982\n",
      "train loss:0.0711288189492055\n",
      "train loss:0.002964396261589461\n",
      "train loss:0.06444505478788462\n",
      "train loss:0.007212536694528949\n",
      "train loss:0.013225779291623664\n",
      "train loss:0.026054053478791143\n",
      "train loss:0.020244099844072768\n",
      "train loss:0.005645982260455095\n",
      "train loss:0.03156496887925222\n",
      "train loss:0.06244442667502832\n",
      "train loss:0.03646799644839272\n",
      "train loss:0.01362437865709804\n",
      "train loss:0.024511080772083003\n",
      "train loss:0.01642981489909506\n",
      "train loss:0.019680413837087473\n",
      "train loss:0.004835267828227886\n",
      "train loss:0.012777178207351629\n",
      "train loss:0.005110308847624655\n",
      "train loss:0.01746933713284407\n",
      "train loss:0.011027680918795335\n",
      "train loss:0.014327690473267329\n",
      "train loss:0.024969156658987347\n",
      "train loss:0.19539987156191035\n",
      "train loss:0.03239156371717149\n",
      "train loss:0.00630594706276124\n",
      "train loss:0.02924274368388418\n",
      "train loss:0.011967490344956571\n",
      "train loss:0.05193665559793208\n",
      "train loss:0.012027296316197495\n",
      "train loss:0.011651820780013762\n",
      "train loss:0.023299645909160026\n",
      "train loss:0.019183583767596737\n",
      "train loss:0.010408748334602197\n",
      "train loss:0.026923070454029894\n",
      "train loss:0.026450806251704297\n",
      "train loss:0.01911384380083109\n",
      "train loss:0.0678692018406729\n",
      "train loss:0.03212585820834537\n",
      "train loss:0.010561270957670043\n",
      "train loss:0.017553322085575588\n",
      "train loss:0.025196676158373118\n",
      "train loss:0.04644518055815288\n",
      "train loss:0.01205380383045341\n",
      "train loss:0.01977770960234343\n",
      "train loss:0.022109619937086024\n",
      "train loss:0.06278234530693134\n",
      "train loss:0.012221909389780166\n",
      "train loss:0.002658995805649112\n",
      "train loss:0.010597679688156012\n",
      "train loss:0.030528620275348476\n",
      "train loss:0.024415740187676047\n",
      "train loss:0.012523114278952337\n",
      "train loss:0.007759326739269613\n",
      "train loss:0.008567784011754852\n",
      "train loss:0.02865401605717433\n",
      "train loss:0.03924156333645916\n",
      "train loss:0.013519653147741744\n",
      "train loss:0.007042693595368244\n",
      "train loss:0.0051253020748068855\n",
      "train loss:0.002705310539022836\n",
      "train loss:0.005401200614679156\n",
      "train loss:0.03836969914561691\n",
      "train loss:0.03462583892725583\n",
      "train loss:0.004916337744512625\n",
      "train loss:0.016059639805065078\n",
      "train loss:0.021505720765978658\n",
      "train loss:0.02779880195505212\n",
      "train loss:0.016793653602944058\n",
      "train loss:0.023796182528798986\n",
      "train loss:0.03165493867440278\n",
      "train loss:0.025638787937458746\n",
      "train loss:0.03514787055689667\n",
      "train loss:0.012400083539635629\n",
      "train loss:0.04175633132565094\n",
      "train loss:0.03604758679168324\n",
      "train loss:0.03916008755074277\n",
      "train loss:0.09658616809386857\n",
      "train loss:0.02233383201138814\n",
      "train loss:0.006646527028785567\n",
      "train loss:0.01766225286700889\n",
      "train loss:0.007608717157548561\n",
      "train loss:0.0295501205653507\n",
      "train loss:0.057275232573297676\n",
      "train loss:0.02840335376220587\n",
      "train loss:0.017735022152360287\n",
      "train loss:0.01106487494543145\n",
      "train loss:0.019560686211174846\n",
      "train loss:0.018898474228421096\n",
      "train loss:0.03879553676960755\n",
      "train loss:0.009370884382851365\n",
      "train loss:0.2081812789849994\n",
      "train loss:0.04314236887686711\n",
      "train loss:0.036381626387438554\n",
      "train loss:0.014456451018223446\n",
      "train loss:0.051804094988807343\n",
      "train loss:0.025232601633626287\n",
      "train loss:0.01793079504674954\n",
      "train loss:0.023849207502166216\n",
      "train loss:0.03713394237888667\n",
      "train loss:0.05476636945109672\n",
      "train loss:0.0086498888005763\n",
      "train loss:0.02118561259766473\n",
      "train loss:0.015206666428986422\n",
      "train loss:0.013570400578245649\n",
      "train loss:0.003015338643760783\n",
      "train loss:0.07958105164194688\n",
      "train loss:0.023195757021009854\n",
      "train loss:0.007198585166187066\n",
      "train loss:0.027733787105489426\n",
      "train loss:0.038119290333069863\n",
      "train loss:0.014773654523577056\n",
      "train loss:0.015485752260619136\n",
      "train loss:0.027181731419365016\n",
      "train loss:0.028170097581511837\n",
      "train loss:0.019629578181724207\n",
      "train loss:0.024068025888141557\n",
      "train loss:0.04220063522884033\n",
      "train loss:0.03109630479814141\n",
      "train loss:0.027171788177814835\n",
      "train loss:0.051666005769476185\n",
      "train loss:0.017927852876180393\n",
      "train loss:0.009873031799978943\n",
      "train loss:0.007911649011389547\n",
      "train loss:0.028386369927574494\n",
      "train loss:0.013305292394458657\n",
      "train loss:0.008594006676676934\n",
      "train loss:0.0540434038980069\n",
      "train loss:0.10948706899713204\n",
      "train loss:0.011016579553872561\n",
      "train loss:0.011157191348613626\n",
      "train loss:0.012080063565933809\n",
      "train loss:0.011755414608725635\n",
      "train loss:0.02302904268249406\n",
      "train loss:0.01704289196691122\n",
      "train loss:0.059550080365824556\n",
      "train loss:0.04708897745498281\n",
      "train loss:0.02013199126027357\n",
      "train loss:0.02608306686004756\n",
      "train loss:0.0100150777934386\n",
      "train loss:0.013313471023673484\n",
      "train loss:0.03494657425529947\n",
      "train loss:0.01099216052259641\n",
      "train loss:0.01599975393840341\n",
      "train loss:0.141300402905001\n",
      "train loss:0.013289799003170845\n",
      "train loss:0.032710077041021475\n",
      "train loss:0.04835540314092941\n",
      "train loss:0.029031358451952344\n",
      "train loss:0.08650380657207034\n",
      "train loss:0.05699678243286946\n",
      "train loss:0.011552891817687117\n",
      "train loss:0.019239252936795605\n",
      "train loss:0.025830088375993702\n",
      "train loss:0.019140794016318366\n",
      "train loss:0.012698889483898008\n",
      "train loss:0.011771686617034207\n",
      "train loss:0.008533023516834598\n",
      "train loss:0.012902231614688713\n",
      "train loss:0.0059405279392314245\n",
      "train loss:0.01617198187771612\n",
      "train loss:0.02128293851201862\n",
      "train loss:0.00842308448740283\n",
      "train loss:0.01219555336520213\n",
      "train loss:0.00801078956381603\n",
      "train loss:0.03157487152750512\n",
      "train loss:0.0046004210775054555\n",
      "train loss:0.00513169014079894\n",
      "train loss:0.044480625834409926\n",
      "train loss:0.02773786479011141\n",
      "train loss:0.07060581624363524\n",
      "train loss:0.041872174873371165\n",
      "train loss:0.016354997219959796\n",
      "train loss:0.01183764704571507\n",
      "train loss:0.020517080578487626\n",
      "train loss:0.014681717626509255\n",
      "train loss:0.0171834043064735\n",
      "train loss:0.014273689761938758\n",
      "train loss:0.012311260133451837\n",
      "train loss:0.020979871795494577\n",
      "train loss:0.01657222000933895\n",
      "train loss:0.03057025487482928\n",
      "train loss:0.01012283504980329\n",
      "train loss:0.04970479182774979\n",
      "train loss:0.010152090878098293\n",
      "train loss:0.011001876714498694\n",
      "train loss:0.015256028339101651\n",
      "train loss:0.016907445312455874\n",
      "train loss:0.032362393547002134\n",
      "train loss:0.004189381599050968\n",
      "train loss:0.015519337828359762\n",
      "train loss:0.056708544862348165\n",
      "train loss:0.015631995527093275\n",
      "train loss:0.014591017548970287\n",
      "train loss:0.04346897066968568\n",
      "train loss:0.014282740634218971\n",
      "train loss:0.06449300242461004\n",
      "train loss:0.0494890339028895\n",
      "train loss:0.0067391816369979695\n",
      "train loss:0.009194604773775062\n",
      "train loss:0.02090142853449863\n",
      "train loss:0.01512025360654666\n",
      "train loss:0.015543917098449293\n",
      "train loss:0.024466329236864936\n",
      "train loss:0.016621474318607263\n",
      "train loss:0.01421784934193749\n",
      "train loss:0.08625577769572654\n",
      "train loss:0.03159769740460399\n",
      "train loss:0.01165550174808945\n",
      "train loss:0.04228304202134537\n",
      "train loss:0.043883934106855246\n",
      "train loss:0.032481472327024086\n",
      "train loss:0.11196764500010298\n",
      "train loss:0.06827251417503404\n",
      "train loss:0.019189204199655682\n",
      "train loss:0.004879108634155694\n",
      "train loss:0.047137931116451696\n",
      "train loss:0.16717011967978454\n",
      "train loss:0.03198623101726132\n",
      "train loss:0.01693834967942324\n",
      "train loss:0.035953947019822574\n",
      "train loss:0.017000376423887572\n",
      "train loss:0.0230451615010193\n",
      "train loss:0.036693576355545515\n",
      "train loss:0.0385444833466723\n",
      "train loss:0.004718567516879746\n",
      "train loss:0.016912361587229127\n",
      "train loss:0.10362495988466684\n",
      "train loss:0.003323406535186123\n",
      "train loss:0.008757621845051097\n",
      "train loss:0.03473310996759006\n",
      "train loss:0.018351343072741947\n",
      "train loss:0.03527259948291691\n",
      "train loss:0.04517517827468109\n",
      "train loss:0.011551124647098909\n",
      "train loss:0.012332811887095244\n",
      "train loss:0.06211800330511596\n",
      "train loss:0.009714181948391132\n",
      "train loss:0.021864821583254777\n",
      "train loss:0.005120650241825655\n",
      "train loss:0.009951950413508645\n",
      "train loss:0.02314128179949817\n",
      "train loss:0.039072344138708213\n",
      "train loss:0.02850611293577164\n",
      "train loss:0.02958059648095928\n",
      "train loss:0.0031135406072180264\n",
      "train loss:0.005967445918184521\n",
      "train loss:0.008499823883930948\n",
      "train loss:0.012981996192092464\n",
      "train loss:0.02566200450597111\n",
      "train loss:0.01709847416855352\n",
      "train loss:0.006548292606452781\n",
      "train loss:0.02303442323865347\n",
      "train loss:0.02982330649023671\n",
      "train loss:0.0324546629273708\n",
      "train loss:0.17116724342676912\n",
      "train loss:0.007209404720380991\n",
      "train loss:0.009713438404146407\n",
      "train loss:0.02081135238350236\n",
      "train loss:0.013812063121608835\n",
      "train loss:0.06976066311582513\n",
      "train loss:0.010558234877096468\n",
      "train loss:0.015871433190807333\n",
      "train loss:0.06074305406773092\n",
      "train loss:0.04961791737396919\n",
      "train loss:0.004474412474098731\n",
      "train loss:0.04204300328399678\n",
      "train loss:0.015795141180991016\n",
      "train loss:0.05846586325272221\n",
      "train loss:0.00395863187404477\n",
      "train loss:0.03840383312951061\n",
      "train loss:0.016647248245734776\n",
      "train loss:0.05179315757360094\n",
      "train loss:0.02349387375204562\n",
      "train loss:0.017528823490330036\n",
      "train loss:0.005557618073269631\n",
      "train loss:0.012051754047566327\n",
      "train loss:0.015063360593344404\n",
      "train loss:0.005538655471541754\n",
      "train loss:0.01008513735742485\n",
      "train loss:0.013035897879549167\n",
      "train loss:0.013863446537633588\n",
      "train loss:0.015366297536606096\n",
      "train loss:0.01936551699132745\n",
      "train loss:0.01599205266369958\n",
      "train loss:0.008682665885385504\n",
      "train loss:0.03015936723132467\n",
      "train loss:0.012242030346489043\n",
      "train loss:0.027308612188286664\n",
      "train loss:0.011213166581934456\n",
      "train loss:0.009518010411230165\n",
      "train loss:0.01919552068033265\n",
      "train loss:0.01640306166249642\n",
      "train loss:0.04401833541906326\n",
      "train loss:0.010786966052515118\n",
      "train loss:0.0072252909814491326\n",
      "train loss:0.016956407948933105\n",
      "train loss:0.009185540028216421\n",
      "train loss:0.0159194937651153\n",
      "train loss:0.016123045334740415\n",
      "train loss:0.014906338579963494\n",
      "train loss:0.025325057538464125\n",
      "train loss:0.021088821474418977\n",
      "train loss:0.033139547352029924\n",
      "train loss:0.030887769132797588\n",
      "train loss:0.054522663253493746\n",
      "train loss:0.01563907222558821\n",
      "train loss:0.05405091347187143\n",
      "train loss:0.009224253754066268\n",
      "train loss:0.023318569573801788\n",
      "train loss:0.03947423413460948\n",
      "train loss:0.014837906765903314\n",
      "train loss:0.07321269357223284\n",
      "train loss:0.06310716309468582\n",
      "train loss:0.008699176401368391\n",
      "train loss:0.0217625476554399\n",
      "train loss:0.01609586305589708\n",
      "train loss:0.037182604997202245\n",
      "train loss:0.024949563629306323\n",
      "train loss:0.008897604238230793\n",
      "train loss:0.018203622982877702\n",
      "train loss:0.021001361724622747\n",
      "train loss:0.010651526769804399\n",
      "train loss:0.010663113767182047\n",
      "train loss:0.016297721717998252\n",
      "train loss:0.020027466257868082\n",
      "train loss:0.008138395177264713\n",
      "train loss:0.016059671867297273\n",
      "train loss:0.012704161424744393\n",
      "train loss:0.01814571105113238\n",
      "train loss:0.04684560400985229\n",
      "train loss:0.00400200726877983\n",
      "train loss:0.02495372428979057\n",
      "train loss:0.020015230540420578\n",
      "train loss:0.016808390568152972\n",
      "train loss:0.009381276114213848\n",
      "train loss:0.035464082493831726\n",
      "train loss:0.009430827012423808\n",
      "train loss:0.066027941702503\n",
      "train loss:0.039963378759698215\n",
      "train loss:0.013095203310333594\n",
      "train loss:0.030370551458834584\n",
      "train loss:0.00827498317745376\n",
      "train loss:0.021217507386549827\n",
      "train loss:0.02266807513689542\n",
      "train loss:0.0525333460905846\n",
      "train loss:0.04176862350769753\n",
      "train loss:0.027947550144388024\n",
      "train loss:0.005313610437019579\n",
      "train loss:0.012340723438939289\n",
      "train loss:0.12432217625428174\n",
      "train loss:0.004403112290241877\n",
      "train loss:0.018177065698156938\n",
      "train loss:0.00868496068936089\n",
      "train loss:0.002074987503114515\n",
      "train loss:0.056572526277034664\n",
      "train loss:0.008467428019305858\n",
      "train loss:0.02496034385708608\n",
      "train loss:0.013952264902557935\n",
      "train loss:0.005621415172561435\n",
      "train loss:0.007921906624543493\n",
      "train loss:0.03352750158967235\n",
      "train loss:0.01038398755797598\n",
      "train loss:0.009737104050467902\n",
      "train loss:0.0912118470624836\n",
      "train loss:0.0036817431061723386\n",
      "train loss:0.05825196385098952\n",
      "train loss:0.02429398820060362\n",
      "train loss:0.016021092287115176\n",
      "train loss:0.012263331480470187\n",
      "train loss:0.022339818858832038\n",
      "train loss:0.01965433579527216\n",
      "train loss:0.011627655710579261\n",
      "train loss:0.015061158922787058\n",
      "train loss:0.05765622972162641\n",
      "train loss:0.0468574308126988\n",
      "train loss:0.025660186797244286\n",
      "train loss:0.0050705299687741935\n",
      "train loss:0.008601830794443795\n",
      "train loss:0.026179682588726688\n",
      "train loss:0.03698133679283663\n",
      "train loss:0.00915623455342998\n",
      "train loss:0.037114564097295355\n",
      "train loss:0.011514891300596726\n",
      "train loss:0.014500384768565576\n",
      "train loss:0.05950057401843086\n",
      "train loss:0.012706418549458798\n",
      "train loss:0.007150594352858086\n",
      "train loss:0.09660478782616888\n",
      "train loss:0.0061723087525131495\n",
      "train loss:0.02669721944714952\n",
      "train loss:0.008408131983740857\n",
      "train loss:0.01134257060381772\n",
      "train loss:0.009488878718995208\n",
      "train loss:0.026213395699170028\n",
      "train loss:0.016616574925650763\n",
      "train loss:0.01296068450526059\n",
      "train loss:0.02909054179305666\n",
      "train loss:0.0038260752867210496\n",
      "train loss:0.0035860389434929653\n",
      "train loss:0.013646683980008224\n",
      "train loss:0.015004900633804752\n",
      "train loss:0.014533237613125645\n",
      "train loss:0.010131571673730608\n",
      "train loss:0.07383176762006614\n",
      "train loss:0.01055412160261063\n",
      "train loss:0.06878132159096367\n",
      "train loss:0.038827771775527944\n",
      "train loss:0.018758113051154473\n",
      "train loss:0.08175716182862403\n",
      "train loss:0.044222552699511815\n",
      "train loss:0.02822662897141556\n",
      "train loss:0.006469780392215903\n",
      "train loss:0.011472116767047114\n",
      "train loss:0.021667115373412614\n",
      "train loss:0.02521105843396517\n",
      "train loss:0.00839131893941589\n",
      "train loss:0.02031385220846922\n",
      "train loss:0.03328597020961343\n",
      "train loss:0.011560310616556786\n",
      "train loss:0.0289680527741369\n",
      "train loss:0.049801619152721674\n",
      "train loss:0.005292356001249851\n",
      "train loss:0.013581470205080593\n",
      "train loss:0.01896501065350746\n",
      "train loss:0.0489901192079202\n",
      "train loss:0.031150916550428634\n",
      "train loss:0.05221306060656779\n",
      "train loss:0.019680161598318507\n",
      "train loss:0.009097926222475605\n",
      "train loss:0.011574287418068216\n",
      "train loss:0.008608994630936067\n",
      "train loss:0.04531323730369756\n",
      "train loss:0.040975153829968324\n",
      "train loss:0.015825503476722517\n",
      "train loss:0.06296195291101297\n",
      "train loss:0.04573093636561645\n",
      "train loss:0.009768209109359428\n",
      "train loss:0.012733138355560954\n",
      "train loss:0.02193470545846174\n",
      "train loss:0.01590955447973509\n",
      "train loss:0.04954306604610635\n",
      "train loss:0.04887305812915208\n",
      "train loss:0.04760263518942869\n",
      "train loss:0.0899344103956403\n",
      "train loss:0.007307088945227133\n",
      "train loss:0.004848059206933905\n",
      "train loss:0.029619827975780735\n",
      "train loss:0.03717848205878245\n",
      "train loss:0.05036076466900066\n",
      "train loss:0.017874242082253026\n",
      "train loss:0.009812071515531554\n",
      "train loss:0.03725512113179283\n",
      "train loss:0.004533643780976666\n",
      "train loss:0.011634167704780924\n",
      "train loss:0.024685362665146107\n",
      "train loss:0.041785795451092976\n",
      "train loss:0.017679478223630113\n",
      "train loss:0.023514453232072848\n",
      "train loss:0.006534424376333928\n",
      "train loss:0.017829953494078406\n",
      "train loss:0.002850028743760141\n",
      "train loss:0.01574360045051509\n",
      "train loss:0.10968927687778886\n",
      "train loss:0.00564038342768983\n",
      "train loss:0.011045695527552482\n",
      "train loss:0.028743949353012138\n",
      "train loss:0.03799413531708678\n",
      "train loss:0.04713160043855515\n",
      "train loss:0.012572301619958995\n",
      "train loss:0.025547426930836094\n",
      "train loss:0.02495237139374967\n",
      "train loss:0.014521831588133355\n",
      "train loss:0.016766634550016025\n",
      "train loss:0.030245023057197954\n",
      "train loss:0.021662034987491186\n",
      "train loss:0.0052680378654215865\n",
      "train loss:0.042612480514151535\n",
      "train loss:0.0036958699267303297\n",
      "train loss:0.0083364123424337\n",
      "train loss:0.006952731465218055\n",
      "train loss:0.02157205367087035\n",
      "train loss:0.017451499320917697\n",
      "train loss:0.007573461145872275\n",
      "train loss:0.01321723830883858\n",
      "train loss:0.00826111648864936\n",
      "train loss:0.02252238131515214\n",
      "train loss:0.01935418778106883\n",
      "train loss:0.01880753391200408\n",
      "train loss:0.026889698542665003\n",
      "train loss:0.029747499412866637\n",
      "train loss:0.003877434819027256\n",
      "train loss:0.02221772159629459\n",
      "train loss:0.057535100416463036\n",
      "train loss:0.0015585616042399961\n",
      "train loss:0.01919513167146087\n",
      "train loss:0.010812991961186411\n",
      "train loss:0.005974535847326046\n",
      "train loss:0.00513098535066619\n",
      "train loss:0.003151818956533841\n",
      "train loss:0.003855150199819169\n",
      "train loss:0.007605517473120168\n",
      "train loss:0.00619562450535025\n",
      "train loss:0.030965905292787133\n",
      "train loss:0.1719587883221524\n",
      "train loss:0.0875555985067162\n",
      "train loss:0.039435884908100564\n",
      "train loss:0.007296894087889784\n",
      "train loss:0.04185348689591199\n",
      "train loss:0.008711793713312089\n",
      "train loss:0.036124621738699327\n",
      "train loss:0.015206351608259167\n",
      "train loss:0.01853787438045582\n",
      "train loss:0.029284141606195746\n",
      "train loss:0.005236825225014829\n",
      "train loss:0.07312839004585549\n",
      "train loss:0.026284275527541583\n",
      "train loss:0.06044831432918832\n",
      "train loss:0.006632272174715716\n",
      "train loss:0.06558192528429255\n",
      "train loss:0.011668484052634544\n",
      "train loss:0.014250131554642227\n",
      "train loss:0.013767819355824794\n",
      "train loss:0.04121880484325077\n",
      "train loss:0.03772435871333712\n",
      "train loss:0.019598225021107318\n",
      "train loss:0.014642957785365476\n",
      "train loss:0.005534867846841009\n",
      "train loss:0.01514678376784196\n",
      "train loss:0.02039537692134205\n",
      "train loss:0.01666123474074883\n",
      "train loss:0.015005181825590354\n",
      "train loss:0.04249498996183272\n",
      "train loss:0.020533125904884333\n",
      "train loss:0.015053742199302233\n",
      "train loss:0.009376569556608476\n",
      "train loss:0.052633807086343916\n",
      "train loss:0.14679888666968843\n",
      "train loss:0.03283933681873686\n",
      "train loss:0.0034126469931422755\n",
      "train loss:0.03567629033946655\n",
      "train loss:0.02200095316213261\n",
      "train loss:0.032465847044949855\n",
      "train loss:0.019881017076342832\n",
      "train loss:0.10997411506559575\n",
      "train loss:0.014493514615110665\n",
      "train loss:0.01476759935563142\n",
      "train loss:0.007115005367865037\n",
      "train loss:0.008213110847626959\n",
      "train loss:0.06512382232492415\n",
      "=== epoch:6, train acc:0.988, test acc:0.985 ===\n",
      "train loss:0.03914729285307254\n",
      "train loss:0.015566395227353156\n",
      "train loss:0.022562526763941836\n",
      "train loss:0.003383537541528495\n",
      "train loss:0.007219023673525109\n",
      "train loss:0.03768767212332765\n",
      "train loss:0.05857293155237318\n",
      "train loss:0.01976628355343756\n",
      "train loss:0.04955047980539674\n",
      "train loss:0.017482566862097454\n",
      "train loss:0.021695645485920803\n",
      "train loss:0.03167562284825252\n",
      "train loss:0.03693000389076498\n",
      "train loss:0.006634930072174616\n",
      "train loss:0.00487992338423101\n",
      "train loss:0.008513693095168364\n",
      "train loss:0.04869182258164427\n",
      "train loss:0.0221000676107499\n",
      "train loss:0.0055491461793212085\n",
      "train loss:0.03220588431758378\n",
      "train loss:0.045847866339666546\n",
      "train loss:0.011377195575023117\n",
      "train loss:0.15858754902200725\n",
      "train loss:0.03423918136240552\n",
      "train loss:0.022615128733483543\n",
      "train loss:0.018700084153223617\n",
      "train loss:0.06060860046102807\n",
      "train loss:0.052607944593097755\n",
      "train loss:0.008491196967105936\n",
      "train loss:0.007900821464156955\n",
      "train loss:0.04180016314806516\n",
      "train loss:0.03461686879682699\n",
      "train loss:0.007881722537473638\n",
      "train loss:0.010643570299670889\n",
      "train loss:0.030804754394810806\n",
      "train loss:0.02403852400889856\n",
      "train loss:0.015847329930888294\n",
      "train loss:0.027839368210630787\n",
      "train loss:0.013512866174650237\n",
      "train loss:0.012632774435383791\n",
      "train loss:0.017876829864048222\n",
      "train loss:0.02590510001355826\n",
      "train loss:0.01504669085138409\n",
      "train loss:0.010235692669639931\n",
      "train loss:0.043355013370455164\n",
      "train loss:0.009090753450475934\n",
      "train loss:0.022750100465469544\n",
      "train loss:0.012169487593642165\n",
      "train loss:0.0960829011244324\n",
      "train loss:0.009437978731759729\n",
      "train loss:0.0062056099649224475\n",
      "train loss:0.0344517037626\n",
      "train loss:0.03225256134617597\n",
      "train loss:0.031468873315402456\n",
      "train loss:0.020490039740087455\n",
      "train loss:0.011301197648918576\n",
      "train loss:0.05412450815829135\n",
      "train loss:0.018189437988863643\n",
      "train loss:0.023050743156067036\n",
      "train loss:0.014507397018601638\n",
      "train loss:0.01935253118564959\n",
      "train loss:0.008711212182599131\n",
      "train loss:0.019413886967593413\n",
      "train loss:0.010386470918619056\n",
      "train loss:0.009645965331897965\n",
      "train loss:0.019073247482995007\n",
      "train loss:0.027467839213532505\n",
      "train loss:0.007045219263649332\n",
      "train loss:0.0034061780217151238\n",
      "train loss:0.02003721945199412\n",
      "train loss:0.004248507591603458\n",
      "train loss:0.0841691532844868\n",
      "train loss:0.05199663299678377\n",
      "train loss:0.012356744320053006\n",
      "train loss:0.007852493432952287\n",
      "train loss:0.016554891363412226\n",
      "train loss:0.1574863788889795\n",
      "train loss:0.024070372150765917\n",
      "train loss:0.037646187172995234\n",
      "train loss:0.06272378390203664\n",
      "train loss:0.020394026222522267\n",
      "train loss:0.0053088015897606875\n",
      "train loss:0.02012711385744788\n",
      "train loss:0.0017945599310930276\n",
      "train loss:0.01657696521089084\n",
      "train loss:0.037547087929244445\n",
      "train loss:0.016241456085339594\n",
      "train loss:0.006097340099681318\n",
      "train loss:0.0026968770180847853\n",
      "train loss:0.0157926109446163\n",
      "train loss:0.050820697864093836\n",
      "train loss:0.08209390370746185\n",
      "train loss:0.015379556298111838\n",
      "train loss:0.056878208000584865\n",
      "train loss:0.014983102155914925\n",
      "train loss:0.06719184214169724\n",
      "train loss:0.020768671573367422\n",
      "train loss:0.016499291499238074\n",
      "train loss:0.040934455336067\n",
      "train loss:0.06398038539928147\n",
      "train loss:0.023602384107851645\n",
      "train loss:0.01676650707120653\n",
      "train loss:0.021976628821475865\n",
      "train loss:0.011411169064454251\n",
      "train loss:0.10344258091614364\n",
      "train loss:0.007874342229385713\n",
      "train loss:0.015929876365430234\n",
      "train loss:0.008384832084985782\n",
      "train loss:0.008277710818892527\n",
      "train loss:0.005326454884668033\n",
      "train loss:0.011633257994629767\n",
      "train loss:0.01160422999945392\n",
      "train loss:0.03962839286486636\n",
      "train loss:0.035664463131511684\n",
      "train loss:0.017814958433088807\n",
      "train loss:0.03808290605763693\n",
      "train loss:0.014599507607608343\n",
      "train loss:0.021853411226994073\n",
      "train loss:0.014612174231607815\n",
      "train loss:0.0033566793412181063\n",
      "train loss:0.01967724255549111\n",
      "train loss:0.01873735384126926\n",
      "train loss:0.004830596139201253\n",
      "train loss:0.011794720746743195\n",
      "train loss:0.0028120018037776228\n",
      "train loss:0.0151668907701139\n",
      "train loss:0.009077820233303493\n",
      "train loss:0.010632960682780744\n",
      "train loss:0.013347111922012095\n",
      "train loss:0.007378415300597966\n",
      "train loss:0.016150082954156528\n",
      "train loss:0.017297867079621523\n",
      "train loss:0.006661813041738747\n",
      "train loss:0.05929238528024955\n",
      "train loss:0.011228032366174444\n",
      "train loss:0.010794193717758265\n",
      "train loss:0.003878962270544065\n",
      "train loss:0.0027472994675533406\n",
      "train loss:0.016948088187662975\n",
      "train loss:0.005013625843463598\n",
      "train loss:0.023527978643235966\n",
      "train loss:0.004975826739401847\n",
      "train loss:0.0270249013455463\n",
      "train loss:0.04720427239491356\n",
      "train loss:0.0610424828711464\n",
      "train loss:0.02049445476990129\n",
      "train loss:0.007410763449101573\n",
      "train loss:0.03167258113128278\n",
      "train loss:0.01340691542957548\n",
      "train loss:0.00630587387756961\n",
      "train loss:0.008196694116599824\n",
      "train loss:0.017099436634551535\n",
      "train loss:0.006765751022983133\n",
      "train loss:0.009745687096462187\n",
      "train loss:0.027275265003017964\n",
      "train loss:0.011157925780685347\n",
      "train loss:0.00491343084082442\n",
      "train loss:0.00567996375160796\n",
      "train loss:0.04548303527363275\n",
      "train loss:0.041910455350586906\n",
      "train loss:0.005650127100609747\n",
      "train loss:0.01764202582893788\n",
      "train loss:0.013818341027311068\n",
      "train loss:0.020203472247519\n",
      "train loss:0.01414772744129581\n",
      "train loss:0.005316958247287071\n",
      "train loss:0.04741196176864094\n",
      "train loss:0.003240227870665393\n",
      "train loss:0.018430589031422952\n",
      "train loss:0.011637413463803006\n",
      "train loss:0.009790327157283103\n",
      "train loss:0.003780315582534955\n",
      "train loss:0.020380930462714476\n",
      "train loss:0.01696197011446339\n",
      "train loss:0.007806525420119472\n",
      "train loss:0.006193170544253741\n",
      "train loss:0.013728368357343017\n",
      "train loss:0.006293578681797851\n",
      "train loss:0.021068042092237435\n",
      "train loss:0.005467990605895967\n",
      "train loss:0.02510692014330429\n",
      "train loss:0.01043389071442448\n",
      "train loss:0.004719568108960517\n",
      "train loss:0.0059939073416699325\n",
      "train loss:0.024414589625041318\n",
      "train loss:0.00831892058940385\n",
      "train loss:0.0029269455884999985\n",
      "train loss:0.1065804521459136\n",
      "train loss:0.019619546147212688\n",
      "train loss:0.0033282510230934793\n",
      "train loss:0.013520454277749847\n",
      "train loss:0.04394413964725987\n",
      "train loss:0.007353219784837709\n",
      "train loss:0.012374812964859873\n",
      "train loss:0.00973731768386003\n",
      "train loss:0.01027624578702925\n",
      "train loss:0.0035840579405714344\n",
      "train loss:0.011631671276588424\n",
      "train loss:0.019801331171929164\n",
      "train loss:0.01258294652626466\n",
      "train loss:0.00970761151187542\n",
      "train loss:0.0128445141740842\n",
      "train loss:0.07111963626160946\n",
      "train loss:0.005377270225078351\n",
      "train loss:0.03349302185441775\n",
      "train loss:0.005569318845132885\n",
      "train loss:0.06573080971313487\n",
      "train loss:0.006520244107504498\n",
      "train loss:0.03361646833071026\n",
      "train loss:0.012716730169267158\n",
      "train loss:0.03232415383831901\n",
      "train loss:0.011324912327109027\n",
      "train loss:0.06208675171805408\n",
      "train loss:0.007690797103969208\n",
      "train loss:0.005463083729160817\n",
      "train loss:0.003809438332461372\n",
      "train loss:0.009901350915154518\n",
      "train loss:0.00392081388133903\n",
      "train loss:0.05254766255873077\n",
      "train loss:0.008531027949569234\n",
      "train loss:0.03916069057142317\n",
      "train loss:0.013032051002666158\n",
      "train loss:0.024401296274728482\n",
      "train loss:0.0030802029596821495\n",
      "train loss:0.04033316651902992\n",
      "train loss:0.011784915403647466\n",
      "train loss:0.049850755405016864\n",
      "train loss:0.004704267480570187\n",
      "train loss:0.011924280379129048\n",
      "train loss:0.00854912041238607\n",
      "train loss:0.00387877595251444\n",
      "train loss:0.035394512001589745\n",
      "train loss:0.05143158007050423\n",
      "train loss:0.01833430843371273\n",
      "train loss:0.01862922766339149\n",
      "train loss:0.013085015641078685\n",
      "train loss:0.08497803290419531\n",
      "train loss:0.008154832453646595\n",
      "train loss:0.0048239822713244266\n",
      "train loss:0.00997464052596988\n",
      "train loss:0.0497980604346542\n",
      "train loss:0.007480443436561029\n",
      "train loss:0.01053585101748427\n",
      "train loss:0.006310666354526128\n",
      "train loss:0.01630941330311177\n",
      "train loss:0.03253433651622156\n",
      "train loss:0.010609502388984107\n",
      "train loss:0.052493923129252267\n",
      "train loss:0.008543347395444207\n",
      "train loss:0.00937697326182969\n",
      "train loss:0.004266933869236928\n",
      "train loss:0.00703247270153129\n",
      "train loss:0.009543363533882363\n",
      "train loss:0.006848324063542943\n",
      "train loss:0.011177334029722867\n",
      "train loss:0.0017294782001006195\n",
      "train loss:0.0502108023469876\n",
      "train loss:0.03525444434282988\n",
      "train loss:0.03512080527497386\n",
      "train loss:0.02958228879273116\n",
      "train loss:0.0026923756523363944\n",
      "train loss:0.032299397774085414\n",
      "train loss:0.037237960587353416\n",
      "train loss:0.022406604446720647\n",
      "train loss:0.04434637268403499\n",
      "train loss:0.010978037464054891\n",
      "train loss:0.041918987135560616\n",
      "train loss:0.03232840575970437\n",
      "train loss:0.017667689196542415\n",
      "train loss:0.03366398585272293\n",
      "train loss:0.01249527825646399\n",
      "train loss:0.037243636897597014\n",
      "train loss:0.06542871446109084\n",
      "train loss:0.014517900869189047\n",
      "train loss:0.029970994515685745\n",
      "train loss:0.021548378680985376\n",
      "train loss:0.008801331759918006\n",
      "train loss:0.013511145530059089\n",
      "train loss:0.015513268652656531\n",
      "train loss:0.016998403449678047\n",
      "train loss:0.013540234302203136\n",
      "train loss:0.022099573713510175\n",
      "train loss:0.003097965069462522\n",
      "train loss:0.010254550345879158\n",
      "train loss:0.0052894450376998955\n",
      "train loss:0.02044620695380168\n",
      "train loss:0.008101056065467897\n",
      "train loss:0.004676201723836242\n",
      "train loss:0.007182131827535839\n",
      "train loss:0.00942042616368983\n",
      "train loss:0.031046285125723046\n",
      "train loss:0.0173013601589278\n",
      "train loss:0.0324673011567105\n",
      "train loss:0.005910830496106218\n",
      "train loss:0.006264716371403589\n",
      "train loss:0.060618403847089934\n",
      "train loss:0.02072865599737994\n",
      "train loss:0.006012230201671972\n",
      "train loss:0.01547778161655567\n",
      "train loss:0.05737064041573522\n",
      "train loss:0.010736373399057204\n",
      "train loss:0.010707843984678174\n",
      "train loss:0.03751474608477204\n",
      "train loss:0.026929415977091243\n",
      "train loss:0.03482878403355366\n",
      "train loss:0.009795283795556078\n",
      "train loss:0.05294427942988226\n",
      "train loss:0.009534897572531419\n",
      "train loss:0.0021078712880625\n",
      "train loss:0.006904847565611847\n",
      "train loss:0.005335184959957994\n",
      "train loss:0.2052573631649876\n",
      "train loss:0.02901726890289082\n",
      "train loss:0.01127323741654359\n",
      "train loss:0.005974713041948486\n",
      "train loss:0.006651887359461634\n",
      "train loss:0.007761005102813281\n",
      "train loss:0.006554527820423853\n",
      "train loss:0.012371584298349407\n",
      "train loss:0.028877094292754125\n",
      "train loss:0.008158679319147497\n",
      "train loss:0.0018602093893976721\n",
      "train loss:0.03234252464683124\n",
      "train loss:0.007047042323440451\n",
      "train loss:0.013607066046950809\n",
      "train loss:0.06417160944553361\n",
      "train loss:0.025095527164772934\n",
      "train loss:0.05805486699720444\n",
      "train loss:0.013125754964820184\n",
      "train loss:0.010396429270910059\n",
      "train loss:0.01792777246872977\n",
      "train loss:0.006033233118485473\n",
      "train loss:0.002476451681396232\n",
      "train loss:0.00837684362895264\n",
      "train loss:0.010651427569655076\n",
      "train loss:0.018448159556383962\n",
      "train loss:0.008030376068566089\n",
      "train loss:0.017018002786644913\n",
      "train loss:0.008564743597960592\n",
      "train loss:0.01113656024030451\n",
      "train loss:0.029613810514746444\n",
      "train loss:0.004552654214333379\n",
      "train loss:0.0053146701988922565\n",
      "train loss:0.031663807108407965\n",
      "train loss:0.007185275831094814\n",
      "train loss:0.05502331972535443\n",
      "train loss:0.011116362330289929\n",
      "train loss:0.011355689400403624\n",
      "train loss:0.004700015425998678\n",
      "train loss:0.015327467163096303\n",
      "train loss:0.029955435429881376\n",
      "train loss:0.005163401455000786\n",
      "train loss:0.012397219383259979\n",
      "train loss:0.030879574359892952\n",
      "train loss:0.08458466630790624\n",
      "train loss:0.06871686126018246\n",
      "train loss:0.0048026418027650765\n",
      "train loss:0.011381608531153558\n",
      "train loss:0.02139402873669078\n",
      "train loss:0.0034218071412851873\n",
      "train loss:0.004306967078164758\n",
      "train loss:0.05555288673619173\n",
      "train loss:0.003391290261383404\n",
      "train loss:0.019373758671225746\n",
      "train loss:0.004018443055159611\n",
      "train loss:0.05267143391290223\n",
      "train loss:0.032383827387380125\n",
      "train loss:0.0046826040445658\n",
      "train loss:0.011125764461230172\n",
      "train loss:0.01179482866317023\n",
      "train loss:0.024597452048328704\n",
      "train loss:0.07072661725652708\n",
      "train loss:0.026955784523612438\n",
      "train loss:0.006910834494477265\n",
      "train loss:0.043842680797534006\n",
      "train loss:0.01398933745801595\n",
      "train loss:0.04926159513617891\n",
      "train loss:0.0057283647814973535\n",
      "train loss:0.013388515003476882\n",
      "train loss:0.008551618095063851\n",
      "train loss:0.001896200894700137\n",
      "train loss:0.04371865472438295\n",
      "train loss:0.005610238594126836\n",
      "train loss:0.023443854524573253\n",
      "train loss:0.005956212955295261\n",
      "train loss:0.005679532870220338\n",
      "train loss:0.014836434319169652\n",
      "train loss:0.016854288794205762\n",
      "train loss:0.016763898143450928\n",
      "train loss:0.010470808063910682\n",
      "train loss:0.003923555918074984\n",
      "train loss:0.0035668090230332582\n",
      "train loss:0.025525031667765243\n",
      "train loss:0.003940208436051258\n",
      "train loss:0.03302768054757017\n",
      "train loss:0.016892809950878083\n",
      "train loss:0.011522878669368929\n",
      "train loss:0.0701649352491611\n",
      "train loss:0.026697894997777125\n",
      "train loss:0.018026240110160206\n",
      "train loss:0.004324792022545685\n",
      "train loss:0.03279206874952166\n",
      "train loss:0.009492071631005733\n",
      "train loss:0.02384524806801953\n",
      "train loss:0.02526125950335771\n",
      "train loss:0.006742620101152103\n",
      "train loss:0.008201598435356346\n",
      "train loss:0.009412339895308553\n",
      "train loss:0.020041814860382732\n",
      "train loss:0.045622326684219214\n",
      "train loss:0.008536779320475207\n",
      "train loss:0.005916214421832022\n",
      "train loss:0.008130682043732908\n",
      "train loss:0.014743657431206158\n",
      "train loss:0.004802337725462191\n",
      "train loss:0.029116627370874316\n",
      "train loss:0.06010249846692267\n",
      "train loss:0.03327582097211508\n",
      "train loss:0.030608432660441717\n",
      "train loss:0.06547051767711155\n",
      "train loss:0.013880674900690402\n",
      "train loss:0.005601792996333971\n",
      "train loss:0.049974627434845854\n",
      "train loss:0.004368140907507065\n",
      "train loss:0.00201403251017374\n",
      "train loss:0.07114390958540895\n",
      "train loss:0.025273380113289737\n",
      "train loss:0.007840029627815479\n",
      "train loss:0.0031308432016701492\n",
      "train loss:0.04601435757313798\n",
      "train loss:0.020591809948362058\n",
      "train loss:0.06955632229039976\n",
      "train loss:0.013544639113335206\n",
      "train loss:0.048307836604243766\n",
      "train loss:0.0061004835347170374\n",
      "train loss:0.004917159921878736\n",
      "train loss:0.010684316680443258\n",
      "train loss:0.006586597318417138\n",
      "train loss:0.00467784121555464\n",
      "train loss:0.05668968995440344\n",
      "train loss:0.02746266876666519\n",
      "train loss:0.047378373525350195\n",
      "train loss:0.013148144260990615\n",
      "train loss:0.006224009912995831\n",
      "train loss:0.034205454912762855\n",
      "train loss:0.016995632922159835\n",
      "train loss:0.004479779410989008\n",
      "train loss:0.024227755909458484\n",
      "train loss:0.01555627454391664\n",
      "train loss:0.006858850271367623\n",
      "train loss:0.016470646243779516\n",
      "train loss:0.011520213510009463\n",
      "train loss:0.005080141594262549\n",
      "train loss:0.016305074354336323\n",
      "train loss:0.025747364147601304\n",
      "train loss:0.014390838192421825\n",
      "train loss:0.024115929794480233\n",
      "train loss:0.005266823828095244\n",
      "train loss:0.02220169256714763\n",
      "train loss:0.017443418727575086\n",
      "train loss:0.02398437997067342\n",
      "train loss:0.007657083004617138\n",
      "train loss:0.01056452806749194\n",
      "train loss:0.004334471211329172\n",
      "train loss:0.022200178689903295\n",
      "train loss:0.001171665700861878\n",
      "train loss:0.009395632223990629\n",
      "train loss:0.02771823405966719\n",
      "train loss:0.03441849103464126\n",
      "train loss:0.010880737735652459\n",
      "train loss:0.049980182572388926\n",
      "train loss:0.00622395774758636\n",
      "train loss:0.049505939747134284\n",
      "train loss:0.027899163413763226\n",
      "train loss:0.02348666524390131\n",
      "train loss:0.005760504191384963\n",
      "train loss:0.013822902560111996\n",
      "train loss:0.06624660600128245\n",
      "train loss:0.01377193301401558\n",
      "train loss:0.005278277753553566\n",
      "train loss:0.03913432653943449\n",
      "train loss:0.009344490396587572\n",
      "train loss:0.010191574555987373\n",
      "train loss:0.00867011335881193\n",
      "train loss:0.008882386785465385\n",
      "train loss:0.0336212842472912\n",
      "train loss:0.023446293236781036\n",
      "train loss:0.03416678108237492\n",
      "train loss:0.014197004083187461\n",
      "train loss:0.013478835047513087\n",
      "train loss:0.0077533803132904975\n",
      "train loss:0.06290271094054724\n",
      "train loss:0.005537332046473895\n",
      "train loss:0.030073659593321624\n",
      "train loss:0.014595285406873281\n",
      "train loss:0.0522944887245984\n",
      "train loss:0.01177856506801574\n",
      "train loss:0.006710423764341258\n",
      "train loss:0.012700014430084677\n",
      "train loss:0.011299877301178263\n",
      "train loss:0.019515800334503758\n",
      "train loss:0.019328742308000316\n",
      "train loss:0.011145688697519756\n",
      "train loss:0.04993843408273325\n",
      "train loss:0.021544263944193287\n",
      "train loss:0.015299910803068867\n",
      "train loss:0.02529619348155898\n",
      "train loss:0.012462712481610981\n",
      "train loss:0.007365783808769232\n",
      "train loss:0.00532122401662669\n",
      "train loss:0.00492681260326641\n",
      "train loss:0.0607433088741333\n",
      "train loss:0.022552028502355694\n",
      "train loss:0.008533942564644497\n",
      "train loss:0.054045191025526476\n",
      "train loss:0.01386863019188493\n",
      "train loss:0.012601009353818617\n",
      "train loss:0.007160907785609111\n",
      "train loss:0.017995715404284726\n",
      "train loss:0.008555799562096287\n",
      "train loss:0.010949417100831487\n",
      "train loss:0.026301929877897378\n",
      "train loss:0.00841441158713403\n",
      "train loss:0.004737562349837537\n",
      "train loss:0.016525771667107024\n",
      "train loss:0.004839962459757689\n",
      "train loss:0.007834747968571743\n",
      "train loss:0.011067071588249225\n",
      "train loss:0.052132941363357846\n",
      "train loss:0.015491120434033652\n",
      "train loss:0.005714454727596256\n",
      "train loss:0.04581941205544421\n",
      "train loss:0.024465578328939176\n",
      "train loss:0.0024707272204436887\n",
      "train loss:0.013647113106948452\n",
      "train loss:0.02213713549393714\n",
      "train loss:0.0036834886100694563\n",
      "train loss:0.018283045200464542\n",
      "train loss:0.00841387428536281\n",
      "train loss:0.026562990492018813\n",
      "train loss:0.01222100659908439\n",
      "train loss:0.030094184047727075\n",
      "train loss:0.014572534481557257\n",
      "train loss:0.01752769170726477\n",
      "train loss:0.009045496187484302\n",
      "train loss:0.00742361697527997\n",
      "train loss:0.010228151502874611\n",
      "train loss:0.026008497849160737\n",
      "train loss:0.012582073099946639\n",
      "train loss:0.0023850261624844245\n",
      "train loss:0.018217832492257724\n",
      "train loss:0.02395716548327958\n",
      "train loss:0.018506254698305517\n",
      "train loss:0.0017822391093780462\n",
      "train loss:0.0017156544789962173\n",
      "train loss:0.08397816563793895\n",
      "train loss:0.034897369140941416\n",
      "train loss:0.008042510633514265\n",
      "train loss:0.004545890619831402\n",
      "train loss:0.011545395686285985\n",
      "train loss:0.0043065088473538075\n",
      "train loss:0.009496291690400656\n",
      "train loss:0.03565612286579967\n",
      "train loss:0.007433534681788213\n",
      "train loss:0.054115804865877755\n",
      "train loss:0.06544918258976609\n",
      "train loss:0.0024723259923657074\n",
      "train loss:0.010840046619965649\n",
      "train loss:0.001319962079544496\n",
      "train loss:0.004198482666880752\n",
      "train loss:0.022385860119462878\n",
      "train loss:0.026651325460966872\n",
      "train loss:0.006467847680831102\n",
      "train loss:0.021433890605119528\n",
      "train loss:0.013523791253614024\n",
      "train loss:0.00958114480633842\n",
      "train loss:0.021491289600144504\n",
      "train loss:0.004068789161100314\n",
      "train loss:0.0036170988916089945\n",
      "train loss:0.042097510611013945\n",
      "train loss:0.007686316102693621\n",
      "train loss:0.0867866713033823\n",
      "train loss:0.009209193884585161\n",
      "train loss:0.020967270030203048\n",
      "train loss:0.04987060330352252\n",
      "train loss:0.016751632650668164\n",
      "train loss:0.014386879373402682\n",
      "train loss:0.04719778179579878\n",
      "train loss:0.0032811229511720804\n",
      "train loss:0.012342116968329587\n",
      "train loss:0.026859060362802147\n",
      "train loss:0.010336621180836027\n",
      "train loss:0.009514955581745027\n",
      "train loss:0.01117174198858668\n",
      "train loss:0.012496405542755768\n",
      "train loss:0.060521336950877656\n",
      "train loss:0.01704463153791906\n",
      "train loss:0.007879300001131273\n",
      "train loss:0.014578646565063304\n",
      "train loss:0.004937095493308501\n",
      "=== epoch:7, train acc:0.991, test acc:0.987 ===\n",
      "train loss:0.023775312481675432\n",
      "train loss:0.012979853520156683\n",
      "train loss:0.013792410669788353\n",
      "train loss:0.014458773153379345\n",
      "train loss:0.004383807313239983\n",
      "train loss:0.015902407340330355\n",
      "train loss:0.01682533694908856\n",
      "train loss:0.01427079428383703\n",
      "train loss:0.003452722241821334\n",
      "train loss:0.02129360830465738\n",
      "train loss:0.026223390809490307\n",
      "train loss:0.01669254233497106\n",
      "train loss:0.005481184560120433\n",
      "train loss:0.004200284236650815\n",
      "train loss:0.005182390496855023\n",
      "train loss:0.03888753931463579\n",
      "train loss:0.027976766590435544\n",
      "train loss:0.007655906790659573\n",
      "train loss:0.018197751433194038\n",
      "train loss:0.007251724416281236\n",
      "train loss:0.0021820942042654356\n",
      "train loss:0.009356056024718945\n",
      "train loss:0.00747010984463464\n",
      "train loss:0.023514093508064236\n",
      "train loss:0.001715696860273867\n",
      "train loss:0.015744970233150656\n",
      "train loss:0.03317587572976771\n",
      "train loss:0.01027681131692622\n",
      "train loss:0.0038012426347207883\n",
      "train loss:0.012393408956617787\n",
      "train loss:0.002309427583808791\n",
      "train loss:0.0029618424846624054\n",
      "train loss:0.0050049623177407234\n",
      "train loss:0.010934148668559794\n",
      "train loss:0.020979868172058033\n",
      "train loss:0.011945682151923495\n",
      "train loss:0.006968425995932731\n",
      "train loss:0.05787952327487148\n",
      "train loss:0.010260059615433687\n",
      "train loss:0.01677609454631414\n",
      "train loss:0.004010548927950599\n",
      "train loss:0.021604492359912453\n",
      "train loss:0.006838858400465348\n",
      "train loss:0.009706794868768197\n",
      "train loss:0.04447437459657988\n",
      "train loss:0.007408200710447605\n",
      "train loss:0.02662816223967062\n",
      "train loss:0.006313713713167769\n",
      "train loss:0.0027290691238885216\n",
      "train loss:0.011351201010838346\n",
      "train loss:0.006110212622255391\n",
      "train loss:0.04654195662296576\n",
      "train loss:0.021153537167897682\n",
      "train loss:0.003342442069052741\n",
      "train loss:0.029938716206523396\n",
      "train loss:0.0063784844327098465\n",
      "train loss:0.020062942929978504\n",
      "train loss:0.012654097936529581\n",
      "train loss:0.015884055391277442\n",
      "train loss:0.012552305034941296\n",
      "train loss:0.013368880615306564\n",
      "train loss:0.008209798871010157\n",
      "train loss:0.012768963267515263\n",
      "train loss:0.01170311566946114\n",
      "train loss:0.029402067127148296\n",
      "train loss:0.0038111120369486353\n",
      "train loss:0.0017857557431856775\n",
      "train loss:0.006693730425839341\n",
      "train loss:0.009165242746839393\n",
      "train loss:0.029845725517730747\n",
      "train loss:0.001560725699837422\n",
      "train loss:0.009389461847427463\n",
      "train loss:0.015854142048216658\n",
      "train loss:0.007261742696218323\n",
      "train loss:0.00684597928992604\n",
      "train loss:0.0005826729230700038\n",
      "train loss:0.026054662434078835\n",
      "train loss:0.019562628082702503\n",
      "train loss:0.0036288956350634155\n",
      "train loss:0.12726668762320723\n",
      "train loss:0.019988018370492293\n",
      "train loss:0.010463376865093086\n",
      "train loss:0.007065303062919029\n",
      "train loss:0.011755393170671306\n",
      "train loss:0.04287306561672219\n",
      "train loss:0.013137699402020047\n",
      "train loss:0.011704374847644146\n",
      "train loss:0.017919148461867693\n",
      "train loss:0.012245671704029532\n",
      "train loss:0.032380287193496435\n",
      "train loss:0.00706953137424646\n",
      "train loss:0.003930014871298302\n",
      "train loss:0.019293491899867662\n",
      "train loss:0.0064720892356810765\n",
      "train loss:0.006727515205614647\n",
      "train loss:0.002825837166079219\n",
      "train loss:0.0135375039602214\n",
      "train loss:0.0060053823963448225\n",
      "train loss:0.014005840385489172\n",
      "train loss:0.019373300365947935\n",
      "train loss:0.008427883136874722\n",
      "train loss:0.0015700320108209145\n",
      "train loss:0.03189933494390585\n",
      "train loss:0.017640090577846226\n",
      "train loss:0.013015493730771764\n",
      "train loss:0.00489270290586608\n",
      "train loss:0.0019591340804095666\n",
      "train loss:0.006024462057822846\n",
      "train loss:0.0050274156979612725\n",
      "train loss:0.008577146687614935\n",
      "train loss:0.0031311286692691253\n",
      "train loss:0.001239371482277076\n",
      "train loss:0.005423076616290176\n",
      "train loss:0.006059719738730044\n",
      "train loss:0.003699513628261118\n",
      "train loss:0.0051664311399251175\n",
      "train loss:0.004633931893181802\n",
      "train loss:0.034147499514482337\n",
      "train loss:0.005796642177584944\n",
      "train loss:0.03998279077099578\n",
      "train loss:0.0018264332909299003\n",
      "train loss:0.007087332756828929\n",
      "train loss:0.014601140563015919\n",
      "train loss:0.005609029047969558\n",
      "train loss:0.010744398491353904\n",
      "train loss:0.0031690954498402755\n",
      "train loss:0.019110096127482604\n",
      "train loss:0.04459612262854993\n",
      "train loss:0.005719925706105523\n",
      "train loss:0.05182767551591324\n",
      "train loss:0.006112062825462958\n",
      "train loss:0.009233194005541213\n",
      "train loss:0.007602931800731737\n",
      "train loss:0.01270284587847766\n",
      "train loss:0.017920482188352124\n",
      "train loss:0.0027076555666655663\n",
      "train loss:0.007228125448802649\n",
      "train loss:0.0091353306870105\n",
      "train loss:0.00935507922964178\n",
      "train loss:0.011147245189523829\n",
      "train loss:0.013115325815017691\n",
      "train loss:0.007121064459460154\n",
      "train loss:0.01306205475560058\n",
      "train loss:0.0019593141185253746\n",
      "train loss:0.00775178724281671\n",
      "train loss:0.053088029639435055\n",
      "train loss:0.014198876446236908\n",
      "train loss:0.006100332916268761\n",
      "train loss:0.0020429790587661715\n",
      "train loss:0.0068086505922526856\n",
      "train loss:0.008171930502561185\n",
      "train loss:0.011554769919813674\n",
      "train loss:0.22606013298320632\n",
      "train loss:0.03103991389625194\n",
      "train loss:0.00529489057402497\n",
      "train loss:0.00788962777904693\n",
      "train loss:0.008323960273786915\n",
      "train loss:0.004373641607056268\n",
      "train loss:0.0018265941308053717\n",
      "train loss:0.01619297266632739\n",
      "train loss:0.01776702557254717\n",
      "train loss:0.03939793715671461\n",
      "train loss:0.009611993927554137\n",
      "train loss:0.020642982148799515\n",
      "train loss:0.008953198995982164\n",
      "train loss:0.029887554905681544\n",
      "train loss:0.004045052208322068\n",
      "train loss:0.024906162727661153\n",
      "train loss:0.017548078628956534\n",
      "train loss:0.0030670947349087903\n",
      "train loss:0.1013476368283696\n",
      "train loss:0.014796916530423379\n",
      "train loss:0.004060649881482432\n",
      "train loss:0.042593814632342616\n",
      "train loss:0.04037544045274995\n",
      "train loss:0.05789167525689659\n",
      "train loss:0.007559217582050599\n",
      "train loss:0.005011166627275719\n",
      "train loss:0.014042002130746791\n",
      "train loss:0.006215336842938046\n",
      "train loss:0.001901384275683259\n",
      "train loss:0.015923324064489094\n",
      "train loss:0.0026562048072715566\n",
      "train loss:0.014251890923327801\n",
      "train loss:0.0360943710273153\n",
      "train loss:0.01855856846267969\n",
      "train loss:0.010889795732972427\n",
      "train loss:0.002981706611756367\n",
      "train loss:0.015930447842550224\n",
      "train loss:0.009756454623222496\n",
      "train loss:0.004152315853391204\n",
      "train loss:0.016356053505039287\n",
      "train loss:0.003036679383027346\n",
      "train loss:0.005567514565967168\n",
      "train loss:0.010818308240937793\n",
      "train loss:0.011105472635974884\n",
      "train loss:0.010812369816889253\n",
      "train loss:0.018791338967908255\n",
      "train loss:0.006706630668798359\n",
      "train loss:0.038276992547051227\n",
      "train loss:0.003761221933880694\n",
      "train loss:0.0015159674515274437\n",
      "train loss:0.040537532809195295\n",
      "train loss:0.009566426457191891\n",
      "train loss:0.00959935367786679\n",
      "train loss:0.01723287087188418\n",
      "train loss:0.01600030074150742\n",
      "train loss:0.006654439393498119\n",
      "train loss:0.014912464762160446\n",
      "train loss:0.02009738178942633\n",
      "train loss:0.005371373891699896\n",
      "train loss:0.019178327505970753\n",
      "train loss:0.008341505635503114\n",
      "train loss:0.005739078197017911\n",
      "train loss:0.008592500207994904\n",
      "train loss:0.0048368903267439365\n",
      "train loss:0.002231629323286447\n",
      "train loss:0.019508928483468854\n",
      "train loss:0.055349870490563405\n",
      "train loss:0.005594714337989459\n",
      "train loss:0.006578301903123425\n",
      "train loss:0.0034208997037620866\n",
      "train loss:0.004246461717980634\n",
      "train loss:0.012969071918934505\n",
      "train loss:0.005148401391343289\n",
      "train loss:0.016287901274261243\n",
      "train loss:0.006601173965456295\n",
      "train loss:0.015360541888022947\n",
      "train loss:0.006334014530032893\n",
      "train loss:0.011379646896724733\n",
      "train loss:0.002319646709042708\n",
      "train loss:0.001636455543491437\n",
      "train loss:0.007422741926201573\n",
      "train loss:0.0272250993811828\n",
      "train loss:0.008632000479493184\n",
      "train loss:0.011023503248150338\n",
      "train loss:0.01860355884340522\n",
      "train loss:0.0975567150117891\n",
      "train loss:0.01863694658166716\n",
      "train loss:0.021928208207035733\n",
      "train loss:0.004876518422696222\n",
      "train loss:0.019341204558290432\n",
      "train loss:0.008374077200819001\n",
      "train loss:0.029295476908219698\n",
      "train loss:0.0017331237701240238\n",
      "train loss:0.06898185360358361\n",
      "train loss:0.019689355908781674\n",
      "train loss:0.009689175640152927\n",
      "train loss:0.02847230169538787\n",
      "train loss:0.009227207410885636\n",
      "train loss:0.06340166583484401\n",
      "train loss:0.026454149429130273\n",
      "train loss:0.004260590238755031\n",
      "train loss:0.02392474381092952\n",
      "train loss:0.0021998889874169517\n",
      "train loss:0.020691090268329652\n",
      "train loss:0.02334527001431506\n",
      "train loss:0.003357600864707232\n",
      "train loss:0.009298906012740187\n",
      "train loss:0.02077361039470906\n",
      "train loss:0.008932300584078942\n",
      "train loss:0.030544598595073157\n",
      "train loss:0.01885856191414581\n",
      "train loss:0.006939719745325188\n",
      "train loss:0.002403992856412559\n",
      "train loss:0.010099599776894046\n",
      "train loss:0.014292055888420575\n",
      "train loss:0.004461190537900551\n",
      "train loss:0.028267860150382983\n",
      "train loss:0.0054769695610478175\n",
      "train loss:0.005548994828238617\n",
      "train loss:0.0249848423365598\n",
      "train loss:0.0009890546698677909\n",
      "train loss:0.012665322165104359\n",
      "train loss:0.02679858067964804\n",
      "train loss:0.00743239181033155\n",
      "train loss:0.07401296539681025\n",
      "train loss:0.009127585430214132\n",
      "train loss:0.03261971103873396\n",
      "train loss:0.052182752859225356\n",
      "train loss:0.0069351640952721675\n",
      "train loss:0.005932597068294478\n",
      "train loss:0.008228995443331616\n",
      "train loss:0.018194794231798907\n",
      "train loss:0.014054245699960449\n",
      "train loss:0.03366622830515982\n",
      "train loss:0.026869106111186255\n",
      "train loss:0.02412899131534096\n",
      "train loss:0.04905532066513953\n",
      "train loss:0.008537987900606375\n",
      "train loss:0.028364976322026475\n",
      "train loss:0.01776647541172387\n",
      "train loss:0.001884987516067379\n",
      "train loss:0.030474713493674054\n",
      "train loss:0.013478252240953918\n",
      "train loss:0.033574048754081535\n",
      "train loss:0.02085717337988082\n",
      "train loss:0.011967391687595783\n",
      "train loss:0.010967823829171022\n",
      "train loss:0.03644458313920179\n",
      "train loss:0.007830929722122227\n",
      "train loss:0.04497826141013135\n",
      "train loss:0.005146971984004817\n",
      "train loss:0.026175352583174903\n",
      "train loss:0.006598173001187519\n",
      "train loss:0.004598909672708676\n",
      "train loss:0.011648605944825077\n",
      "train loss:0.0035467978025539378\n",
      "train loss:0.013573200656540716\n",
      "train loss:0.008428508197771075\n",
      "train loss:0.004538420745546173\n",
      "train loss:0.02348276780160425\n",
      "train loss:0.002908006067977772\n",
      "train loss:0.013998686666406334\n",
      "train loss:0.005528414444043054\n",
      "train loss:0.003182521882890693\n",
      "train loss:0.04274096539871972\n",
      "train loss:0.012714613539991738\n",
      "train loss:0.014851378815386364\n",
      "train loss:0.008025359829091144\n",
      "train loss:0.010871912078842177\n",
      "train loss:0.004266882508756914\n",
      "train loss:0.042583828750658484\n",
      "train loss:0.013068090301982884\n",
      "train loss:0.023038991581072935\n",
      "train loss:0.005375008756499337\n",
      "train loss:0.01804193142377159\n",
      "train loss:0.007238342888746427\n",
      "train loss:0.0028840897985722125\n",
      "train loss:0.008838782836832286\n",
      "train loss:0.016941095618772946\n",
      "train loss:0.006272662463039203\n",
      "train loss:0.0022698509326863265\n",
      "train loss:0.04356077400903241\n",
      "train loss:0.015314421234535469\n",
      "train loss:0.03810496753327039\n",
      "train loss:0.02328290880150011\n",
      "train loss:0.008537689517018778\n",
      "train loss:0.005505097065482113\n",
      "train loss:0.006389410020008728\n",
      "train loss:0.04218393201286477\n",
      "train loss:0.03414723752225359\n",
      "train loss:0.0035310509923751772\n",
      "train loss:0.01595643688319258\n",
      "train loss:0.0030020052100612183\n",
      "train loss:0.006706226217439564\n",
      "train loss:0.0037394951609845194\n",
      "train loss:0.1390997727135472\n",
      "train loss:0.015191501262061358\n",
      "train loss:0.006253824715453429\n",
      "train loss:0.0012355072139635817\n",
      "train loss:0.04131161440149679\n",
      "train loss:0.006110780000484242\n",
      "train loss:0.007585655964273036\n",
      "train loss:0.028526081466945775\n",
      "train loss:0.009671032867985875\n",
      "train loss:0.002732896162348863\n",
      "train loss:0.03653395327389257\n",
      "train loss:0.007223032429142578\n",
      "train loss:0.012479280525393798\n",
      "train loss:0.0029582272294490534\n",
      "train loss:0.002475438895009471\n",
      "train loss:0.03713053908056541\n",
      "train loss:0.003925361865976926\n",
      "train loss:0.053202123259085424\n",
      "train loss:0.0033632128920232287\n",
      "train loss:0.011545166322771774\n",
      "train loss:0.01742114317377097\n",
      "train loss:0.030275157650445382\n",
      "train loss:0.006810605572819967\n",
      "train loss:0.027045575505672027\n",
      "train loss:0.010764811250976003\n",
      "train loss:0.07896762349274682\n",
      "train loss:0.016611564875177395\n",
      "train loss:0.03768511687194562\n",
      "train loss:0.004781448791391857\n",
      "train loss:0.053105126071727356\n",
      "train loss:0.008749869794806086\n",
      "train loss:0.017018789103384894\n",
      "train loss:0.027335078972902094\n",
      "train loss:0.0020650931327349346\n",
      "train loss:0.009225663101835022\n",
      "train loss:0.020937120013724306\n",
      "train loss:0.016216650811281482\n",
      "train loss:0.03169336365486282\n",
      "train loss:0.018531528746820153\n",
      "train loss:0.00238794434761298\n",
      "train loss:0.011827131722488162\n",
      "train loss:0.0022951102111893598\n",
      "train loss:0.0036740555051605313\n",
      "train loss:0.007334159876079886\n",
      "train loss:0.019252376179720074\n",
      "train loss:0.01752164358824162\n",
      "train loss:0.013532179663204075\n",
      "train loss:0.00964761121424948\n",
      "train loss:0.005900978640744606\n",
      "train loss:0.0053191490317468755\n",
      "train loss:0.000548881737529841\n",
      "train loss:0.015808870258640865\n",
      "train loss:0.014875747807645714\n",
      "train loss:0.007695982372114697\n",
      "train loss:0.007590412933614351\n",
      "train loss:0.005650847588667523\n",
      "train loss:0.013260539067128381\n",
      "train loss:0.006437290700268677\n",
      "train loss:0.004558211758276416\n",
      "train loss:0.004194200195889959\n",
      "train loss:0.03462897684006117\n",
      "train loss:0.012103082204489458\n",
      "train loss:0.008179284446991921\n",
      "train loss:0.0005697508335057852\n",
      "train loss:0.004661790328655168\n",
      "train loss:0.0038252197371812136\n",
      "train loss:0.01315060454458998\n",
      "train loss:0.030878787758259297\n",
      "train loss:0.000791385217488322\n",
      "train loss:0.06497647881454792\n",
      "train loss:0.01123966215315741\n",
      "train loss:0.0015961159194914862\n",
      "train loss:0.035621438674216806\n",
      "train loss:0.04037215077047969\n",
      "train loss:0.009805594575091416\n",
      "train loss:0.004280438529782646\n",
      "train loss:0.01417705292005856\n",
      "train loss:0.023884500569794374\n",
      "train loss:0.0045072220657395076\n",
      "train loss:0.02816694111415726\n",
      "train loss:0.01144007747209579\n",
      "train loss:0.0017860545852490086\n",
      "train loss:0.004364129992956086\n",
      "train loss:0.004428446211502032\n",
      "train loss:0.018611708869270903\n",
      "train loss:0.0074498116443727416\n",
      "train loss:0.02588835673117036\n",
      "train loss:0.010343396241926747\n",
      "train loss:0.06541477956225263\n",
      "train loss:0.07343555199315084\n",
      "train loss:0.06058803934722193\n",
      "train loss:0.005691530853647832\n",
      "train loss:0.00345843658849163\n",
      "train loss:0.0009661084011914647\n",
      "train loss:0.025667370548493308\n",
      "train loss:0.011623319702391029\n",
      "train loss:0.007077069978368645\n",
      "train loss:0.025481471938845715\n",
      "train loss:0.015806799514148283\n",
      "train loss:0.015075614619063682\n",
      "train loss:0.036736364691483385\n",
      "train loss:0.005727466066961784\n",
      "train loss:0.007536461898692586\n",
      "train loss:0.010959437869368363\n",
      "train loss:0.014927187646996663\n",
      "train loss:0.004751273370184829\n",
      "train loss:0.03043018645841099\n",
      "train loss:0.019718929407417134\n",
      "train loss:0.00938009078847604\n",
      "train loss:0.014743255903639937\n",
      "train loss:0.004217826236738345\n",
      "train loss:0.02009075606001436\n",
      "train loss:0.0496903573680441\n",
      "train loss:0.01413678413055803\n",
      "train loss:0.06429237097428156\n",
      "train loss:0.010627114095105647\n",
      "train loss:0.005627736256373939\n",
      "train loss:0.018958190539412795\n",
      "train loss:0.07835116388273121\n",
      "train loss:0.016990283127207215\n",
      "train loss:0.030344283682818357\n",
      "train loss:0.0650829892552417\n",
      "train loss:0.003352744333724234\n",
      "train loss:0.01837786564261198\n",
      "train loss:0.04380838871444322\n",
      "train loss:0.011426133619072852\n",
      "train loss:0.012793637652780368\n",
      "train loss:0.015223757158331576\n",
      "train loss:0.012176237045874725\n",
      "train loss:0.01824178380470642\n",
      "train loss:0.005383656634845032\n",
      "train loss:0.028320638401736736\n",
      "train loss:0.032183045465948926\n",
      "train loss:0.03880125339620138\n",
      "train loss:0.0572788618940062\n",
      "train loss:0.00931004785795004\n",
      "train loss:0.012426292620576856\n",
      "train loss:0.010868063605881552\n",
      "train loss:0.016981487292621958\n",
      "train loss:0.00496949303730685\n",
      "train loss:0.0005211051792390427\n",
      "train loss:0.012892770216192243\n",
      "train loss:0.010804329514504385\n",
      "train loss:0.04193049774183929\n",
      "train loss:0.006233499696212594\n",
      "train loss:0.008915872926300526\n",
      "train loss:0.0030473058256521085\n",
      "train loss:0.008607276739275112\n",
      "train loss:0.00554451076208708\n",
      "train loss:0.009280740203480901\n",
      "train loss:0.005363481370978739\n",
      "train loss:0.00394132350107629\n",
      "train loss:0.1267108097495947\n",
      "train loss:0.042810174622614605\n",
      "train loss:0.007226263121172178\n",
      "train loss:0.018576267757349746\n",
      "train loss:0.005263659296451293\n",
      "train loss:0.019209237432509164\n",
      "train loss:0.07043987943097425\n",
      "train loss:0.028354161475181196\n",
      "train loss:0.0055081789858624575\n",
      "train loss:0.01289430597390236\n",
      "train loss:0.01919975298140366\n",
      "train loss:0.004655252908498674\n",
      "train loss:0.008104376447139613\n",
      "train loss:0.07017301852457143\n",
      "train loss:0.020163292246588256\n",
      "train loss:0.018744325831407123\n",
      "train loss:0.005766052427081339\n",
      "train loss:0.04163107264401065\n",
      "train loss:0.01776396257396572\n",
      "train loss:0.06034645461105193\n",
      "train loss:0.014224229826595339\n",
      "train loss:0.004574261427654873\n",
      "train loss:0.008431256860296466\n",
      "train loss:0.03884825434301456\n",
      "train loss:0.024713564054882\n",
      "train loss:0.02554254221733356\n",
      "train loss:0.01357198170530309\n",
      "train loss:0.011272520653131501\n",
      "train loss:0.03388267334304034\n",
      "train loss:0.019009204710391706\n",
      "train loss:0.007158453339758064\n",
      "train loss:0.020361126108054284\n",
      "train loss:0.025105162344565498\n",
      "train loss:0.03376588576502824\n",
      "train loss:0.008098547312589584\n",
      "train loss:0.06199857544623561\n",
      "train loss:0.005617264702428352\n",
      "train loss:0.05460617909456382\n",
      "train loss:0.020743454432318197\n",
      "train loss:0.011312370753882896\n",
      "train loss:0.0023429184034787737\n",
      "train loss:0.022603229133825828\n",
      "train loss:0.06095097576791545\n",
      "train loss:0.008256368930678994\n",
      "train loss:0.015144703673438285\n",
      "train loss:0.002679727276358211\n",
      "train loss:0.0026971577008853376\n",
      "train loss:0.0038584589319425717\n",
      "train loss:0.000804384956880308\n",
      "train loss:0.012085519137403643\n",
      "train loss:0.00441586719631444\n",
      "train loss:0.005082147105047849\n",
      "train loss:0.02146588018424298\n",
      "train loss:0.00999865386703472\n",
      "train loss:0.02494377980247674\n",
      "train loss:0.022820030619968776\n",
      "train loss:0.003949742353595644\n",
      "train loss:0.051366828093484\n",
      "train loss:0.0037013198078011634\n",
      "train loss:0.0037129093199134654\n",
      "train loss:0.014998711710102556\n",
      "train loss:0.02332492086047336\n",
      "train loss:0.029496013025890444\n",
      "train loss:0.0022018848378215074\n",
      "train loss:0.004417062595116413\n",
      "train loss:0.007577950076534887\n",
      "train loss:0.04075132544896189\n",
      "train loss:0.005108133931442056\n",
      "train loss:0.04571831061328067\n",
      "train loss:0.004596677686297148\n",
      "train loss:0.01757389551868692\n",
      "train loss:0.055349349114398746\n",
      "train loss:0.01285143573861102\n",
      "train loss:0.06938173182402659\n",
      "train loss:0.010422511586515661\n",
      "train loss:0.03346079477780023\n",
      "train loss:0.004931783193657146\n",
      "train loss:0.0023802032370048853\n",
      "train loss:0.038847573286585745\n",
      "train loss:0.021125334997895266\n",
      "train loss:0.011300934404548081\n",
      "train loss:0.005758253555997982\n",
      "train loss:0.014091287985493956\n",
      "train loss:0.004151539677775771\n",
      "train loss:0.011665048636705078\n",
      "train loss:0.021111457754635823\n",
      "train loss:0.014877964140558985\n",
      "train loss:0.026639786007173313\n",
      "train loss:0.015883626736808626\n",
      "train loss:0.008342537146532863\n",
      "train loss:0.011280716361795472\n",
      "train loss:0.06966377679059972\n",
      "train loss:0.022647178283058688\n",
      "train loss:0.009693419491683257\n",
      "train loss:0.008389639833956755\n",
      "train loss:0.0037704377287898637\n",
      "train loss:0.009749807132675451\n",
      "train loss:0.0030341501692685274\n",
      "train loss:0.001371321189351187\n",
      "train loss:0.01716065583002798\n",
      "train loss:0.000850951790440247\n",
      "=== epoch:8, train acc:0.994, test acc:0.992 ===\n",
      "train loss:0.002102095798770234\n",
      "train loss:0.0019068249795704511\n",
      "train loss:0.035119191483937766\n",
      "train loss:0.002856616268363647\n",
      "train loss:0.012061022031360478\n",
      "train loss:0.0190288333550454\n",
      "train loss:0.0050020849139948845\n",
      "train loss:0.015953712866434606\n",
      "train loss:0.004084678361326837\n",
      "train loss:0.01458272980962811\n",
      "train loss:0.006098030488014769\n",
      "train loss:0.018193722788610204\n",
      "train loss:0.0037402058226225264\n",
      "train loss:0.020581314069228928\n",
      "train loss:0.003830431102042031\n",
      "train loss:0.0056450588787899745\n",
      "train loss:0.012168468031801227\n",
      "train loss:0.002549702544285505\n",
      "train loss:0.013311929506812252\n",
      "train loss:0.004574415135655004\n",
      "train loss:0.01433009634873123\n",
      "train loss:0.009787153320106178\n",
      "train loss:0.01855034351533913\n",
      "train loss:0.004546170580256054\n",
      "train loss:0.003683008869926409\n",
      "train loss:0.0031571400330243915\n",
      "train loss:0.0340539732458534\n",
      "train loss:0.0104779550333079\n",
      "train loss:0.003718314367237661\n",
      "train loss:0.0025778478209983542\n",
      "train loss:0.02066699274879673\n",
      "train loss:0.012622099590637505\n",
      "train loss:0.021179770681633615\n",
      "train loss:0.003235197313774518\n",
      "train loss:0.0029601179991814493\n",
      "train loss:0.029348030422462822\n",
      "train loss:0.007655054187705297\n",
      "train loss:0.014875549741856264\n",
      "train loss:0.009875129921529275\n",
      "train loss:0.0034943798900763166\n",
      "train loss:0.00616424853272308\n",
      "train loss:0.0031009529261465203\n",
      "train loss:0.004767472958027433\n",
      "train loss:0.00662600066868568\n",
      "train loss:0.03553585887367619\n",
      "train loss:0.032335516461693546\n",
      "train loss:0.00809240587827063\n",
      "train loss:0.019145545099249373\n",
      "train loss:0.048441316949576735\n",
      "train loss:0.014108062606220724\n",
      "train loss:0.0059462828995270715\n",
      "train loss:0.0045809354564590515\n",
      "train loss:0.0015424671565875594\n",
      "train loss:0.012612332282738902\n",
      "train loss:0.006020996680843786\n",
      "train loss:0.003126680616582017\n",
      "train loss:0.014618642143065986\n",
      "train loss:0.0738433010222881\n",
      "train loss:0.0034305485845025504\n",
      "train loss:0.010314896777455696\n",
      "train loss:0.004908717527948819\n",
      "train loss:0.006175700448050693\n",
      "train loss:0.04266252489418107\n",
      "train loss:0.013269294603180784\n",
      "train loss:0.04735738334526162\n",
      "train loss:0.01029766770525662\n",
      "train loss:0.005683369007457334\n",
      "train loss:0.013974982430095628\n",
      "train loss:0.015668415815230933\n",
      "train loss:0.010660190044274733\n",
      "train loss:0.03290796745915419\n",
      "train loss:0.013775786288972313\n",
      "train loss:0.007559103634544344\n",
      "train loss:0.02989843924196078\n",
      "train loss:0.0022749945874901965\n",
      "train loss:0.004881734720162335\n",
      "train loss:0.005723206915618685\n",
      "train loss:0.06096413651351201\n",
      "train loss:0.021377493468821528\n",
      "train loss:0.005423398637681597\n",
      "train loss:0.009230237857846477\n",
      "train loss:0.021430104180358373\n",
      "train loss:0.027290498531844083\n",
      "train loss:0.019355238747716205\n",
      "train loss:0.018830606530006868\n",
      "train loss:0.01339338809952555\n",
      "train loss:0.0059438663218147145\n",
      "train loss:0.036074772053489836\n",
      "train loss:0.004483466773815825\n",
      "train loss:0.007440833879838213\n",
      "train loss:0.001207898250345234\n",
      "train loss:0.006163281043349601\n",
      "train loss:0.0033482977445850105\n",
      "train loss:0.010692039469249029\n",
      "train loss:0.011639932503731338\n",
      "train loss:0.0060530951508723\n",
      "train loss:0.03644101346811902\n",
      "train loss:0.013123146253671987\n",
      "train loss:0.01016814788846756\n",
      "train loss:0.002644591609713605\n",
      "train loss:0.030550737898671937\n",
      "train loss:0.02108338066093344\n",
      "train loss:0.04865282611737223\n",
      "train loss:0.064566143336059\n",
      "train loss:0.003138694362363605\n",
      "train loss:0.025647326965826965\n",
      "train loss:0.002852735309217683\n",
      "train loss:0.011085886074449746\n",
      "train loss:0.018325420619741586\n",
      "train loss:0.015180560740577841\n",
      "train loss:0.015699498637767772\n",
      "train loss:0.008784736703961621\n",
      "train loss:0.004594774842438423\n",
      "train loss:0.02266673310244999\n",
      "train loss:0.0325548395277466\n",
      "train loss:0.00470259364966229\n",
      "train loss:0.005568168424839562\n",
      "train loss:0.003241303184791703\n",
      "train loss:0.049142393316203604\n",
      "train loss:0.0015556421695946388\n",
      "train loss:0.0206532910233029\n",
      "train loss:0.011736336851227784\n",
      "train loss:0.009268667111746289\n",
      "train loss:0.004821023855970787\n",
      "train loss:0.005646426115325247\n",
      "train loss:0.014623024685393551\n",
      "train loss:0.028517412728246067\n",
      "train loss:0.007175902672219428\n",
      "train loss:0.0031277788455387834\n",
      "train loss:0.010724929485515663\n",
      "train loss:0.006217560519196903\n",
      "train loss:0.004815807728892745\n",
      "train loss:0.00966785611059899\n",
      "train loss:0.033808574707574854\n",
      "train loss:0.007366763917974925\n",
      "train loss:0.01009552078606621\n",
      "train loss:0.005902545344680763\n",
      "train loss:0.006726046119771239\n",
      "train loss:0.017122134136901546\n",
      "train loss:0.004259103960677867\n",
      "train loss:0.004194122948060596\n",
      "train loss:0.002977833498301665\n",
      "train loss:0.0165673182120803\n",
      "train loss:0.015565111316552097\n",
      "train loss:0.03476217096533152\n",
      "train loss:0.027934229606403637\n",
      "train loss:0.0026529394688296452\n",
      "train loss:0.0025869050699202827\n",
      "train loss:0.003154842187258819\n",
      "train loss:0.002662295595354877\n",
      "train loss:0.003678081827977472\n",
      "train loss:0.05467603300453233\n",
      "train loss:0.0027420576883289615\n",
      "train loss:0.0069615458989349685\n",
      "train loss:0.012028428386942864\n",
      "train loss:0.08568991691543998\n",
      "train loss:0.0072320720439543506\n",
      "train loss:0.003300838106785575\n",
      "train loss:0.01267972686464562\n",
      "train loss:0.005634209743662988\n",
      "train loss:0.007470003427835452\n",
      "train loss:0.012223265298938841\n",
      "train loss:0.0076305520414091865\n",
      "train loss:0.008331701877655811\n",
      "train loss:0.003098300403427068\n",
      "train loss:0.02338344821249446\n",
      "train loss:0.005401466915786219\n",
      "train loss:0.011270220577454209\n",
      "train loss:0.01421600610273458\n",
      "train loss:0.007506729230497501\n",
      "train loss:0.00913651957688226\n",
      "train loss:0.013110320969088526\n",
      "train loss:0.011287789965694428\n",
      "train loss:0.017741905161151438\n",
      "train loss:0.013814573666115895\n",
      "train loss:0.0033058235128257023\n",
      "train loss:0.004128584322630463\n",
      "train loss:0.015010325171699512\n",
      "train loss:0.010923927719650745\n",
      "train loss:0.00927233542989549\n",
      "train loss:0.016893038361592682\n",
      "train loss:0.004214680443522145\n",
      "train loss:0.00443368166465972\n",
      "train loss:0.01426217015865447\n",
      "train loss:0.007612487050273095\n",
      "train loss:0.004442157825294694\n",
      "train loss:0.01542638078048291\n",
      "train loss:0.02896435868894076\n",
      "train loss:0.027775253597867446\n",
      "train loss:0.005837188680161951\n",
      "train loss:0.0018481619433322043\n",
      "train loss:0.0070918944986101155\n",
      "train loss:0.0013851481871213526\n",
      "train loss:0.04040421864085553\n",
      "train loss:0.0007772399865861951\n",
      "train loss:0.002054859151787346\n",
      "train loss:0.00628640568219424\n",
      "train loss:0.0075017881692472374\n",
      "train loss:0.002842078739537037\n",
      "train loss:0.0041924360296984\n",
      "train loss:0.022134332834846334\n",
      "train loss:0.019461059765047337\n",
      "train loss:0.029307599637290106\n",
      "train loss:0.005695942815191682\n",
      "train loss:0.017820730634639317\n",
      "train loss:0.01756374832967839\n",
      "train loss:0.004425630966007868\n",
      "train loss:0.008176814045227389\n",
      "train loss:0.013301878206181615\n",
      "train loss:0.004419182578008909\n",
      "train loss:0.035814524172274396\n",
      "train loss:0.010295985935831468\n",
      "train loss:0.03804402052610766\n",
      "train loss:0.007916767193313327\n",
      "train loss:0.007363896719505235\n",
      "train loss:0.0029007959768840618\n",
      "train loss:0.006459757483321466\n",
      "train loss:0.010053363548889884\n",
      "train loss:0.02353702727500432\n",
      "train loss:0.0031850803474033277\n",
      "train loss:0.02537787225481355\n",
      "train loss:0.028906433764779606\n",
      "train loss:0.018008802391011804\n",
      "train loss:0.041205788058132874\n",
      "train loss:0.05501805579363855\n",
      "train loss:0.07922065566572793\n",
      "train loss:0.008308182820216354\n",
      "train loss:0.011204391829492087\n",
      "train loss:0.003089377898169696\n",
      "train loss:0.0012891012558549372\n",
      "train loss:0.0028046934980382764\n",
      "train loss:0.005861027210237476\n",
      "train loss:0.017601285186975273\n",
      "train loss:0.02020846043017304\n",
      "train loss:0.03740199950398348\n",
      "train loss:0.06634200659898815\n",
      "train loss:0.009075177798303252\n",
      "train loss:0.06679434858520461\n",
      "train loss:0.028698354919277812\n",
      "train loss:0.07699065632123438\n",
      "train loss:0.005668777432120977\n",
      "train loss:0.023700609163771924\n",
      "train loss:0.012017861872261998\n",
      "train loss:0.021940242667067403\n",
      "train loss:0.009537584408216707\n",
      "train loss:0.006455897145511215\n",
      "train loss:0.018367797161451736\n",
      "train loss:0.012180346623820403\n",
      "train loss:0.017127219917090843\n",
      "train loss:0.013847725541579042\n",
      "train loss:0.0151463795836305\n",
      "train loss:0.0020141354573180235\n",
      "train loss:0.01328443486605047\n",
      "train loss:0.0031568157467482456\n",
      "train loss:0.011565884474357371\n",
      "train loss:0.03002450783798164\n",
      "train loss:0.011762145164431364\n",
      "train loss:0.014526406767397788\n",
      "train loss:0.023746302681306362\n",
      "train loss:0.00231521208596143\n",
      "train loss:0.01343589244615868\n",
      "train loss:0.0018382544563472795\n",
      "train loss:0.009409958994428584\n",
      "train loss:0.01136514116173404\n",
      "train loss:0.013072375909099225\n",
      "train loss:0.019568582508038296\n",
      "train loss:0.01845891917935885\n",
      "train loss:0.006396586048475145\n",
      "train loss:0.011671590323472132\n",
      "train loss:0.004979493328100961\n",
      "train loss:0.007829021939711883\n",
      "train loss:0.006030185468317568\n",
      "train loss:0.006212003827805155\n",
      "train loss:0.005672219664323658\n",
      "train loss:0.004830424808838461\n",
      "train loss:0.03176937228224865\n",
      "train loss:0.023411811005295272\n",
      "train loss:0.0014974728927070794\n",
      "train loss:0.0025171037125676816\n",
      "train loss:0.004576165056550715\n",
      "train loss:0.009944564854177808\n",
      "train loss:0.03759230231385052\n",
      "train loss:0.007771070325816534\n",
      "train loss:0.0032931370469454807\n",
      "train loss:0.009293623526947997\n",
      "train loss:0.014532606600793752\n",
      "train loss:0.005958945648431676\n",
      "train loss:0.005160374996424009\n",
      "train loss:0.003099034366033258\n",
      "train loss:0.0066447719597778464\n",
      "train loss:0.0023211089730141472\n",
      "train loss:0.0030908671120081993\n",
      "train loss:0.06026553740117351\n",
      "train loss:0.022284840070549185\n",
      "train loss:0.013837934359082404\n",
      "train loss:0.0032604465053919047\n",
      "train loss:0.01443708750057451\n",
      "train loss:0.012963171921519261\n",
      "train loss:0.007235739119705706\n",
      "train loss:0.019065206075212605\n",
      "train loss:0.011579015252157807\n",
      "train loss:0.019850021461047494\n",
      "train loss:0.004428969857371229\n",
      "train loss:0.002977828005432978\n",
      "train loss:0.0027116007384724466\n",
      "train loss:0.017900206335021977\n",
      "train loss:0.009828617620731037\n",
      "train loss:0.04969006210285637\n",
      "train loss:0.01244991581395966\n",
      "train loss:0.015875802756894222\n",
      "train loss:0.01598480956784662\n",
      "train loss:0.024437688580733648\n",
      "train loss:0.009272358056382891\n",
      "train loss:0.02494186595053423\n",
      "train loss:0.06788034109927107\n",
      "train loss:0.0019339030071345775\n",
      "train loss:0.005551374636404215\n",
      "train loss:0.008413202907142866\n",
      "train loss:0.0320874417764373\n",
      "train loss:0.008046097546021471\n",
      "train loss:0.004704958001453488\n",
      "train loss:0.02777056856605307\n",
      "train loss:0.01813701730826591\n",
      "train loss:0.0034506724648530073\n",
      "train loss:0.002547950310564976\n",
      "train loss:0.007979623530442157\n",
      "train loss:0.01147060895204252\n",
      "train loss:0.006786157734661955\n",
      "train loss:0.00759411176763471\n",
      "train loss:0.006769769159929939\n",
      "train loss:0.006853088401460325\n",
      "train loss:0.0037683844866812626\n",
      "train loss:0.005702772265912214\n",
      "train loss:0.0012728270355669236\n",
      "train loss:0.007279214518141067\n",
      "train loss:0.003488629801830387\n",
      "train loss:0.006691411551814529\n",
      "train loss:0.007084475390072263\n",
      "train loss:0.037321286285954096\n",
      "train loss:0.013668809916677058\n",
      "train loss:0.004854049000968487\n",
      "train loss:0.005756917108138796\n",
      "train loss:0.006535810690282463\n",
      "train loss:0.003782928898350353\n",
      "train loss:0.040411760430868006\n",
      "train loss:0.0030621434146662807\n",
      "train loss:0.012234601579653432\n",
      "train loss:0.016242793361559954\n",
      "train loss:0.002310927459561962\n",
      "train loss:0.002924345853416081\n",
      "train loss:0.011595494508319884\n",
      "train loss:0.013151298874745799\n",
      "train loss:0.007146939826933177\n",
      "train loss:0.02042492736015833\n",
      "train loss:0.008332209331152798\n",
      "train loss:0.01965666874005323\n",
      "train loss:0.003338179693488022\n",
      "train loss:0.009562587786606118\n",
      "train loss:0.006935973675803529\n",
      "train loss:0.011693896168855362\n",
      "train loss:0.0029724341627160593\n",
      "train loss:0.0025643663134992355\n",
      "train loss:0.012187287637829542\n",
      "train loss:0.010844433521840682\n",
      "train loss:0.012007712117499101\n",
      "train loss:0.016193580472052053\n",
      "train loss:0.0023344998986802603\n",
      "train loss:0.003680068369085955\n",
      "train loss:0.0066155161298837376\n",
      "train loss:0.001503936504753634\n",
      "train loss:0.006811989674355\n",
      "train loss:0.0032648587329189103\n",
      "train loss:0.003665425415128998\n",
      "train loss:0.011883278077265911\n",
      "train loss:0.0065132267138577485\n",
      "train loss:0.007616330809869049\n",
      "train loss:0.0039692076415356985\n",
      "train loss:0.01051794319324392\n",
      "train loss:0.05328394848990713\n",
      "train loss:0.0030221514606114507\n",
      "train loss:0.005464661555186466\n",
      "train loss:0.00921272935960684\n",
      "train loss:0.01917896487559868\n",
      "train loss:0.009870945465666626\n",
      "train loss:0.012503199239576292\n",
      "train loss:0.005268726931583613\n",
      "train loss:0.004973035918446827\n",
      "train loss:0.002022080272888767\n",
      "train loss:0.00616073989870641\n",
      "train loss:0.004079466732825767\n",
      "train loss:0.004929148692705984\n",
      "train loss:0.006114466552709098\n",
      "train loss:0.0016950196465396203\n",
      "train loss:0.00584393031803537\n",
      "train loss:0.011131972848180585\n",
      "train loss:0.0015802922719379256\n",
      "train loss:0.0071341733122473995\n",
      "train loss:0.00973374510224106\n",
      "train loss:0.001494710471617211\n",
      "train loss:0.003757507695534714\n",
      "train loss:0.006100158123897368\n",
      "train loss:0.009307878171132438\n",
      "train loss:0.007010621444665308\n",
      "train loss:0.010671187227239287\n",
      "train loss:0.020604780306346222\n",
      "train loss:0.030205523747049816\n",
      "train loss:0.002538634231882479\n",
      "train loss:0.0014334143693128677\n",
      "train loss:0.004243279863996347\n",
      "train loss:0.0029487639931074505\n",
      "train loss:0.005818823483166655\n",
      "train loss:0.00681059875268063\n",
      "train loss:0.0035446673064427094\n",
      "train loss:0.019070864057321772\n",
      "train loss:0.006208872122988286\n",
      "train loss:0.0013482348771332072\n",
      "train loss:0.001291907091983925\n",
      "train loss:0.007699923277242781\n",
      "train loss:0.00510178489529523\n",
      "train loss:0.0025519936162618443\n",
      "train loss:0.0022541793754419473\n",
      "train loss:0.005781899411123939\n",
      "train loss:0.0037372634149025713\n",
      "train loss:0.003576561142331529\n",
      "train loss:0.0018506313304492137\n",
      "train loss:0.009558828880265827\n",
      "train loss:0.005875732383168361\n",
      "train loss:0.062255762966629186\n",
      "train loss:0.003545987536599942\n",
      "train loss:0.014976351295729051\n",
      "train loss:0.009466787105432382\n",
      "train loss:0.0031179806605688186\n",
      "train loss:0.00628871509617064\n",
      "train loss:0.008397135795661636\n",
      "train loss:0.001992330256899582\n",
      "train loss:0.01582710539886754\n",
      "train loss:0.009379590395948047\n",
      "train loss:0.022985321202628972\n",
      "train loss:0.010044261493992544\n",
      "train loss:0.007491364283396969\n",
      "train loss:0.004490998341273848\n",
      "train loss:0.012003013203157989\n",
      "train loss:0.008682734263687139\n",
      "train loss:0.015598676083368979\n",
      "train loss:0.011007312061775729\n",
      "train loss:0.0027848375440291382\n",
      "train loss:0.015466249733696784\n",
      "train loss:0.005933096049872181\n",
      "train loss:0.003686533014501518\n",
      "train loss:0.008216473012145346\n",
      "train loss:0.004889944714974023\n",
      "train loss:0.06563913819349922\n",
      "train loss:0.008129699443329565\n",
      "train loss:0.021396434291173053\n",
      "train loss:0.0006350120434380887\n",
      "train loss:0.004309565354757648\n",
      "train loss:0.004453095611548148\n",
      "train loss:0.03406097728313882\n",
      "train loss:0.02549400452537193\n",
      "train loss:0.01023579718269198\n",
      "train loss:0.017189388133005933\n",
      "train loss:0.009129687705112976\n",
      "train loss:0.00374074199836675\n",
      "train loss:0.008119520058683612\n",
      "train loss:0.003122429492005073\n",
      "train loss:0.0025880926100707658\n",
      "train loss:0.0033467074470884305\n",
      "train loss:0.00429867735692105\n",
      "train loss:0.014917417534042217\n",
      "train loss:0.017402828512619987\n",
      "train loss:0.003805059356018783\n",
      "train loss:0.0028505291795153844\n",
      "train loss:0.01759723972396446\n",
      "train loss:0.005722492318803469\n",
      "train loss:0.0038226177202351583\n",
      "train loss:0.026879021295421465\n",
      "train loss:0.007228585133918217\n",
      "train loss:0.014897697380143593\n",
      "train loss:0.015382218954848162\n",
      "train loss:0.048894676722635595\n",
      "train loss:0.0029411651125276234\n",
      "train loss:0.002827838573318295\n",
      "train loss:0.005055922102155736\n",
      "train loss:0.0026656277165654236\n",
      "train loss:0.02266802027631873\n",
      "train loss:0.006325826784075946\n",
      "train loss:0.0034581536736895684\n",
      "train loss:0.015343373249893537\n",
      "train loss:0.059113250263007205\n",
      "train loss:0.01329409832991945\n",
      "train loss:0.008995644567977315\n",
      "train loss:0.003358863947257144\n",
      "train loss:0.004369362694250891\n",
      "train loss:0.020751705032177364\n",
      "train loss:0.0039312455895472095\n",
      "train loss:0.007996997094290964\n",
      "train loss:0.02966362181353582\n",
      "train loss:0.005271340671283874\n",
      "train loss:0.004980379109582359\n",
      "train loss:0.01678466284041359\n",
      "train loss:0.01172795512448002\n",
      "train loss:0.002753251755900452\n",
      "train loss:0.00840328436131557\n",
      "train loss:0.0016087726571415329\n",
      "train loss:0.005780114026713158\n",
      "train loss:0.005980534465154509\n",
      "train loss:0.004661427956992465\n",
      "train loss:0.04159821760355403\n",
      "train loss:0.003186209025950465\n",
      "train loss:0.006013470453950022\n",
      "train loss:0.009159992713795702\n",
      "train loss:0.0064170350475132535\n",
      "train loss:0.003912867540722333\n",
      "train loss:0.00539661846199759\n",
      "train loss:0.03446572455495971\n",
      "train loss:0.005901923044279753\n",
      "train loss:0.008195306104333954\n",
      "train loss:0.004311446172019123\n",
      "train loss:0.02348599088938319\n",
      "train loss:0.0008203663912182362\n",
      "train loss:0.005786026277922824\n",
      "train loss:0.006300924322492444\n",
      "train loss:0.0073217087658271705\n",
      "train loss:0.0029896160026889394\n",
      "train loss:0.012635303587374495\n",
      "train loss:0.023235746067811557\n",
      "train loss:0.011650726592602396\n",
      "train loss:0.020053463266266704\n",
      "train loss:0.0024013855803667757\n",
      "train loss:0.0033962379722173672\n",
      "train loss:0.006502202788525443\n",
      "train loss:0.021289251325136226\n",
      "train loss:0.005715251113790334\n",
      "train loss:0.00620517132172844\n",
      "train loss:0.009971491122251824\n",
      "train loss:0.01727163497154296\n",
      "train loss:0.002613142636616841\n",
      "train loss:0.01379026006482355\n",
      "train loss:0.0024568473573260254\n",
      "train loss:0.0009777993730951161\n",
      "train loss:0.010444522696972684\n",
      "train loss:0.006712522891190678\n",
      "train loss:0.020189789567817154\n",
      "train loss:0.008812084123091056\n",
      "train loss:0.00302031177778982\n",
      "train loss:0.005133640522154691\n",
      "train loss:0.0006736918930844482\n",
      "train loss:0.004877361165809297\n",
      "train loss:0.00470053341573627\n",
      "train loss:0.07387742129596524\n",
      "train loss:0.01450263683040047\n",
      "train loss:0.01684921086827077\n",
      "train loss:0.022996601896394367\n",
      "train loss:0.0013776466124977712\n",
      "train loss:0.009611722579057869\n",
      "train loss:0.005944719475479675\n",
      "train loss:0.0008748778216566351\n",
      "train loss:0.0024418243743094398\n",
      "train loss:0.036098015350824124\n",
      "train loss:0.01247325214119607\n",
      "train loss:0.016217102235049196\n",
      "train loss:0.003329075953737762\n",
      "train loss:0.023557542826122418\n",
      "train loss:0.023233731220696878\n",
      "train loss:0.0014486002972385892\n",
      "train loss:0.00991576068547313\n",
      "train loss:0.013492294248103689\n",
      "train loss:0.007497665343564383\n",
      "train loss:0.01510974508857379\n",
      "train loss:0.008077096333371154\n",
      "train loss:0.0018106868054168918\n",
      "train loss:0.0018270474751409804\n",
      "train loss:0.0010420183031533184\n",
      "train loss:0.005369716021090138\n",
      "train loss:0.0034437530065892343\n",
      "train loss:0.002341884035143857\n",
      "train loss:0.005679422116382357\n",
      "train loss:0.007462474150606949\n",
      "train loss:0.00879799467678535\n",
      "train loss:0.003978078576983589\n",
      "train loss:0.09627805839370945\n",
      "train loss:0.0034789323973969484\n",
      "train loss:0.004042315345003963\n",
      "train loss:0.001405916778260739\n",
      "train loss:0.0038799393299057657\n",
      "train loss:0.0027398056807257224\n",
      "train loss:0.006628009048212558\n",
      "train loss:0.005781638364634796\n",
      "train loss:0.00865493236202827\n",
      "train loss:0.015971667118922218\n",
      "train loss:0.007578146331659973\n",
      "train loss:0.011765796715608146\n",
      "train loss:0.007095619629907806\n",
      "train loss:0.004214928498451502\n",
      "train loss:0.0012005790776109227\n",
      "train loss:0.0032640778928768816\n",
      "train loss:0.0072788631399523475\n",
      "train loss:0.01052173326168804\n",
      "train loss:0.015077970792787165\n",
      "train loss:0.001327429653294373\n",
      "=== epoch:9, train acc:0.995, test acc:0.988 ===\n",
      "train loss:0.00040306439883328624\n",
      "train loss:0.005383199585574698\n",
      "train loss:0.011627992908484033\n",
      "train loss:0.013816120813204411\n",
      "train loss:0.004160633049881248\n",
      "train loss:0.0060425726387107045\n",
      "train loss:0.005719790480585771\n",
      "train loss:0.011968672042280255\n",
      "train loss:0.006745875593453405\n",
      "train loss:0.0025035686358560456\n",
      "train loss:0.0022308455221652424\n",
      "train loss:0.0015421355252400858\n",
      "train loss:0.0013454051944890584\n",
      "train loss:0.005452387472825944\n",
      "train loss:0.012588605439616712\n",
      "train loss:0.010874823499421173\n",
      "train loss:0.004744585552981861\n",
      "train loss:0.030037238913589687\n",
      "train loss:0.004600227719207953\n",
      "train loss:0.002988251936242071\n",
      "train loss:0.004002506843201667\n",
      "train loss:0.015125263951123773\n",
      "train loss:0.002981059988962335\n",
      "train loss:0.004475499498233207\n",
      "train loss:0.006121596612485471\n",
      "train loss:0.004697045779186125\n",
      "train loss:0.011495432784345106\n",
      "train loss:0.0060441456515201355\n",
      "train loss:0.004646926584278572\n",
      "train loss:0.01509389190924586\n",
      "train loss:0.0010422975257161431\n",
      "train loss:0.00261777882043641\n",
      "train loss:0.01825895980450158\n",
      "train loss:0.018454935331852627\n",
      "train loss:0.004417974573034438\n",
      "train loss:0.008469903967588191\n",
      "train loss:0.008968240325341692\n",
      "train loss:0.0009836944212465069\n",
      "train loss:0.0065672760094987355\n",
      "train loss:0.008012535833451543\n",
      "train loss:0.0029429459029780302\n",
      "train loss:0.02515694453988625\n",
      "train loss:0.05481496082657834\n",
      "train loss:0.0033526092249115905\n",
      "train loss:0.006519338223782162\n",
      "train loss:0.010117156986171471\n",
      "train loss:0.012330886835749053\n",
      "train loss:0.014848141943255243\n",
      "train loss:0.0024976228963919144\n",
      "train loss:0.0026575911680196355\n",
      "train loss:0.005394126402863088\n",
      "train loss:0.03211455372453465\n",
      "train loss:0.0028911106735550708\n",
      "train loss:0.0020818983909042478\n",
      "train loss:0.002020416620882899\n",
      "train loss:0.07044013554988744\n",
      "train loss:0.001299609205469157\n",
      "train loss:0.00917386438217669\n",
      "train loss:0.007651576153168896\n",
      "train loss:0.009528383830247037\n",
      "train loss:0.0063982017927883324\n",
      "train loss:0.014835021749281608\n",
      "train loss:0.005589237739804516\n",
      "train loss:0.0031368999981088446\n",
      "train loss:0.0011764493671103894\n",
      "train loss:0.015415284355928515\n",
      "train loss:0.001222839361018562\n",
      "train loss:0.01025195974030191\n",
      "train loss:0.001954945001834288\n",
      "train loss:0.006283097142853466\n",
      "train loss:0.06064454172075234\n",
      "train loss:0.004003650827994314\n",
      "train loss:0.002432029419705208\n",
      "train loss:0.0008181869114422585\n",
      "train loss:0.0024772865504553735\n",
      "train loss:0.004538027731699286\n",
      "train loss:0.0025133589581803435\n",
      "train loss:0.008970201316708669\n",
      "train loss:0.035654378995287714\n",
      "train loss:0.003999099436008647\n",
      "train loss:0.04644974329785719\n",
      "train loss:0.00767298695538534\n",
      "train loss:0.009379861691154382\n",
      "train loss:0.006246561160436343\n",
      "train loss:0.0033868013852115784\n",
      "train loss:0.006046521298506761\n",
      "train loss:0.01326348339778335\n",
      "train loss:0.007633131277097713\n",
      "train loss:0.002524285356083071\n",
      "train loss:0.007123097743451929\n",
      "train loss:0.006363669057797722\n",
      "train loss:0.007861238312142405\n",
      "train loss:0.0065878231925100535\n",
      "train loss:0.014825216919280118\n",
      "train loss:0.008860161345019529\n",
      "train loss:0.006306434191662266\n",
      "train loss:0.02151808517331569\n",
      "train loss:0.04681309856074318\n",
      "train loss:0.05802687832652349\n",
      "train loss:0.0022605234143116214\n",
      "train loss:0.005594250146586445\n",
      "train loss:0.014183274974261304\n",
      "train loss:0.012560488342836072\n",
      "train loss:0.012051209959967873\n",
      "train loss:0.006098133936180098\n",
      "train loss:0.001905244099401619\n",
      "train loss:0.010348029646664625\n",
      "train loss:0.023760074224177717\n",
      "train loss:0.017933813788015795\n",
      "train loss:0.00923778298605791\n",
      "train loss:0.004313307115893855\n",
      "train loss:0.006507615812912803\n",
      "train loss:0.03839615786735697\n",
      "train loss:0.13576213850582836\n",
      "train loss:0.009875602959660385\n",
      "train loss:0.013469912040143655\n",
      "train loss:0.012183263191661978\n",
      "train loss:0.003131736216116159\n",
      "train loss:0.024355092393638107\n",
      "train loss:0.041254258511270805\n",
      "train loss:0.010384894197655077\n",
      "train loss:0.006723054425012901\n",
      "train loss:0.001246611468387385\n",
      "train loss:0.006808190861298862\n",
      "train loss:0.017920380741660063\n",
      "train loss:0.005215499288184713\n",
      "train loss:0.016023097059199347\n",
      "train loss:0.0025164411055491553\n",
      "train loss:0.0075000052257411165\n",
      "train loss:0.011734109631734262\n",
      "train loss:0.032226100727230304\n",
      "train loss:0.006918153311609704\n",
      "train loss:0.0034995538405323033\n",
      "train loss:0.007512614057359189\n",
      "train loss:0.010857825587137309\n",
      "train loss:0.002043941821180487\n",
      "train loss:0.005164098889684241\n",
      "train loss:0.0060465036979993345\n",
      "train loss:0.0030453253843078587\n",
      "train loss:0.005325080674286078\n",
      "train loss:0.0026565370352019508\n",
      "train loss:0.004474232920534724\n",
      "train loss:0.0066278746331124684\n",
      "train loss:0.07372915849189317\n",
      "train loss:0.006660151714784818\n",
      "train loss:0.010461912933590578\n",
      "train loss:0.0023927446264406724\n",
      "train loss:0.013252005749919592\n",
      "train loss:0.004452244522108607\n",
      "train loss:0.0017973550866421622\n",
      "train loss:0.008005882084294775\n",
      "train loss:0.007570504016380818\n",
      "train loss:0.00029891150948998466\n",
      "train loss:0.03426606255169321\n",
      "train loss:0.005830971593690115\n",
      "train loss:0.0025691986846572965\n",
      "train loss:0.0052112558109103976\n",
      "train loss:0.004338106260689747\n",
      "train loss:0.02202174845104921\n",
      "train loss:0.00939953516598623\n",
      "train loss:0.009377988808783523\n",
      "train loss:0.002380018454519023\n",
      "train loss:0.004630400091370508\n",
      "train loss:0.003569590937964457\n",
      "train loss:0.002885861678689184\n",
      "train loss:0.0013408503728806606\n",
      "train loss:0.0012281889116765757\n",
      "train loss:0.006111705011028277\n",
      "train loss:0.0018843649949062975\n",
      "train loss:0.007295665486105956\n",
      "train loss:0.003652229716140826\n",
      "train loss:0.00047913458439509236\n",
      "train loss:0.021636451269492447\n",
      "train loss:0.0017493612845412938\n",
      "train loss:0.00917781927116557\n",
      "train loss:0.0017319012511268954\n",
      "train loss:0.009982254153230653\n",
      "train loss:0.01037269535234054\n",
      "train loss:0.0031081360210816946\n",
      "train loss:0.006638677522774055\n",
      "train loss:0.00392860909027048\n",
      "train loss:0.002072798899579945\n",
      "train loss:0.018761582272408428\n",
      "train loss:0.002027238356104277\n",
      "train loss:0.0004592679932480092\n",
      "train loss:0.0028159033062626266\n",
      "train loss:0.006705500507032424\n",
      "train loss:0.05364056213369139\n",
      "train loss:0.0013455684809956694\n",
      "train loss:0.03276166224678838\n",
      "train loss:0.007870709430078265\n",
      "train loss:0.031813109202242444\n",
      "train loss:0.004771963201205341\n",
      "train loss:0.019713803319526043\n",
      "train loss:0.0030843110281370905\n",
      "train loss:0.0018868326498348875\n",
      "train loss:0.00450114095930322\n",
      "train loss:0.029406837631915907\n",
      "train loss:0.00626959846097627\n",
      "train loss:0.0017571379510979215\n",
      "train loss:0.001285845953830233\n",
      "train loss:0.005795286064595883\n",
      "train loss:0.0026691723533446426\n",
      "train loss:0.01287830440004261\n",
      "train loss:0.008415196764467597\n",
      "train loss:0.0013366383618398478\n",
      "train loss:0.0033869703533852707\n",
      "train loss:0.011651769536568664\n",
      "train loss:0.003234111564667796\n",
      "train loss:0.021286498267072074\n",
      "train loss:0.007559661701105521\n",
      "train loss:0.0037829666320548616\n",
      "train loss:0.00898660481989227\n",
      "train loss:0.07926998348588828\n",
      "train loss:0.014661096854395848\n",
      "train loss:0.005706538316178871\n",
      "train loss:0.005737325283359832\n",
      "train loss:0.002357176768458514\n",
      "train loss:0.02349793035343742\n",
      "train loss:0.015444247706651575\n",
      "train loss:0.04348589282396751\n",
      "train loss:0.001039183521417177\n",
      "train loss:0.010998973453608145\n",
      "train loss:0.012359165598177659\n",
      "train loss:0.006828830162246867\n",
      "train loss:0.011260844545230669\n",
      "train loss:0.0098871111326243\n",
      "train loss:0.010370885440977268\n",
      "train loss:0.00301630439779888\n",
      "train loss:0.002473359605206732\n",
      "train loss:0.00487551396357623\n",
      "train loss:0.0023178712877361066\n",
      "train loss:0.02741972042332264\n",
      "train loss:0.0053654406788923685\n",
      "train loss:0.005102840313360499\n",
      "train loss:0.013318953879322255\n",
      "train loss:0.018011108966876143\n",
      "train loss:0.002002664869306161\n",
      "train loss:0.002013302806137313\n",
      "train loss:0.01767127978153694\n",
      "train loss:0.0034390697331654918\n",
      "train loss:0.005100163897614118\n",
      "train loss:0.015198091686105603\n",
      "train loss:0.004073221403279662\n",
      "train loss:0.005912385821334424\n",
      "train loss:0.019006386239130268\n",
      "train loss:0.0038971872981481766\n",
      "train loss:0.010929190013506366\n",
      "train loss:0.015970827648331992\n",
      "train loss:0.01116851126486432\n",
      "train loss:0.00189364500457925\n",
      "train loss:0.013884971690441332\n",
      "train loss:0.042124149993535705\n",
      "train loss:0.003783346444938081\n",
      "train loss:0.01090227555498931\n",
      "train loss:0.005606603831090474\n",
      "train loss:0.005690331606249631\n",
      "train loss:0.002802660027273325\n",
      "train loss:0.005309228663273582\n",
      "train loss:0.0025211158640499947\n",
      "train loss:0.01282516971065771\n",
      "train loss:0.01171057427571218\n",
      "train loss:0.004060227259973953\n",
      "train loss:0.0012526624935516762\n",
      "train loss:0.0016095218709783817\n",
      "train loss:0.006088325869242731\n",
      "train loss:0.006604989040756827\n",
      "train loss:0.013938939951094291\n",
      "train loss:0.003596237706330718\n",
      "train loss:0.011070655021595745\n",
      "train loss:0.07178618296208229\n",
      "train loss:0.006360180492659714\n",
      "train loss:0.017056293207883752\n",
      "train loss:0.003084702605016815\n",
      "train loss:0.004590525991931329\n",
      "train loss:0.00225867443180664\n",
      "train loss:0.003152972344245636\n",
      "train loss:0.0028648271826648064\n",
      "train loss:0.026213608156563796\n",
      "train loss:0.007053851761158894\n",
      "train loss:0.0018647385032407376\n",
      "train loss:0.0015378547450265536\n",
      "train loss:0.025108617211850297\n",
      "train loss:0.01715681377173987\n",
      "train loss:0.011636024824293559\n",
      "train loss:0.002067599952751435\n",
      "train loss:0.007365895595545987\n",
      "train loss:0.004344786408548799\n",
      "train loss:0.006897815124785961\n",
      "train loss:0.00555002178528634\n",
      "train loss:0.012282131235371854\n",
      "train loss:0.007724049747360379\n",
      "train loss:0.006473622464053364\n",
      "train loss:0.001842873869325559\n",
      "train loss:0.011930728050522166\n",
      "train loss:0.0060526806791060175\n",
      "train loss:0.00936688257591472\n",
      "train loss:0.008738667808614924\n",
      "train loss:0.0010573275725006585\n",
      "train loss:0.025687555992501155\n",
      "train loss:0.0035604074698790244\n",
      "train loss:0.003832657257474492\n",
      "train loss:0.006923572367280695\n",
      "train loss:0.008159228933614617\n",
      "train loss:0.00812573039491577\n",
      "train loss:0.003612988135240182\n",
      "train loss:0.016091235616241525\n",
      "train loss:0.00987558244767319\n",
      "train loss:0.002383320865114736\n",
      "train loss:0.000268573453295958\n",
      "train loss:0.01226311725086638\n",
      "train loss:0.034669504771797574\n",
      "train loss:0.005424894887954149\n",
      "train loss:0.008317095035985817\n",
      "train loss:0.0033852805377524407\n",
      "train loss:0.0017702134277566503\n",
      "train loss:0.008622581515751921\n",
      "train loss:0.00850587254326664\n",
      "train loss:0.004511490984743709\n",
      "train loss:0.03623185791706415\n",
      "train loss:0.015485764850305672\n",
      "train loss:0.004686578881395172\n",
      "train loss:0.0008971924619806743\n",
      "train loss:0.013897446858751545\n",
      "train loss:0.009229529318274468\n",
      "train loss:0.0063755881245423016\n",
      "train loss:0.008316382812373237\n",
      "train loss:0.011896886133758531\n",
      "train loss:0.004862528796238634\n",
      "train loss:0.009281001489695923\n",
      "train loss:0.03251930982542668\n",
      "train loss:0.009466416466595436\n",
      "train loss:0.0023306930515814834\n",
      "train loss:0.00810338831231234\n",
      "train loss:0.011995630039269187\n",
      "train loss:0.004404691558723067\n",
      "train loss:0.009900585714250105\n",
      "train loss:0.0021562103538172008\n",
      "train loss:0.014428813605873178\n",
      "train loss:0.0038112367394504197\n",
      "train loss:0.00335129085985606\n",
      "train loss:0.018372003581044852\n",
      "train loss:0.028732883920888828\n",
      "train loss:0.0026074493525836463\n",
      "train loss:0.002677553171304617\n",
      "train loss:0.006304065472934216\n",
      "train loss:0.0055884393962056566\n",
      "train loss:0.006712089774105407\n",
      "train loss:0.012790641139230334\n",
      "train loss:0.0023484252329466025\n",
      "train loss:0.01152546768201754\n",
      "train loss:0.01481797767650387\n",
      "train loss:0.01939351605082221\n",
      "train loss:0.009553675133329555\n",
      "train loss:0.0010599321536608553\n",
      "train loss:0.010173470041645361\n",
      "train loss:0.006751720347748461\n",
      "train loss:0.007223978249424033\n",
      "train loss:0.025115444911351526\n",
      "train loss:0.013418469820492137\n",
      "train loss:0.0012511304445415369\n",
      "train loss:0.007433782091865001\n",
      "train loss:0.023304890908106744\n",
      "train loss:0.06506394625465142\n",
      "train loss:0.015491539357696687\n",
      "train loss:0.0024117051422664136\n",
      "train loss:0.01114341047690269\n",
      "train loss:0.004658195483860084\n",
      "train loss:0.007555726957792607\n",
      "train loss:0.011406308493465094\n",
      "train loss:0.02704550101602175\n",
      "train loss:0.006879276358803492\n",
      "train loss:0.001983977345751687\n",
      "train loss:0.019354071702425545\n",
      "train loss:0.01106583895434211\n",
      "train loss:0.007743476820548711\n",
      "train loss:0.01283807666001991\n",
      "train loss:0.001162684638677518\n",
      "train loss:0.012276899299270394\n",
      "train loss:0.003631330149883511\n",
      "train loss:0.008723492691657958\n",
      "train loss:0.0017008156329369822\n",
      "train loss:0.0017053417285424405\n",
      "train loss:0.024152151339547033\n",
      "train loss:0.004413595309888825\n",
      "train loss:0.003819512460355731\n",
      "train loss:0.0034538992746909595\n",
      "train loss:0.011426098760218098\n",
      "train loss:0.008110447722531973\n",
      "train loss:0.0005772006004668958\n",
      "train loss:0.006367506570797223\n",
      "train loss:0.003492784999587306\n",
      "train loss:0.003044840170308959\n",
      "train loss:0.0019997570179098325\n",
      "train loss:0.072389362756111\n",
      "train loss:0.017855128371446448\n",
      "train loss:0.006872979414433504\n",
      "train loss:0.0009564663906234217\n",
      "train loss:0.002447574701921178\n",
      "train loss:0.01833312795170206\n",
      "train loss:0.01886399472748143\n",
      "train loss:0.0027867110822928755\n",
      "train loss:0.07396467499235776\n",
      "train loss:0.0052861751736459316\n",
      "train loss:0.001110574125050791\n",
      "train loss:0.0023668870609397717\n",
      "train loss:0.0116057437370059\n",
      "train loss:0.06937922408400105\n",
      "train loss:0.01914412074997827\n",
      "train loss:0.0018023980171421358\n",
      "train loss:0.004053603422134625\n",
      "train loss:0.010412710308687734\n",
      "train loss:0.001070451425953256\n",
      "train loss:0.004555892121801614\n",
      "train loss:0.011050132014509743\n",
      "train loss:0.0012554144232820774\n",
      "train loss:0.023315061621285063\n",
      "train loss:0.005375026401837397\n",
      "train loss:0.05455050580341595\n",
      "train loss:0.020759004420452514\n",
      "train loss:0.011352810597615483\n",
      "train loss:0.002653214222531988\n",
      "train loss:0.0045910708212384575\n",
      "train loss:0.004890962122954043\n",
      "train loss:0.007947444721894344\n",
      "train loss:0.003459586618852369\n",
      "train loss:0.004437532485985916\n",
      "train loss:0.021125623118238224\n",
      "train loss:0.0014448807162589744\n",
      "train loss:0.012332856764553772\n",
      "train loss:0.008948120547391676\n",
      "train loss:0.0036699868744554504\n",
      "train loss:0.0013606826531361435\n",
      "train loss:0.02551614083767718\n",
      "train loss:0.03700136447584456\n",
      "train loss:0.008065608158735476\n",
      "train loss:0.0036542764010425925\n",
      "train loss:0.001798377065965476\n",
      "train loss:0.004818622240396464\n",
      "train loss:0.02648412814875106\n",
      "train loss:0.00210969040213681\n",
      "train loss:0.04369310730902734\n",
      "train loss:0.000517325663592912\n",
      "train loss:0.05853247868407532\n",
      "train loss:0.027653994197147095\n",
      "train loss:0.007779105706985253\n",
      "train loss:0.00435026086397663\n",
      "train loss:0.013218439146111672\n",
      "train loss:0.0029434371207314393\n",
      "train loss:0.0009990632715831031\n",
      "train loss:0.005152251616413997\n",
      "train loss:0.013152583485930337\n",
      "train loss:0.0126091326915788\n",
      "train loss:0.0020423656565439364\n",
      "train loss:0.007421826323025465\n",
      "train loss:0.004521573583592049\n",
      "train loss:0.026979757537006082\n",
      "train loss:0.012873340853191528\n",
      "train loss:0.007546335033543441\n",
      "train loss:0.011610006526886934\n",
      "train loss:0.0031460480233986917\n",
      "train loss:0.05076529262807073\n",
      "train loss:0.0034912802905598945\n",
      "train loss:0.011484722428427442\n",
      "train loss:0.018870533145124536\n",
      "train loss:0.005403464708730686\n",
      "train loss:0.008713120869991571\n",
      "train loss:0.008447379516249917\n",
      "train loss:0.008903693736869901\n",
      "train loss:0.01029490787118217\n",
      "train loss:0.01138924102720887\n",
      "train loss:0.003325090903460109\n",
      "train loss:0.007651354765072078\n",
      "train loss:0.01189070533550998\n",
      "train loss:0.02258059475290638\n",
      "train loss:0.006748839237960867\n",
      "train loss:0.01449826278249664\n",
      "train loss:0.054468287053188666\n",
      "train loss:0.012392601227873935\n",
      "train loss:0.021107208830142502\n",
      "train loss:0.0030228359288141204\n",
      "train loss:0.0023950376303052703\n",
      "train loss:0.00432502306503672\n",
      "train loss:0.007523264532137666\n",
      "train loss:0.002353001378500739\n",
      "train loss:0.006546095093492435\n",
      "train loss:0.009481130955862154\n",
      "train loss:0.02055679265517505\n",
      "train loss:0.012999528314435942\n",
      "train loss:0.015405058895115207\n",
      "train loss:0.001154047182823279\n",
      "train loss:0.006576150055368918\n",
      "train loss:0.024373413237018644\n",
      "train loss:0.006430836369594679\n",
      "train loss:0.002892795381607754\n",
      "train loss:0.04082022543853735\n",
      "train loss:0.008002973532175434\n",
      "train loss:0.003563985592218974\n",
      "train loss:0.013739635763404652\n",
      "train loss:0.010877868279482075\n",
      "train loss:0.009777370629243975\n",
      "train loss:0.004335688811482485\n",
      "train loss:0.008081155814670308\n",
      "train loss:0.0051268131354908954\n",
      "train loss:0.0005808082531268866\n",
      "train loss:0.018561851823302788\n",
      "train loss:0.01638964341054351\n",
      "train loss:0.003916762736166648\n",
      "train loss:0.010807668127499767\n",
      "train loss:0.003258703611450455\n",
      "train loss:0.001775625413700674\n",
      "train loss:0.019818451784359817\n",
      "train loss:0.004225989786295575\n",
      "train loss:0.0013501307202869429\n",
      "train loss:0.008319447780802203\n",
      "train loss:0.0034004842874856772\n",
      "train loss:0.0009144848889274571\n",
      "train loss:0.003050595569390495\n",
      "train loss:0.003932677754218688\n",
      "train loss:0.003352576004153235\n",
      "train loss:0.0037917360961573325\n",
      "train loss:0.006714974006467153\n",
      "train loss:0.011788475385388197\n",
      "train loss:0.00225982703597305\n",
      "train loss:0.0009743141284140056\n",
      "train loss:0.004839260699090402\n",
      "train loss:0.0009505641190729664\n",
      "train loss:0.009676697074992899\n",
      "train loss:0.004074351971431155\n",
      "train loss:0.0029118394752905923\n",
      "train loss:0.004834369878900856\n",
      "train loss:0.021731824828784187\n",
      "train loss:0.00249273579079551\n",
      "train loss:0.013237676712375211\n",
      "train loss:0.009962225249639377\n",
      "train loss:0.0033632484722952065\n",
      "train loss:0.002998374799484241\n",
      "train loss:0.001864946288400533\n",
      "train loss:0.007111194718219577\n",
      "train loss:0.0043144429357479044\n",
      "train loss:0.004222096476299563\n",
      "train loss:0.009690951744997529\n",
      "train loss:0.0010533620520346077\n",
      "train loss:0.02006002707473829\n",
      "train loss:0.008674436613140699\n",
      "train loss:0.003571706677673524\n",
      "train loss:0.00785106818874273\n",
      "train loss:0.00407824230022334\n",
      "train loss:0.004306886523688376\n",
      "train loss:0.009113030564168314\n",
      "train loss:0.04312624543407973\n",
      "train loss:0.002209689848497467\n",
      "train loss:0.010013617290310315\n",
      "train loss:0.010446775070137929\n",
      "train loss:0.044937501103744316\n",
      "train loss:0.0035644242083301843\n",
      "train loss:0.003232236353745173\n",
      "train loss:0.007077142813171086\n",
      "train loss:0.0005488779534877613\n",
      "train loss:0.03877070238920546\n",
      "train loss:0.06575768652582653\n",
      "train loss:0.011622711468756175\n",
      "train loss:0.005509009075381662\n",
      "train loss:0.007159333208896443\n",
      "train loss:0.019296828665509937\n",
      "train loss:0.006780198131085962\n",
      "train loss:0.001056035011139521\n",
      "train loss:0.017546905740918127\n",
      "train loss:0.0067999749895837625\n",
      "train loss:0.0022683558054124296\n",
      "train loss:0.04217546085786316\n",
      "train loss:0.01538331796246289\n",
      "train loss:0.0011299023818594866\n",
      "train loss:0.0020813673938115886\n",
      "train loss:0.024121616812201766\n",
      "train loss:0.005621157883139325\n",
      "train loss:0.0005575208066386495\n",
      "train loss:0.000420589572313811\n",
      "train loss:0.030965056719267355\n",
      "train loss:0.011090970664173885\n",
      "train loss:0.0024166405484305283\n",
      "train loss:0.0004438842333031157\n",
      "train loss:0.0008297346480283454\n",
      "train loss:0.009595311933883766\n",
      "train loss:0.0025854867172538103\n",
      "train loss:0.0023472052327535293\n",
      "train loss:0.0035162955381022047\n",
      "train loss:0.000626262663113996\n",
      "train loss:0.001142610178317339\n",
      "train loss:0.0035283305196022498\n",
      "train loss:0.004149891767292654\n",
      "train loss:0.0024721787609528704\n",
      "train loss:0.014808252565578184\n",
      "train loss:0.0005788913197518016\n",
      "train loss:0.004610856970976189\n",
      "train loss:0.0015488514867508338\n",
      "train loss:0.0016897018430900952\n",
      "train loss:0.0007616137004764407\n",
      "train loss:0.007469527684283368\n",
      "train loss:0.021530041750138725\n",
      "=== epoch:10, train acc:0.996, test acc:0.988 ===\n",
      "train loss:0.004769807635175857\n",
      "train loss:0.008918497863608526\n",
      "train loss:0.00885081064404826\n",
      "train loss:0.031960049828593705\n",
      "train loss:0.001922380475032056\n",
      "train loss:0.010172094918804919\n",
      "train loss:0.010184357434215923\n",
      "train loss:0.012099148204802618\n",
      "train loss:0.00018434838470336116\n",
      "train loss:0.010195786303330137\n",
      "train loss:0.003157473970288548\n",
      "train loss:0.0007777781850586419\n",
      "train loss:0.009045485025575069\n",
      "train loss:0.0037692614276917725\n",
      "train loss:0.017937867645654956\n",
      "train loss:0.007584975538696328\n",
      "train loss:0.012753430629614725\n",
      "train loss:0.0007438455586619431\n",
      "train loss:0.00439977780085196\n",
      "train loss:0.0007837547469991265\n",
      "train loss:0.00048440412036466693\n",
      "train loss:0.00251605310337399\n",
      "train loss:0.007662733736028267\n",
      "train loss:0.03024746144688652\n",
      "train loss:0.0008269054361981904\n",
      "train loss:0.0028406482050528674\n",
      "train loss:0.0017465566118663029\n",
      "train loss:0.001510717723457536\n",
      "train loss:0.007215419189242486\n",
      "train loss:0.010768320394314152\n",
      "train loss:0.0009353883915958067\n",
      "train loss:0.0012759743609822075\n",
      "train loss:0.03734443824810341\n",
      "train loss:0.001151456626922292\n",
      "train loss:0.008865317723819542\n",
      "train loss:0.0012108996064012212\n",
      "train loss:0.010523776973839159\n",
      "train loss:0.01077096954419549\n",
      "train loss:0.015121727705284431\n",
      "train loss:0.021745835675373602\n",
      "train loss:0.030515035388871223\n",
      "train loss:0.038166120306744294\n",
      "train loss:0.003537825437133439\n",
      "train loss:0.001789090414788394\n",
      "train loss:0.002397090823860265\n",
      "train loss:0.020722711240684092\n",
      "train loss:0.002623729878904244\n",
      "train loss:0.00634445501347865\n",
      "train loss:0.014234460914009534\n",
      "train loss:0.05376682905966821\n",
      "train loss:0.03293974759964212\n",
      "train loss:0.0022104612673977094\n",
      "train loss:0.06020746885742903\n",
      "train loss:0.005407437786422402\n",
      "train loss:0.034331402479650774\n",
      "train loss:0.003979826072238964\n",
      "train loss:0.005470777130773877\n",
      "train loss:0.007759829567891376\n",
      "train loss:0.003973071048745472\n",
      "train loss:0.01232235484904103\n",
      "train loss:0.003214690681780691\n",
      "train loss:0.002548114257935972\n",
      "train loss:0.05373604034020676\n",
      "train loss:0.02188909488718667\n",
      "train loss:0.02718889311759612\n",
      "train loss:0.0029015792690975217\n",
      "train loss:0.012380220040806553\n",
      "train loss:0.0011770571697995163\n",
      "train loss:0.010052826114023092\n",
      "train loss:0.007622909078710965\n",
      "train loss:0.0022202769280283583\n",
      "train loss:0.002293126488963274\n",
      "train loss:0.01581370759230262\n",
      "train loss:0.008108313135528204\n",
      "train loss:0.0014509899609430796\n",
      "train loss:0.0019229332018182357\n",
      "train loss:0.02459384756983536\n",
      "train loss:0.0038877463359717214\n",
      "train loss:0.0038252160734517275\n",
      "train loss:0.0024525386921119357\n",
      "train loss:0.005430022796843192\n",
      "train loss:0.0038214670803550736\n",
      "train loss:0.005089405629392927\n",
      "train loss:0.010250828863111407\n",
      "train loss:0.009551725033177425\n",
      "train loss:0.004813826079948993\n",
      "train loss:0.018879959126606935\n",
      "train loss:0.0023067408731794544\n",
      "train loss:0.0057739870945684\n",
      "train loss:0.0068599826411871526\n",
      "train loss:0.004739524509162515\n",
      "train loss:0.00989871977265591\n",
      "train loss:0.0022075126285057093\n",
      "train loss:0.0016646026796529464\n",
      "train loss:0.0038654909869709547\n",
      "train loss:0.0037485466784578135\n",
      "train loss:0.009559063752986098\n",
      "train loss:0.007145418801751272\n",
      "train loss:0.0025956089641355085\n",
      "train loss:0.0014596032898597255\n",
      "train loss:0.014766157872397349\n",
      "train loss:0.004410750100127341\n",
      "train loss:0.007005466440254067\n",
      "train loss:0.0013438503261299956\n",
      "train loss:0.01271555960641214\n",
      "train loss:0.006719460711087669\n",
      "train loss:0.010841823986932515\n",
      "train loss:0.003874892210176327\n",
      "train loss:0.04977716695774609\n",
      "train loss:0.03981516702420435\n",
      "train loss:0.003986112421259941\n",
      "train loss:0.018654832827243235\n",
      "train loss:0.010427713660888708\n",
      "train loss:0.0033337007066943673\n",
      "train loss:0.004136698702926686\n",
      "train loss:0.0063787142790209675\n",
      "train loss:0.006219522804005678\n",
      "train loss:0.0019768275702891276\n",
      "train loss:0.01726622838456835\n",
      "train loss:0.005193095478454095\n",
      "train loss:0.005582983161478284\n",
      "train loss:0.01007514472434087\n",
      "train loss:0.007346636770278446\n",
      "train loss:0.0020258003643070246\n",
      "train loss:0.005684414156591676\n",
      "train loss:0.004051999822379613\n",
      "train loss:0.0046399975334697145\n",
      "train loss:0.008635155572083142\n",
      "train loss:0.002681533599489757\n",
      "train loss:0.014343141512664493\n",
      "train loss:0.009427649874214922\n",
      "train loss:0.014153327413289578\n",
      "train loss:0.007331075777129752\n",
      "train loss:0.003632502233397344\n",
      "train loss:0.0004369849309650804\n",
      "train loss:0.00584044263662929\n",
      "train loss:0.006124118889849498\n",
      "train loss:0.022647475441140846\n",
      "train loss:0.0034961416787982124\n",
      "train loss:0.0038574763858109495\n",
      "train loss:0.0012636254454410386\n",
      "train loss:0.024131808972539567\n",
      "train loss:0.017571318738397835\n",
      "train loss:0.003681345644646452\n",
      "train loss:0.004857360972281541\n",
      "train loss:0.004326032277720952\n",
      "train loss:0.002821621630857597\n",
      "train loss:0.004913693353839398\n",
      "train loss:0.007660697486210023\n",
      "train loss:0.004359986850433294\n",
      "train loss:0.0032153341035370594\n",
      "train loss:0.014037380207854475\n",
      "train loss:0.015472808395851093\n",
      "train loss:0.0003730686919841611\n",
      "train loss:0.0036483599719178967\n",
      "train loss:0.000794786239282713\n",
      "train loss:0.006086213025679045\n",
      "train loss:0.003163097083644605\n",
      "train loss:0.018958895594909445\n",
      "train loss:0.004510539111122992\n",
      "train loss:0.006824370509938556\n",
      "train loss:0.00524124143231268\n",
      "train loss:0.0023808856572268017\n",
      "train loss:0.0011266233755455367\n",
      "train loss:0.0015052573823060508\n",
      "train loss:0.0009741090231969129\n",
      "train loss:0.004256260098575149\n",
      "train loss:0.0045975574197401805\n",
      "train loss:0.0018496699399939492\n",
      "train loss:0.008886781042473733\n",
      "train loss:0.0048984574769386025\n",
      "train loss:0.006647356091537016\n",
      "train loss:0.007027126428604914\n",
      "train loss:0.010059146690888953\n",
      "train loss:0.0011488315738670354\n",
      "train loss:0.003972162758572987\n",
      "train loss:0.0021501945273053025\n",
      "train loss:0.0037754137106611866\n",
      "train loss:0.0030989882577224944\n",
      "train loss:0.0021635636494124547\n",
      "train loss:0.002602920324207762\n",
      "train loss:0.011024725645482427\n",
      "train loss:0.0017400559047119838\n",
      "train loss:0.002729254952781695\n",
      "train loss:0.0023731702678385976\n",
      "train loss:0.004294487039459234\n",
      "train loss:0.014160693452315345\n",
      "train loss:0.002472855304015343\n",
      "train loss:0.007752146087592571\n",
      "train loss:0.0023805320658141166\n",
      "train loss:0.004832571301736243\n",
      "train loss:0.0039467132690590824\n",
      "train loss:0.010490303428354435\n",
      "train loss:0.006472172215681229\n",
      "train loss:0.0005059139810279962\n",
      "train loss:0.010849890020196104\n",
      "train loss:0.0020512020869747206\n",
      "train loss:0.0015959786488630478\n",
      "train loss:0.018917308871123008\n",
      "train loss:0.010021545509658572\n",
      "train loss:0.029590747333483266\n",
      "train loss:0.0045988409766192\n",
      "train loss:0.0049016636220725295\n",
      "train loss:0.027783610005382493\n",
      "train loss:0.0024406870092911147\n",
      "train loss:0.003084849296379098\n",
      "train loss:0.0012582901296990542\n",
      "train loss:0.00470858535111511\n",
      "train loss:0.007244675118713822\n",
      "train loss:0.0010059278167611151\n",
      "train loss:0.003387209926907742\n",
      "train loss:0.004922214429201136\n",
      "train loss:0.01171244730708591\n",
      "train loss:0.010784392314286986\n",
      "train loss:0.02424932109141426\n",
      "train loss:0.002449504999671237\n",
      "train loss:0.014579609087714931\n",
      "train loss:0.001204238928899346\n",
      "train loss:0.002386646275829224\n",
      "train loss:0.0037291798218166013\n",
      "train loss:0.0023551813021324046\n",
      "train loss:0.006126413451316513\n",
      "train loss:0.0013171117897529234\n",
      "train loss:0.0076876814633235905\n",
      "train loss:0.03479647892581763\n",
      "train loss:0.0024722583015222327\n",
      "train loss:0.001169797989612729\n",
      "train loss:0.005109979649767785\n",
      "train loss:0.0032441984120129535\n",
      "train loss:0.0005261308659540641\n",
      "train loss:0.0069467767422841335\n",
      "train loss:0.01994829973797012\n",
      "train loss:0.009106101700745252\n",
      "train loss:0.006756516101600009\n",
      "train loss:0.0006271710877168912\n",
      "train loss:0.0070573252345301615\n",
      "train loss:0.004885728665979273\n",
      "train loss:0.014240449204874378\n",
      "train loss:0.009293084285097945\n",
      "train loss:0.015209590567025881\n",
      "train loss:0.008227345763633516\n",
      "train loss:0.002593996632364583\n",
      "train loss:0.0009450957201779103\n",
      "train loss:0.0021228517591471404\n",
      "train loss:0.0012171354925109713\n",
      "train loss:0.0009284508866203041\n",
      "train loss:0.0032113198162227615\n",
      "train loss:0.003254560649315242\n",
      "train loss:0.06129223895245115\n",
      "train loss:0.01929130438716952\n",
      "train loss:0.0011730861663185467\n",
      "train loss:0.002378515664176902\n",
      "train loss:0.00856274464655959\n",
      "train loss:0.0023791899052686884\n",
      "train loss:0.002047054875531326\n",
      "train loss:0.009580381964369175\n",
      "train loss:0.004263330871016196\n",
      "train loss:0.0013967436631546143\n",
      "train loss:0.0028501902674284824\n",
      "train loss:0.018924749738068306\n",
      "train loss:0.0017619031823505843\n",
      "train loss:0.00942536160485716\n",
      "train loss:0.014127443320737962\n",
      "train loss:0.009343351654125547\n",
      "train loss:0.011528419664210053\n",
      "train loss:0.0006248045890676942\n",
      "train loss:0.001879621897900399\n",
      "train loss:0.00809599560536667\n",
      "train loss:0.007867984892696349\n",
      "train loss:0.014699888611391774\n",
      "train loss:0.0009826660737666496\n",
      "train loss:0.006133534793934172\n",
      "train loss:0.0037114496145187847\n",
      "train loss:0.0015114583771148118\n",
      "train loss:0.03429674211682531\n",
      "train loss:0.0017739504790345317\n",
      "train loss:0.008511724635148113\n",
      "train loss:0.02082037562756827\n",
      "train loss:0.0005510116867262612\n",
      "train loss:0.0053861331456298775\n",
      "train loss:0.0006688860298318017\n",
      "train loss:0.01030780718798924\n",
      "train loss:0.0570676020477117\n",
      "train loss:0.010195725782406774\n",
      "train loss:0.0074778364230992725\n",
      "train loss:0.004863339715286314\n",
      "train loss:0.00942688945501248\n",
      "train loss:0.008611808732754831\n",
      "train loss:0.0016997748665713637\n",
      "train loss:0.005238101484698269\n",
      "train loss:0.005203107957154218\n",
      "train loss:0.009713356415148026\n",
      "train loss:0.0024946555371667795\n",
      "train loss:0.02210171251782833\n",
      "train loss:0.006302218756874339\n",
      "train loss:0.008666770650911433\n",
      "train loss:0.027200093120170733\n",
      "train loss:0.01045843388373188\n",
      "train loss:0.0008077209892164699\n",
      "train loss:0.00874864418895726\n",
      "train loss:0.012675318140503395\n",
      "train loss:0.005214120812868098\n",
      "train loss:0.00842040595116019\n",
      "train loss:0.0036330488771900153\n",
      "train loss:0.0019238996958706785\n",
      "train loss:0.005820064816266704\n",
      "train loss:0.007847965116806861\n",
      "train loss:0.009734877645548234\n",
      "train loss:0.0038289868097934297\n",
      "train loss:0.0014754687300506278\n",
      "train loss:0.02783416730560051\n",
      "train loss:0.004995312301812577\n",
      "train loss:0.0010416236475487425\n",
      "train loss:0.03713243824525905\n",
      "train loss:0.0005103406519274253\n",
      "train loss:0.004499341651070363\n",
      "train loss:0.004910640573716674\n",
      "train loss:0.0024885505571011473\n",
      "train loss:0.04036525630469759\n",
      "train loss:0.006773493417006747\n",
      "train loss:0.004228986842946717\n",
      "train loss:0.0010164333144801082\n",
      "train loss:0.0017648513245321264\n",
      "train loss:0.0017594984835297156\n",
      "train loss:0.009257609445774062\n",
      "train loss:0.010877132548587878\n",
      "train loss:0.0013261303256463899\n",
      "train loss:0.017832234099256054\n",
      "train loss:0.005637992212922318\n",
      "train loss:0.0021729597697652393\n",
      "train loss:0.001304635544033943\n",
      "train loss:0.0014456365937742458\n",
      "train loss:0.0029802352312889085\n",
      "train loss:0.005877062165144502\n",
      "train loss:0.0023184092120770846\n",
      "train loss:0.00032997779108960524\n",
      "train loss:0.0030719864861904317\n",
      "train loss:0.004348083413987297\n",
      "train loss:0.009291644206979154\n",
      "train loss:0.00885951738914527\n",
      "train loss:0.0006512485317003177\n",
      "train loss:0.011476943915239462\n",
      "train loss:0.0033492951266266375\n",
      "train loss:0.008112702932199164\n",
      "train loss:0.010359111553469804\n",
      "train loss:0.019897186330050946\n",
      "train loss:0.0066556970113252\n",
      "train loss:0.004330950969321185\n",
      "train loss:0.0037581919692738675\n",
      "train loss:0.026081071128686805\n",
      "train loss:0.0001903144015582616\n",
      "train loss:0.003839317330122607\n",
      "train loss:0.001180872875612584\n",
      "train loss:0.016448725536198142\n",
      "train loss:0.0030258468888913407\n",
      "train loss:0.005163788710336913\n",
      "train loss:0.005892201678250807\n",
      "train loss:0.003309774850860596\n",
      "train loss:0.07214345657631498\n",
      "train loss:0.019383099624103298\n",
      "train loss:0.0019319209289455886\n",
      "train loss:0.023013428121136843\n",
      "train loss:0.005508046956962965\n",
      "train loss:0.004405309796042614\n",
      "train loss:0.01790276760605915\n",
      "train loss:0.005635463490791189\n",
      "train loss:0.01782482695551004\n",
      "train loss:0.009905943911790952\n",
      "train loss:0.0025239323476259536\n",
      "train loss:0.01000755352787463\n",
      "train loss:0.0037335151929852066\n",
      "train loss:0.06038252815328348\n",
      "train loss:0.005871152185611826\n",
      "train loss:0.023771105763970804\n",
      "train loss:0.00409845059596734\n",
      "train loss:0.005352092374224623\n",
      "train loss:0.004647737496068496\n",
      "train loss:0.004764896827641848\n",
      "train loss:0.0017849212858781546\n",
      "train loss:0.0077643180043006285\n",
      "train loss:0.0023991692132161336\n",
      "train loss:0.006853620706758117\n",
      "train loss:0.013247854300520879\n",
      "train loss:0.005083058517003095\n",
      "train loss:0.005608703912010599\n",
      "train loss:0.005632823902343933\n",
      "train loss:0.006525756968453235\n",
      "train loss:0.002678020209404382\n",
      "train loss:0.032039851195943596\n",
      "train loss:0.0019169491361697053\n",
      "train loss:0.004084176165596956\n",
      "train loss:0.000823261513625203\n",
      "train loss:0.0076694799472719535\n",
      "train loss:0.0041866255892656105\n",
      "train loss:0.0012774573608916445\n",
      "train loss:0.012864270413629607\n",
      "train loss:0.020106259785270062\n",
      "train loss:0.0015274634239284405\n",
      "train loss:0.011335321728175479\n",
      "train loss:0.012027779979762515\n",
      "train loss:0.014904378868182999\n",
      "train loss:0.0013738088287085074\n",
      "train loss:0.0021239545409897555\n",
      "train loss:0.004277680963145149\n",
      "train loss:0.009263551684868554\n",
      "train loss:0.006559404964815696\n",
      "train loss:0.008551636678556367\n",
      "train loss:0.0011074652893174742\n",
      "train loss:0.00478624591371834\n",
      "train loss:0.0024078990214945694\n",
      "train loss:0.0011831313946151598\n",
      "train loss:0.002005553160327093\n",
      "train loss:0.06043877952762089\n",
      "train loss:0.020699796428226266\n",
      "train loss:0.006487931507367789\n",
      "train loss:0.0010519730986352865\n",
      "train loss:0.0017501517954046969\n",
      "train loss:0.027429663755637407\n",
      "train loss:0.005546207724185739\n",
      "train loss:0.004010179363313751\n",
      "train loss:0.004243813938794551\n",
      "train loss:0.024474807115442202\n",
      "train loss:0.002175474594028856\n",
      "train loss:0.005916314444771506\n",
      "train loss:0.013213847669856121\n",
      "train loss:0.002446772046395081\n",
      "train loss:0.0025348927358499994\n",
      "train loss:0.005654953823472918\n",
      "train loss:0.00045827721733918765\n",
      "train loss:0.0006551606573214769\n",
      "train loss:0.01933594587774173\n",
      "train loss:0.00423945940939413\n",
      "train loss:0.015381621138958485\n",
      "train loss:0.006282996411865252\n",
      "train loss:0.03525662240433938\n",
      "train loss:0.00041510107992272704\n",
      "train loss:0.006808611071602561\n",
      "train loss:0.005426385083985201\n",
      "train loss:0.004532953779827532\n",
      "train loss:0.004597384184415196\n",
      "train loss:0.003343871116988441\n",
      "train loss:0.005121300264525414\n",
      "train loss:0.008744370499815914\n",
      "train loss:0.01540765394020274\n",
      "train loss:0.061686306915832274\n",
      "train loss:0.009521075484922948\n",
      "train loss:0.0021863514463396475\n",
      "train loss:0.0007941543076524476\n",
      "train loss:0.001157400459048402\n",
      "train loss:0.009174412085810796\n",
      "train loss:0.0069388450937575286\n",
      "train loss:0.0010547724624612798\n",
      "train loss:0.006439068398675366\n",
      "train loss:0.0016964604692533292\n",
      "train loss:0.002191493590917878\n",
      "train loss:0.025269867231363215\n",
      "train loss:0.0025160547283201405\n",
      "train loss:0.00465981179732535\n",
      "train loss:0.004235883700731998\n",
      "train loss:0.0007525722526375618\n",
      "train loss:0.00030593449699442717\n",
      "train loss:0.004414358399894667\n",
      "train loss:0.005847795886056138\n",
      "train loss:0.00603092100218542\n",
      "train loss:0.0005501455730671595\n",
      "train loss:0.00033276889797307204\n",
      "train loss:0.003477724186259506\n",
      "train loss:0.0029565913670862505\n",
      "train loss:0.005389879613911024\n",
      "train loss:0.005887480007832326\n",
      "train loss:0.0038185320038692195\n",
      "train loss:0.013008832162532872\n",
      "train loss:0.004645737565555297\n",
      "train loss:0.0019816071141820365\n",
      "train loss:0.012675487064458249\n",
      "train loss:0.007530429682936459\n",
      "train loss:0.0015117663754934563\n",
      "train loss:0.017760585741392755\n",
      "train loss:0.007290373510691828\n",
      "train loss:0.0030105339031913647\n",
      "train loss:0.026196592758436263\n",
      "train loss:0.0008236148367812983\n",
      "train loss:0.0027683623051135784\n",
      "train loss:0.025731146256536778\n",
      "train loss:0.00612807676879654\n",
      "train loss:0.015686618480553617\n",
      "train loss:0.014111219997148332\n",
      "train loss:0.0044252936068558115\n",
      "train loss:0.004483484832350088\n",
      "train loss:0.000933543499523792\n",
      "train loss:0.006794535093502628\n",
      "train loss:0.027174613575651176\n",
      "train loss:0.0031879200936106044\n",
      "train loss:0.008713140202251519\n",
      "train loss:0.0062286896480309665\n",
      "train loss:0.0010829519455915202\n",
      "train loss:0.005074203973032849\n",
      "train loss:0.017741746484469006\n",
      "train loss:0.006660526220373267\n",
      "train loss:0.004337604545221209\n",
      "train loss:0.002541459690015424\n",
      "train loss:0.002186244920630871\n",
      "train loss:0.011474023181157993\n",
      "train loss:0.0004441136048928821\n",
      "train loss:0.0064646642616400015\n",
      "train loss:0.007215326659749023\n",
      "train loss:0.017669898840076734\n",
      "train loss:0.00184111453464962\n",
      "train loss:0.0176128744628826\n",
      "train loss:0.05730238661480166\n",
      "train loss:0.002303397805952682\n",
      "train loss:0.007178226471719428\n",
      "train loss:0.008605415125846843\n",
      "train loss:0.0028743776109402563\n",
      "train loss:0.010329613926685884\n",
      "train loss:0.012338670121007998\n",
      "train loss:0.006171400681600479\n",
      "train loss:0.00517916703947329\n",
      "train loss:0.000743053345534321\n",
      "train loss:0.007818994511356956\n",
      "train loss:0.0032575488082408344\n",
      "train loss:0.01400398923205315\n",
      "train loss:0.004561245816111383\n",
      "train loss:0.013395969925949101\n",
      "train loss:0.005306808019061846\n",
      "train loss:0.0022723054685893336\n",
      "train loss:0.03974291238732406\n",
      "train loss:0.009314334419803637\n",
      "train loss:0.006997121392318903\n",
      "train loss:0.003373880720582346\n",
      "train loss:0.0038311564045204133\n",
      "train loss:0.04166949071207828\n",
      "train loss:0.01019286724350364\n",
      "train loss:0.002293367846489203\n",
      "train loss:0.0182615396847936\n",
      "train loss:0.0037276783951813277\n",
      "train loss:0.002431213222970528\n",
      "train loss:0.0024356406906120135\n",
      "train loss:0.002136501199889511\n",
      "train loss:0.010428957673203884\n",
      "train loss:0.00517442733362409\n",
      "train loss:0.008861146420634484\n",
      "train loss:0.02301930205821988\n",
      "train loss:0.000842000575666964\n",
      "train loss:0.007357598229895071\n",
      "train loss:0.014635309090111284\n",
      "train loss:0.0013086642567332102\n",
      "train loss:0.0035503282985583427\n",
      "train loss:0.005629928683982211\n",
      "train loss:0.001267227705376151\n",
      "train loss:0.0048582347045422235\n",
      "train loss:0.00518078902476815\n",
      "train loss:0.003913183033505494\n",
      "train loss:0.0021071457951286595\n",
      "train loss:0.00827741928019411\n",
      "train loss:0.007201203765496565\n",
      "train loss:0.0006063121438653154\n",
      "train loss:0.014380720741045747\n",
      "train loss:0.005061212108108996\n",
      "train loss:0.015146740385783597\n",
      "train loss:0.0013058995069111312\n",
      "train loss:0.0029862511241567124\n",
      "train loss:0.006565786398559288\n",
      "train loss:0.003926241605026562\n",
      "train loss:0.006763358585743674\n",
      "train loss:0.0010629851132904077\n",
      "train loss:0.006089924337737858\n",
      "train loss:0.0033689675787306845\n",
      "train loss:0.0012097132034825126\n",
      "train loss:0.00551900140152071\n",
      "train loss:0.0017602258631144122\n",
      "train loss:0.013241581912059583\n",
      "train loss:0.002174259494702564\n",
      "train loss:0.005671817582608576\n",
      "train loss:0.0025992991385106684\n",
      "train loss:0.0018352603751528452\n",
      "train loss:0.002362946787525306\n",
      "train loss:0.009318536358717157\n",
      "train loss:0.004049778312961351\n",
      "train loss:0.010277371651696532\n",
      "train loss:0.011926353506375416\n",
      "train loss:0.02497635453706222\n",
      "train loss:0.007354507757536717\n",
      "train loss:0.0017676310008521963\n",
      "train loss:0.007484427944346358\n",
      "train loss:0.008448508854800852\n",
      "train loss:0.003160977633355645\n",
      "train loss:0.009530839963644726\n",
      "train loss:0.05128152610028017\n",
      "train loss:0.001677197857451403\n",
      "train loss:0.0077160500532217945\n",
      "train loss:0.0042305171955691\n",
      "train loss:0.011333836635441533\n",
      "train loss:0.007115205221793808\n",
      "train loss:0.0011790371376046882\n",
      "train loss:0.019098503515671227\n",
      "train loss:0.013647750776885292\n",
      "train loss:0.033522188097873516\n",
      "train loss:0.008665653621354632\n",
      "train loss:0.00040716648954478013\n",
      "=== epoch:11, train acc:0.993, test acc:0.992 ===\n",
      "train loss:0.03270558027071823\n",
      "train loss:0.015350282941588623\n",
      "train loss:0.0016480513177307345\n",
      "train loss:0.005937527488890336\n",
      "train loss:0.010490841995682162\n",
      "train loss:0.002302267690184147\n",
      "train loss:0.0070378862578801835\n",
      "train loss:0.006099058246782166\n",
      "train loss:0.005690340487441259\n",
      "train loss:0.004146180877370775\n",
      "train loss:0.003570261203341027\n",
      "train loss:0.010805371388062741\n",
      "train loss:0.007164543697717372\n",
      "train loss:0.01219610869721449\n",
      "train loss:0.027127417387723108\n",
      "train loss:0.1454731772272466\n",
      "train loss:0.006609901656345395\n",
      "train loss:0.003240509821384619\n",
      "train loss:0.001676342614724341\n",
      "train loss:0.010443814257489465\n",
      "train loss:0.0012043966928777718\n",
      "train loss:0.003783643594597822\n",
      "train loss:0.0018426397005582237\n",
      "train loss:0.002886341592134899\n",
      "train loss:0.025501282327052958\n",
      "train loss:0.0013561728954937333\n",
      "train loss:0.009320872655072022\n",
      "train loss:0.005305304742104677\n",
      "train loss:0.003143258284378798\n",
      "train loss:0.0033668789268493245\n",
      "train loss:0.005474191549137547\n",
      "train loss:0.0017336321757044598\n",
      "train loss:0.039805109837417384\n",
      "train loss:0.007429705780454543\n",
      "train loss:0.009783762907776494\n",
      "train loss:0.0019619063506206335\n",
      "train loss:0.00465592777587217\n",
      "train loss:0.007353749148566395\n",
      "train loss:0.0023610560785384998\n",
      "train loss:0.0020218924571681536\n",
      "train loss:0.0025349633116932397\n",
      "train loss:0.0031897001121204776\n",
      "train loss:0.019151606425556654\n",
      "train loss:0.0010735862955129417\n",
      "train loss:0.010627482398782782\n",
      "train loss:0.0018916897425240618\n",
      "train loss:0.0021717894380946954\n",
      "train loss:0.000767695481522771\n",
      "train loss:0.004657343081151139\n",
      "train loss:0.00476828818971126\n",
      "train loss:0.0016791215790098444\n",
      "train loss:0.0053396586486594965\n",
      "train loss:0.03403772041166965\n",
      "train loss:0.011622347170342185\n",
      "train loss:0.0029624998013968317\n",
      "train loss:0.023165456163932757\n",
      "train loss:0.0022780361073844813\n",
      "train loss:0.0011419118161119944\n",
      "train loss:0.009259721345446992\n",
      "train loss:0.04412402456072813\n",
      "train loss:0.023504949547358347\n",
      "train loss:0.01003150790481177\n",
      "train loss:0.0010241270877223991\n",
      "train loss:0.00664488254869292\n",
      "train loss:0.0244854724169761\n",
      "train loss:0.007152813890090045\n",
      "train loss:0.03874981840520538\n",
      "train loss:0.0085565826741418\n",
      "train loss:0.01850071554753491\n",
      "train loss:0.005211949372075964\n",
      "train loss:0.00649350167603541\n",
      "train loss:0.007330766384416095\n",
      "train loss:0.004838212385598836\n",
      "train loss:0.0006240055057231063\n",
      "train loss:0.006530849761044955\n",
      "train loss:0.007213674186897398\n",
      "train loss:0.007690518750155868\n",
      "train loss:0.004201204305667379\n",
      "train loss:0.001212190287321401\n",
      "train loss:0.0014684035585818423\n",
      "train loss:0.0018973072527122487\n",
      "train loss:0.00433776713859156\n",
      "train loss:0.0023233737883822433\n",
      "train loss:0.0026815158428071255\n",
      "train loss:0.003111369432362931\n",
      "train loss:0.016562051397028595\n",
      "train loss:0.002484141772445697\n",
      "train loss:0.0025266593392873865\n",
      "train loss:0.0104316883173247\n",
      "train loss:0.0035359282044990265\n",
      "train loss:0.0061591198853157315\n",
      "train loss:0.0019264227205033997\n",
      "train loss:0.004849448487292398\n",
      "train loss:0.06472279650838172\n",
      "train loss:0.001776599695574461\n",
      "train loss:0.0030677564135607217\n",
      "train loss:0.04337227022751611\n",
      "train loss:0.003797741374305953\n",
      "train loss:0.02170140884237443\n",
      "train loss:0.016966531476589303\n",
      "train loss:0.005965561131590881\n",
      "train loss:0.0009694438590534874\n",
      "train loss:0.0023935723931344717\n",
      "train loss:0.004666738187128613\n",
      "train loss:0.021385416102110998\n",
      "train loss:0.018053815611924377\n",
      "train loss:0.00900177040025331\n",
      "train loss:0.003412522101992563\n",
      "train loss:0.010254039376254744\n",
      "train loss:0.0045597537349187775\n",
      "train loss:0.02190364188444376\n",
      "train loss:0.0008198166323171338\n",
      "train loss:0.009252501651418917\n",
      "train loss:0.03181677702270825\n",
      "train loss:0.011609107301640068\n",
      "train loss:0.006599401428716547\n",
      "train loss:0.0004692666785253367\n",
      "train loss:0.009060231485323792\n",
      "train loss:0.021827622104002367\n",
      "train loss:0.002042939009420706\n",
      "train loss:0.0019091126785263535\n",
      "train loss:0.0016606189582914848\n",
      "train loss:0.009244256720798089\n",
      "train loss:0.051383331122384586\n",
      "train loss:0.0029074523340776193\n",
      "train loss:0.01367508654388546\n",
      "train loss:0.0012004025496914982\n",
      "train loss:0.0027404523886408317\n",
      "train loss:0.012394521892268053\n",
      "train loss:0.012681838304788529\n",
      "train loss:0.022280311701021707\n",
      "train loss:0.00386720862574526\n",
      "train loss:0.0044811761546970355\n",
      "train loss:0.0050187508378639785\n",
      "train loss:0.007751125928339315\n",
      "train loss:0.0014255855089379632\n",
      "train loss:0.002749102487610895\n",
      "train loss:0.005429756561654325\n",
      "train loss:0.038289472851593384\n",
      "train loss:0.006784058327767989\n",
      "train loss:0.005594606812595776\n",
      "train loss:0.005601950069808442\n",
      "train loss:0.0022718328446717194\n",
      "train loss:0.007487224754707905\n",
      "train loss:0.01108068288059788\n",
      "train loss:0.0032537817613219437\n",
      "train loss:0.0017603968972558352\n",
      "train loss:0.002101813383068481\n",
      "train loss:0.002523423668868622\n",
      "train loss:0.013017891663089245\n",
      "train loss:0.0014738942668443738\n",
      "train loss:0.006172245884934084\n",
      "train loss:0.015757964486332546\n",
      "train loss:0.0019376851889569904\n",
      "train loss:0.003624334638874233\n",
      "train loss:0.006082506652336546\n",
      "train loss:0.004750947641456689\n",
      "train loss:0.0037634580424478715\n",
      "train loss:0.007495302581206557\n",
      "train loss:0.006915412305037888\n",
      "train loss:0.010144191686331733\n",
      "train loss:0.02561377433892809\n",
      "train loss:0.054588285043457765\n",
      "train loss:0.012802862348774252\n",
      "train loss:0.039418500141823826\n",
      "train loss:0.0026988541498152614\n",
      "train loss:0.003433202449038468\n",
      "train loss:0.00864249172815929\n",
      "train loss:0.02078457391920877\n",
      "train loss:0.0017490764186464162\n",
      "train loss:0.003011234393187304\n",
      "train loss:0.051572453261010134\n",
      "train loss:0.0050491510974150665\n",
      "train loss:0.030859655838043554\n",
      "train loss:0.007036264764632721\n",
      "train loss:0.007641361466473804\n",
      "train loss:0.0010178153785947099\n",
      "train loss:0.001941567378592587\n",
      "train loss:0.0026063136854211784\n",
      "train loss:0.005022351025396291\n",
      "train loss:0.0016686096130616912\n",
      "train loss:0.0014204700773465778\n",
      "train loss:0.011725725020774512\n",
      "train loss:0.0027944699855967266\n",
      "train loss:0.020944527811388638\n",
      "train loss:0.011932692639047863\n",
      "train loss:0.0018416494429642019\n",
      "train loss:0.0037652259274494966\n",
      "train loss:0.014825307674002692\n",
      "train loss:0.021431494806919006\n",
      "train loss:0.0021776416689405736\n",
      "train loss:0.002211419570197743\n",
      "train loss:0.0038784524945917388\n",
      "train loss:0.003303913937289979\n",
      "train loss:0.005257962714861162\n",
      "train loss:0.009219827042616048\n",
      "train loss:0.015689653604810967\n",
      "train loss:0.004772296145600754\n",
      "train loss:0.05901294343218374\n",
      "train loss:0.003092344740797412\n",
      "train loss:0.01293016133583686\n",
      "train loss:0.0049766300206691505\n",
      "train loss:0.0016392780167394678\n",
      "train loss:0.015395100801716986\n",
      "train loss:0.010942040526408223\n",
      "train loss:0.003154896178466525\n",
      "train loss:0.005146471119444689\n",
      "train loss:0.004049534634153318\n",
      "train loss:0.01740953570264728\n",
      "train loss:0.06422776516540375\n",
      "train loss:0.0021970033409718643\n",
      "train loss:0.00577791674579448\n",
      "train loss:0.004745174498792784\n",
      "train loss:0.0038120085314480873\n",
      "train loss:0.018396485958908155\n",
      "train loss:0.001892851422600731\n",
      "train loss:0.001764635710859623\n",
      "train loss:0.0017601682883598396\n",
      "train loss:0.0004949079292825788\n",
      "train loss:0.003990270363672751\n",
      "train loss:0.0017385436695800387\n",
      "train loss:0.007955811910837822\n",
      "train loss:0.0012128915987181883\n",
      "train loss:0.015975332157212755\n",
      "train loss:0.00318297472555744\n",
      "train loss:0.0016110435637916843\n",
      "train loss:0.007514492418741225\n",
      "train loss:0.0037309732384240846\n",
      "train loss:0.004650889763289779\n",
      "train loss:0.002581825146767185\n",
      "train loss:0.002938353587149635\n",
      "train loss:0.0028545602944590313\n",
      "train loss:0.0017366031598948781\n",
      "train loss:0.014892993276866835\n",
      "train loss:0.01928407764313757\n",
      "train loss:0.004104691346791937\n",
      "train loss:0.002185654634180416\n",
      "train loss:0.002270536985933285\n",
      "train loss:0.03879572529525062\n",
      "train loss:0.001033437655475134\n",
      "train loss:0.002151740799342321\n",
      "train loss:0.0005579505839253026\n",
      "train loss:0.0029499626570214394\n",
      "train loss:0.003629231716539904\n",
      "train loss:0.0021122176121443226\n",
      "train loss:0.0036395499297260676\n",
      "train loss:0.09838623786408336\n",
      "train loss:0.0038151926889299147\n",
      "train loss:0.009793923521190455\n",
      "train loss:0.00010516962471418855\n",
      "train loss:0.005076317183005535\n",
      "train loss:0.00020530807688113936\n",
      "train loss:0.0014013907042907362\n",
      "train loss:0.018193453754851218\n",
      "train loss:0.01799876385692302\n",
      "train loss:0.01095139892533771\n",
      "train loss:0.003511971647937155\n",
      "train loss:0.0030311833867956196\n",
      "train loss:0.0003045550961872056\n",
      "train loss:0.01979442199853951\n",
      "train loss:0.0010443934587209007\n",
      "train loss:0.0012112721709145007\n",
      "train loss:0.011986746904780994\n",
      "train loss:0.004326611446396362\n",
      "train loss:0.023321144978781013\n",
      "train loss:0.0047887883924486755\n",
      "train loss:0.008037967966923517\n",
      "train loss:0.009682125060337323\n",
      "train loss:0.00027706570860590275\n",
      "train loss:0.006504465998736189\n",
      "train loss:0.004454863007548621\n",
      "train loss:0.001087888430087393\n",
      "train loss:0.0022981632135418433\n",
      "train loss:0.006788763763209831\n",
      "train loss:0.0032029164059618202\n",
      "train loss:0.0004856693029245794\n",
      "train loss:0.001534591863199278\n",
      "train loss:0.0013010274500137786\n",
      "train loss:0.0027125203031698924\n",
      "train loss:0.003110877421590276\n",
      "train loss:0.01579024323535074\n",
      "train loss:0.001988783087163595\n",
      "train loss:0.0018479821554980638\n",
      "train loss:0.002028485634588494\n",
      "train loss:0.0018667382170911573\n",
      "train loss:0.0004121772142563911\n",
      "train loss:0.012106341285785709\n",
      "train loss:0.0059085136650933725\n",
      "train loss:0.002206288062611432\n",
      "train loss:0.0008510294566856335\n",
      "train loss:0.003455889279540787\n",
      "train loss:0.004489580221453921\n",
      "train loss:0.0064316314529053245\n",
      "train loss:0.002716440834246583\n",
      "train loss:0.004628236780561391\n",
      "train loss:0.0011731598880193488\n",
      "train loss:0.0005413499605212421\n",
      "train loss:0.0024427539366037795\n",
      "train loss:0.04478241682459036\n",
      "train loss:0.04269681190078046\n",
      "train loss:0.006201421063754848\n",
      "train loss:0.0034010795469741244\n",
      "train loss:0.0029089354057913906\n",
      "train loss:0.006068286938924184\n",
      "train loss:0.013353802934455738\n",
      "train loss:0.0013238843285490068\n",
      "train loss:0.025884705410840998\n",
      "train loss:0.00028328854032240604\n",
      "train loss:0.002814374589982137\n",
      "train loss:0.014922095924686251\n",
      "train loss:0.0007874232537355621\n",
      "train loss:0.032263964767378306\n",
      "train loss:0.007183417775175941\n",
      "train loss:0.004214367066278365\n",
      "train loss:0.006160359152909462\n",
      "train loss:0.014344376117485087\n",
      "train loss:0.002885372535510835\n",
      "train loss:0.0008236869206644789\n",
      "train loss:0.004762834896346458\n",
      "train loss:0.002225314927722059\n",
      "train loss:0.0014670091703337998\n",
      "train loss:0.010909159924242288\n",
      "train loss:0.00652423878393592\n",
      "train loss:0.0023123444674382283\n",
      "train loss:0.028461352307947906\n",
      "train loss:0.004293610321379601\n",
      "train loss:0.011978651775626731\n",
      "train loss:0.000835724734796506\n",
      "train loss:0.004803253276388306\n",
      "train loss:0.020649679811910328\n",
      "train loss:0.003870047941995555\n",
      "train loss:0.01530921616121212\n",
      "train loss:0.002333091297850551\n",
      "train loss:0.0051362151692829795\n",
      "train loss:0.0015864245674217972\n",
      "train loss:0.006424426545142096\n",
      "train loss:0.004067533644849393\n",
      "train loss:0.0014397063712529958\n",
      "train loss:0.028921485824013417\n",
      "train loss:0.0068509202411217015\n",
      "train loss:0.007986828612257085\n",
      "train loss:0.0039908635255843945\n",
      "train loss:0.0020963063452865993\n",
      "train loss:0.0016849944896131447\n",
      "train loss:0.011386164602312168\n",
      "train loss:0.007902036782826066\n",
      "train loss:0.0030125600577654748\n",
      "train loss:0.007869759479468226\n",
      "train loss:0.0014722740170156996\n",
      "train loss:0.0009365605348421667\n",
      "train loss:0.008609456765061054\n",
      "train loss:0.002995130871547856\n",
      "train loss:0.00512757361918135\n",
      "train loss:0.003761101274005995\n",
      "train loss:0.00239835318602211\n",
      "train loss:0.0030210728071611557\n",
      "train loss:0.003180804197019817\n",
      "train loss:0.0014810280847325952\n",
      "train loss:0.006259277400053568\n",
      "train loss:0.002323194823149422\n",
      "train loss:0.007592473344173163\n",
      "train loss:0.004023096682250993\n",
      "train loss:0.0008205025236515177\n",
      "train loss:0.005887477900907406\n",
      "train loss:0.0003709521258924299\n",
      "train loss:0.004097189138159974\n",
      "train loss:0.0076252445427897894\n",
      "train loss:0.00947164487304665\n",
      "train loss:0.015035753435812857\n",
      "train loss:0.006919591374454382\n",
      "train loss:0.0019530833157136002\n",
      "train loss:0.002843870104389549\n",
      "train loss:0.013233392790685862\n",
      "train loss:0.0017631358434928677\n",
      "train loss:0.005405317002502891\n",
      "train loss:0.00496721504203753\n",
      "train loss:0.002941248875795218\n",
      "train loss:0.001499961147102189\n",
      "train loss:0.0007724434991841954\n",
      "train loss:0.012016737262051436\n",
      "train loss:0.010859864876394865\n",
      "train loss:0.006325573618345626\n",
      "train loss:0.002451701095370609\n",
      "train loss:0.0007418124494748017\n",
      "train loss:0.0064863671766755004\n",
      "train loss:0.013721629509675159\n",
      "train loss:0.022449428735487876\n",
      "train loss:0.002857229771837708\n",
      "train loss:0.01873726509140794\n",
      "train loss:0.001070035905594514\n",
      "train loss:0.012762129975035006\n",
      "train loss:0.004288747147017061\n",
      "train loss:0.010210705782426254\n",
      "train loss:0.008319672114240078\n",
      "train loss:0.007954539710929782\n",
      "train loss:0.007845897837024388\n",
      "train loss:0.008836667240327148\n",
      "train loss:0.012237405410157783\n",
      "train loss:0.005029841558988064\n",
      "train loss:0.0005597834338995008\n",
      "train loss:0.0017223039111068353\n",
      "train loss:0.004437391595086082\n",
      "train loss:0.002882460537734741\n",
      "train loss:0.00024922590261894096\n",
      "train loss:0.015193396424777832\n",
      "train loss:0.0032716343643677728\n",
      "train loss:0.010494413042239949\n",
      "train loss:0.00041499140777761\n",
      "train loss:0.018858589682739676\n",
      "train loss:0.00013640554375342256\n",
      "train loss:0.003860297604550073\n",
      "train loss:0.004146475048162416\n",
      "train loss:0.0036028285554851407\n",
      "train loss:0.0010347298014983094\n",
      "train loss:0.030598815505306423\n",
      "train loss:0.001296641473240891\n",
      "train loss:0.002788672922382527\n",
      "train loss:0.0031362208843397437\n",
      "train loss:0.005860201362170228\n",
      "train loss:0.003942943457819332\n",
      "train loss:0.005585717379434898\n",
      "train loss:0.005043944027284869\n",
      "train loss:0.001285993342111136\n",
      "train loss:0.017890827871099108\n",
      "train loss:0.0016205014132388118\n",
      "train loss:0.01107722330075682\n",
      "train loss:0.001719380787421828\n",
      "train loss:0.0005348281495113116\n",
      "train loss:0.0018030865366520763\n",
      "train loss:0.0004705740412777194\n",
      "train loss:0.0101552150622882\n",
      "train loss:0.001385198357540989\n",
      "train loss:0.026733878104776756\n",
      "train loss:0.003987965025594456\n",
      "train loss:0.005170050515250573\n",
      "train loss:0.005231811436981442\n",
      "train loss:0.00256559672528842\n",
      "train loss:0.0033952750479910206\n",
      "train loss:0.003133061789410329\n",
      "train loss:0.04674268069919598\n",
      "train loss:0.0011237419445481642\n",
      "train loss:0.007446531637773802\n",
      "train loss:0.0009937356020190118\n",
      "train loss:0.0016581438325866105\n",
      "train loss:0.003477009718657488\n",
      "train loss:0.02468408387475741\n",
      "train loss:0.0035287240141375275\n",
      "train loss:0.0020711881915416366\n",
      "train loss:0.004050604393176026\n",
      "train loss:0.009788681635807416\n",
      "train loss:0.0025202342059737442\n",
      "train loss:0.005783474189744786\n",
      "train loss:0.0012653726550288604\n",
      "train loss:0.005557077064581012\n",
      "train loss:0.007858138192768682\n",
      "train loss:0.002555852094518162\n",
      "train loss:0.0006818269375147846\n",
      "train loss:0.00850690210069036\n",
      "train loss:0.0011538042198786897\n",
      "train loss:0.006763969508796323\n",
      "train loss:0.029503556355563624\n",
      "train loss:0.02506413062804214\n",
      "train loss:0.003674457420963902\n",
      "train loss:0.0019992723773722466\n",
      "train loss:0.0027635357868714887\n",
      "train loss:0.03149178146586665\n",
      "train loss:0.01030818567514332\n",
      "train loss:0.004118906592467494\n",
      "train loss:0.0023968297465352165\n",
      "train loss:0.005648354954783759\n",
      "train loss:0.0030249566864561737\n",
      "train loss:0.0013507338267367513\n",
      "train loss:0.0031042378709259647\n",
      "train loss:0.0011601977974148722\n",
      "train loss:0.0062822618723800926\n",
      "train loss:0.004504842404508647\n",
      "train loss:0.0009586819816856711\n",
      "train loss:0.0006025030326569842\n",
      "train loss:0.010934872092752367\n",
      "train loss:0.01706677883108141\n",
      "train loss:0.002485608013916637\n",
      "train loss:0.01658803793087836\n",
      "train loss:0.006285460774612155\n",
      "train loss:0.004302783014225285\n",
      "train loss:0.00832090884100779\n",
      "train loss:0.002073516441625036\n",
      "train loss:0.0007112443535642366\n",
      "train loss:0.0010657098043590817\n",
      "train loss:0.008476723637994447\n",
      "train loss:0.03894348577470572\n",
      "train loss:0.0027125595652662234\n",
      "train loss:0.006664022011529955\n",
      "train loss:0.0006553286718960404\n",
      "train loss:0.004333107955279421\n",
      "train loss:0.0038555724210440697\n",
      "train loss:0.030097933866677713\n",
      "train loss:0.0037379839663071353\n",
      "train loss:0.053465662658531345\n",
      "train loss:0.0027630975403074576\n",
      "train loss:0.0009052389416645676\n",
      "train loss:0.0017304424266624382\n",
      "train loss:0.0028324362366557226\n",
      "train loss:0.004674375220512956\n",
      "train loss:0.0038243139266786377\n",
      "train loss:0.0035163158065876577\n",
      "train loss:0.013445399559850787\n",
      "train loss:0.002230344155887527\n",
      "train loss:0.008199069518697734\n",
      "train loss:0.004532312495469076\n",
      "train loss:0.0014796649821955995\n",
      "train loss:0.0027306683074614364\n",
      "train loss:0.006078027449445173\n",
      "train loss:0.01882695857883647\n",
      "train loss:0.0037182329103726862\n",
      "train loss:0.0039423171502101124\n",
      "train loss:0.005401783422024365\n",
      "train loss:0.004655145431023319\n",
      "train loss:0.001940908728315864\n",
      "train loss:0.00044577852765837275\n",
      "train loss:0.00477966899080607\n",
      "train loss:0.006055261554001041\n",
      "train loss:0.008148071674676589\n",
      "train loss:0.0011377510534111997\n",
      "train loss:0.009042817391994503\n",
      "train loss:0.017641996642042457\n",
      "train loss:0.0026036102590556603\n",
      "train loss:0.00035974965599240056\n",
      "train loss:0.005475420993643466\n",
      "train loss:0.01353311021581979\n",
      "train loss:0.006232324972236196\n",
      "train loss:0.0011023658987095594\n",
      "train loss:0.006555560171516136\n",
      "train loss:0.004615083529105587\n",
      "train loss:0.0005274163399210893\n",
      "train loss:0.040864820516651974\n",
      "train loss:0.0045265650685998825\n",
      "train loss:0.009575679495446575\n",
      "train loss:0.0015458805411119327\n",
      "train loss:0.0014383853354518901\n",
      "train loss:0.0010559247012689149\n",
      "train loss:0.004634325690994159\n",
      "train loss:0.000431198667010114\n",
      "train loss:0.004772472460864177\n",
      "train loss:0.0107828869981106\n",
      "train loss:0.006572915992192206\n",
      "train loss:0.002770239373513358\n",
      "train loss:0.0051588241998216725\n",
      "train loss:0.0026179080376437635\n",
      "train loss:0.00465170161253683\n",
      "train loss:0.0040051983885991075\n",
      "train loss:0.005370280207702346\n",
      "train loss:0.0015063263713017258\n",
      "train loss:0.004765797211531719\n",
      "train loss:0.002175233955267673\n",
      "train loss:0.00046048597074863654\n",
      "train loss:0.00022252492240082275\n",
      "train loss:0.0042232893832721274\n",
      "train loss:0.01700075429453404\n",
      "train loss:0.004768612298903604\n",
      "train loss:0.007521986308397764\n",
      "train loss:0.008517867538686878\n",
      "train loss:0.006059651130274268\n",
      "train loss:0.0013316982805150577\n",
      "train loss:0.0010522471562299449\n",
      "train loss:0.0015218931765405119\n",
      "train loss:0.007118083178366505\n",
      "train loss:0.012154687921145123\n",
      "train loss:0.005471493706955138\n",
      "train loss:0.029341565390108883\n",
      "train loss:0.005286421755710331\n",
      "train loss:0.020253404250585878\n",
      "train loss:0.01972254735540434\n",
      "train loss:0.0010011529753925583\n",
      "train loss:0.0019817665032596968\n",
      "train loss:0.0047680978346187316\n",
      "train loss:0.004048685461829167\n",
      "train loss:0.00047891571328679395\n",
      "train loss:0.005651911787210271\n",
      "train loss:0.0007266694086599132\n",
      "train loss:0.002039702465658151\n",
      "train loss:0.007131121586297203\n",
      "train loss:0.0037904557660041276\n",
      "train loss:0.0055831957910236815\n",
      "train loss:0.022634538946535818\n",
      "train loss:0.00751403968230898\n",
      "train loss:0.0024609798009795026\n",
      "train loss:0.0006736141895654899\n",
      "train loss:0.0018672829850426575\n",
      "train loss:0.00015898250470821048\n",
      "train loss:0.011873216509209378\n",
      "train loss:0.001828402963589038\n",
      "train loss:0.003293342304377296\n",
      "train loss:0.0015547843544696058\n",
      "train loss:0.0013005152395468703\n",
      "train loss:0.015202562124687648\n",
      "train loss:0.0006887638574401019\n",
      "train loss:0.004388694771036546\n",
      "train loss:0.021377049542280025\n",
      "train loss:0.03953985974371738\n",
      "train loss:0.0030395987595303003\n",
      "=== epoch:12, train acc:0.998, test acc:0.988 ===\n",
      "train loss:0.02208196681948225\n",
      "train loss:0.00565153629975508\n",
      "train loss:0.011442557166092637\n",
      "train loss:0.0013213175409371974\n",
      "train loss:0.009995750426923848\n",
      "train loss:0.020019016911680683\n",
      "train loss:0.014910420590712035\n",
      "train loss:0.0005756988116953088\n",
      "train loss:0.002842201133847297\n",
      "train loss:0.0032021918964896317\n",
      "train loss:0.0019867129523247866\n",
      "train loss:0.007147687652388036\n",
      "train loss:0.002135292759014989\n",
      "train loss:0.013085494599005296\n",
      "train loss:0.0019670197823903595\n",
      "train loss:0.0021857763569658344\n",
      "train loss:0.012936751613526259\n",
      "train loss:0.001386793217660953\n",
      "train loss:0.009076733276961872\n",
      "train loss:0.004355273354407882\n",
      "train loss:0.0022600395647904893\n",
      "train loss:0.0026408682197928855\n",
      "train loss:0.004187034625083032\n",
      "train loss:0.0007677231214889983\n",
      "train loss:0.010453637069624823\n",
      "train loss:0.004712949217005959\n",
      "train loss:0.005170184747049197\n",
      "train loss:0.005872330256205142\n",
      "train loss:0.008710682428325222\n",
      "train loss:0.030068275040066306\n",
      "train loss:0.008565354033576179\n",
      "train loss:0.0027135660187349807\n",
      "train loss:0.009400774820473759\n",
      "train loss:0.0057884370638687285\n",
      "train loss:0.016247460357202415\n",
      "train loss:0.0032022387862566982\n",
      "train loss:0.000593711217540064\n",
      "train loss:0.008615366632354918\n",
      "train loss:0.0028461599800369162\n",
      "train loss:0.002484991628720807\n",
      "train loss:0.003115876887923919\n",
      "train loss:0.0012335566743286546\n",
      "train loss:0.003336052155399388\n",
      "train loss:0.0027711963772608966\n",
      "train loss:0.001192293427275724\n",
      "train loss:0.0012529989719683539\n",
      "train loss:0.009385378970534167\n",
      "train loss:0.004088741892354697\n",
      "train loss:0.017123429123524003\n",
      "train loss:0.0169658578225324\n",
      "train loss:0.0028837302830631768\n",
      "train loss:0.0016844329828125892\n",
      "train loss:0.0015239767443073415\n",
      "train loss:0.0017597992030270282\n",
      "train loss:0.0038175291732741746\n",
      "train loss:0.0012058248478010762\n",
      "train loss:0.003106217789458165\n",
      "train loss:0.0029138787822666746\n",
      "train loss:0.005480763014142964\n",
      "train loss:0.002041262753304308\n",
      "train loss:0.011914898478578786\n",
      "train loss:0.0004955222193347845\n",
      "train loss:0.0015822381820368716\n",
      "train loss:0.0018651037509717487\n",
      "train loss:0.03973232174036552\n",
      "train loss:0.0031646517261830825\n",
      "train loss:0.0016763201764646541\n",
      "train loss:0.01672722786396827\n",
      "train loss:0.0005533900172139998\n",
      "train loss:0.003018018917336645\n",
      "train loss:0.0022923105944569295\n",
      "train loss:0.000848875895832583\n",
      "train loss:0.004760328192297849\n",
      "train loss:0.00249957793543709\n",
      "train loss:0.06283616154289713\n",
      "train loss:0.004091861419034036\n",
      "train loss:0.00880626853294894\n",
      "train loss:0.0026454614876547555\n",
      "train loss:0.004565225333215317\n",
      "train loss:0.007853347709980831\n",
      "train loss:0.006335655062781876\n",
      "train loss:0.0036642551889483465\n",
      "train loss:0.004717944055257523\n",
      "train loss:0.00017168443075912422\n",
      "train loss:0.000956948416742905\n",
      "train loss:0.016153454533076955\n",
      "train loss:0.00859923683992848\n",
      "train loss:0.004961246680209566\n",
      "train loss:0.008732821188539797\n",
      "train loss:0.002543170901470054\n",
      "train loss:0.0002564092570273516\n",
      "train loss:0.004153404008353332\n",
      "train loss:0.001727482299683227\n",
      "train loss:0.0022991263321710835\n",
      "train loss:0.013570162059468491\n",
      "train loss:0.0037550913000668545\n",
      "train loss:0.0006731867819956311\n",
      "train loss:0.00480727684569779\n",
      "train loss:0.00507717132144545\n",
      "train loss:0.0009302374873111193\n",
      "train loss:0.0029105044568834546\n",
      "train loss:0.0011106545047487914\n",
      "train loss:0.002202721370612395\n",
      "train loss:0.0015678907446797263\n",
      "train loss:0.05183960566304442\n",
      "train loss:0.0007881295183657651\n",
      "train loss:0.0022402587130327654\n",
      "train loss:0.00550198286810063\n",
      "train loss:0.01125751756142686\n",
      "train loss:0.00033149764005482564\n",
      "train loss:0.0024307164997859\n",
      "train loss:0.008493166917707023\n",
      "train loss:0.005604951036578032\n",
      "train loss:0.0020116399122927456\n",
      "train loss:0.0010829571570017097\n",
      "train loss:0.004346854911510575\n",
      "train loss:0.0090342443651008\n",
      "train loss:0.0029817360066177606\n",
      "train loss:0.008379576182385568\n",
      "train loss:0.003794296532650912\n",
      "train loss:0.0034259182552733207\n",
      "train loss:0.001338811380230526\n",
      "train loss:0.0025672379390679363\n",
      "train loss:0.003894178110331401\n",
      "train loss:0.003261893234450261\n",
      "train loss:0.0004901151050546149\n",
      "train loss:0.0024050951647647356\n",
      "train loss:0.00381327619852279\n",
      "train loss:0.0021573917257341844\n",
      "train loss:0.0004103858547396888\n",
      "train loss:0.0015388374930067835\n",
      "train loss:0.0017531680873059097\n",
      "train loss:0.0003300271914511249\n",
      "train loss:0.0010588796699216416\n",
      "train loss:0.00039605802612074367\n",
      "train loss:0.0017511895930151463\n",
      "train loss:0.002407073588026212\n",
      "train loss:0.0011312749124487464\n",
      "train loss:0.0006693934034832744\n",
      "train loss:0.0003283737059380566\n",
      "train loss:0.019326916615870448\n",
      "train loss:0.029537728375648373\n",
      "train loss:0.002735081372644635\n",
      "train loss:0.010294279101608884\n",
      "train loss:0.002031202036639192\n",
      "train loss:0.004275080854373784\n",
      "train loss:0.004125199731756424\n",
      "train loss:0.0005763909215365707\n",
      "train loss:0.004269751614070217\n",
      "train loss:0.00543024539451016\n",
      "train loss:0.0041256635453377774\n",
      "train loss:0.0008075236561096625\n",
      "train loss:0.006050213875103778\n",
      "train loss:0.00019015208941584112\n",
      "train loss:0.001394978862402842\n",
      "train loss:0.003695479842066194\n",
      "train loss:0.0006833361474093838\n",
      "train loss:0.12538442650918408\n",
      "train loss:0.03845462976377284\n",
      "train loss:0.0027221261287595716\n",
      "train loss:0.0008501891259691382\n",
      "train loss:0.013133840280829185\n",
      "train loss:0.007754442274971147\n",
      "train loss:0.0005125973528605223\n",
      "train loss:0.004914564777212567\n",
      "train loss:0.002062769536988515\n",
      "train loss:0.006737258004439576\n",
      "train loss:0.006236637932959405\n",
      "train loss:0.0016213155562134227\n",
      "train loss:0.0025646161709338504\n",
      "train loss:0.0008132332234769056\n",
      "train loss:0.0022141789201623957\n",
      "train loss:0.0014590161672289061\n",
      "train loss:0.002512850176596013\n",
      "train loss:0.003275018269192795\n",
      "train loss:0.006472039546967583\n",
      "train loss:0.013791297043336249\n",
      "train loss:0.002755218933015946\n",
      "train loss:0.0019912506816892593\n",
      "train loss:0.004382037811982053\n",
      "train loss:0.0046160984929862455\n",
      "train loss:0.0009115618379554742\n",
      "train loss:0.015605179988238705\n",
      "train loss:0.022856499529048935\n",
      "train loss:0.002489751264911283\n",
      "train loss:0.0038903681310638026\n",
      "train loss:0.003798625297549802\n",
      "train loss:0.021834277736816014\n",
      "train loss:0.008174612522600305\n",
      "train loss:0.00048015665416745927\n",
      "train loss:0.0004861203009592141\n",
      "train loss:0.0008462396000217689\n",
      "train loss:0.004258001824745147\n",
      "train loss:0.0005910570839431229\n",
      "train loss:0.015967145760387\n",
      "train loss:0.003037547755082068\n",
      "train loss:0.0034099371302035103\n",
      "train loss:0.001552195856713697\n",
      "train loss:0.003823018776554118\n",
      "train loss:0.003241186340181659\n",
      "train loss:0.004157556083810096\n",
      "train loss:0.00024193912707792806\n",
      "train loss:0.00024462797929158844\n",
      "train loss:0.002281279596769576\n",
      "train loss:0.007850554564259636\n",
      "train loss:0.007849880612509073\n",
      "train loss:0.022904447342117856\n",
      "train loss:0.014435794489016327\n",
      "train loss:0.0006046076295839913\n",
      "train loss:0.0005548608390088445\n",
      "train loss:0.02602842264064304\n",
      "train loss:0.0027349303826794845\n",
      "train loss:0.004896309993547876\n",
      "train loss:0.0007613957918929313\n",
      "train loss:0.00017015602696285708\n",
      "train loss:0.001852754297208133\n",
      "train loss:0.0007965123524819715\n",
      "train loss:0.0031633516922219156\n",
      "train loss:0.0032230251248809953\n",
      "train loss:0.019518794830605108\n",
      "train loss:0.00043452647740780325\n",
      "train loss:0.009715075457187722\n",
      "train loss:0.0010114368809610499\n",
      "train loss:0.007021365066048645\n",
      "train loss:0.0064194458931997374\n",
      "train loss:0.009639478731367297\n",
      "train loss:0.013245825628085246\n",
      "train loss:0.010222269005580249\n",
      "train loss:0.0050953665809796355\n",
      "train loss:0.002179301823416888\n",
      "train loss:0.005033853561829307\n",
      "train loss:0.0050034280879820425\n",
      "train loss:0.014069901168638311\n",
      "train loss:0.0023971608849148126\n",
      "train loss:0.0012700836285551406\n",
      "train loss:0.011585163356747525\n",
      "train loss:0.0059855011453929475\n",
      "train loss:0.007172246775634588\n",
      "train loss:0.0025710969899089154\n",
      "train loss:0.0010169596306884052\n",
      "train loss:0.005066822633488654\n",
      "train loss:0.0029326999261342647\n",
      "train loss:0.0002782444755724917\n",
      "train loss:0.018819915608953932\n",
      "train loss:0.004728447641211136\n",
      "train loss:0.009151112986067314\n",
      "train loss:0.0024256904456544546\n",
      "train loss:0.0009082228950942023\n",
      "train loss:0.005215825426101992\n",
      "train loss:0.00024576990618302473\n",
      "train loss:0.00034216249223096613\n",
      "train loss:0.006543988964254228\n",
      "train loss:0.007732823752397009\n",
      "train loss:0.0036954064438276357\n",
      "train loss:0.0019341191353652695\n",
      "train loss:0.002193875421055277\n",
      "train loss:0.0005131912318158772\n",
      "train loss:0.012667924654688538\n",
      "train loss:0.004997165857909029\n",
      "train loss:0.004525472139745326\n",
      "train loss:0.0015644988048850023\n",
      "train loss:0.0015897399697609243\n",
      "train loss:0.00752461541914379\n",
      "train loss:0.0018662313369409542\n",
      "train loss:0.006359060098949028\n",
      "train loss:0.0023034072547390046\n",
      "train loss:0.0030996755940701348\n",
      "train loss:0.0016921772983870555\n",
      "train loss:0.005257930532208762\n",
      "train loss:0.001226858401850379\n",
      "train loss:0.005613389984485621\n",
      "train loss:0.0005152752780646099\n",
      "train loss:0.0025363287451627844\n",
      "train loss:0.0028433826296749027\n",
      "train loss:0.0017801062772258736\n",
      "train loss:0.016380344410763047\n",
      "train loss:0.002717652622553921\n",
      "train loss:0.00348248697851594\n",
      "train loss:0.030376028117572795\n",
      "train loss:0.00036614665941821114\n",
      "train loss:0.0002589567660270911\n",
      "train loss:0.004793017905545347\n",
      "train loss:0.000363669053659293\n",
      "train loss:0.0017990033231097642\n",
      "train loss:0.010089031994419136\n",
      "train loss:0.006147528597929826\n",
      "train loss:0.06627041281162828\n",
      "train loss:0.0008297294780691729\n",
      "train loss:0.0072445182818832035\n",
      "train loss:0.026149921774265436\n",
      "train loss:0.0028003673850942167\n",
      "train loss:0.012952952241172225\n",
      "train loss:0.02754332138650684\n",
      "train loss:0.003086896509591217\n",
      "train loss:0.0037696045640209443\n",
      "train loss:0.016654019968050226\n",
      "train loss:0.0002377783094295636\n",
      "train loss:0.003957805172278118\n",
      "train loss:0.0023773662330115516\n",
      "train loss:0.006588913483958915\n",
      "train loss:0.008152630016765054\n",
      "train loss:0.03494429649406405\n",
      "train loss:0.003236517722216104\n",
      "train loss:0.0024381825557128222\n",
      "train loss:0.0034307419792504136\n",
      "train loss:0.0025356162704196876\n",
      "train loss:0.031500415698023185\n",
      "train loss:0.0030881583482025425\n",
      "train loss:0.0020455044865954576\n",
      "train loss:0.0019280499132196397\n",
      "train loss:0.0023422191350383798\n",
      "train loss:0.0014870166589143901\n",
      "train loss:0.005854150287688376\n",
      "train loss:0.0018888480550755871\n",
      "train loss:0.001207086326332139\n",
      "train loss:0.0022281417188126655\n",
      "train loss:0.001923054393992273\n",
      "train loss:0.006677819997610084\n",
      "train loss:0.009450207113887507\n",
      "train loss:0.01696122097627046\n",
      "train loss:0.003589387122432643\n",
      "train loss:0.0006856336206437582\n",
      "train loss:0.00452424989001701\n",
      "train loss:0.0010943210765055156\n",
      "train loss:0.002641249930514903\n",
      "train loss:0.005576064829440344\n",
      "train loss:0.0028987149805432947\n",
      "train loss:0.0018614416209190507\n",
      "train loss:0.007237248603872017\n",
      "train loss:0.014716293108322785\n",
      "train loss:0.001958718787962783\n",
      "train loss:0.003773020564915517\n",
      "train loss:0.0019734242586113312\n",
      "train loss:0.006619678329663228\n",
      "train loss:0.0027288241908312518\n",
      "train loss:0.0012787975826507858\n",
      "train loss:0.002561069119888809\n",
      "train loss:0.016451845711331188\n",
      "train loss:0.0038820334435523142\n",
      "train loss:0.00880168255828393\n",
      "train loss:0.0058799145578332\n",
      "train loss:0.0016202876860932553\n",
      "train loss:0.004031225108084258\n",
      "train loss:0.0017565000646212671\n",
      "train loss:0.029404014075521817\n",
      "train loss:0.002605683946847181\n",
      "train loss:0.004696474734462379\n",
      "train loss:0.002465727919860429\n",
      "train loss:0.006821425175368257\n",
      "train loss:0.04379894345912834\n",
      "train loss:0.04045040494467377\n",
      "train loss:0.000256779461156626\n",
      "train loss:0.006325521207943297\n",
      "train loss:0.000784722228650218\n",
      "train loss:0.0004989159583016665\n",
      "train loss:0.02175112206733818\n",
      "train loss:0.0017224814887284382\n",
      "train loss:0.0011013128260059842\n",
      "train loss:0.0008912744110344577\n",
      "train loss:0.0006194982397108221\n",
      "train loss:0.0038671927365804167\n",
      "train loss:0.0031738296978283636\n",
      "train loss:0.0030395453873552558\n",
      "train loss:0.00281664735333423\n",
      "train loss:0.003918679810480885\n",
      "train loss:0.001360561207997507\n",
      "train loss:0.0019336919646437232\n",
      "train loss:0.0010830854813932648\n",
      "train loss:0.001927941177668308\n",
      "train loss:0.006722405030473727\n",
      "train loss:0.004423602530265371\n",
      "train loss:0.008766634655436643\n",
      "train loss:0.000782298335713426\n",
      "train loss:0.006501740969171051\n",
      "train loss:0.0036785046657884855\n",
      "train loss:0.0007231938013410838\n",
      "train loss:0.0065636429405896675\n",
      "train loss:0.0025796279164507\n",
      "train loss:0.0009476250518655517\n",
      "train loss:0.00014734562848049207\n",
      "train loss:0.0021699643852043484\n",
      "train loss:0.000553213713449351\n",
      "train loss:0.0005856794490894999\n",
      "train loss:0.0014706587028478345\n",
      "train loss:0.0006346760109922374\n",
      "train loss:0.001068552689391926\n",
      "train loss:0.0009737392260528374\n",
      "train loss:0.0032174979159938417\n",
      "train loss:0.0009978016290507347\n",
      "train loss:0.0013052600771878639\n",
      "train loss:0.0035297505643098652\n",
      "train loss:0.005453943502395246\n",
      "train loss:0.001154879327704086\n",
      "train loss:0.002904833349681549\n",
      "train loss:0.004834247169349546\n",
      "train loss:0.0006110566382720793\n",
      "train loss:0.0010933891133675746\n",
      "train loss:0.0011849261073984523\n",
      "train loss:0.00034467198221597653\n",
      "train loss:0.00203048831097393\n",
      "train loss:0.003920943394129885\n",
      "train loss:0.0017290915998929757\n",
      "train loss:0.003597962930397239\n",
      "train loss:0.0019124586127363605\n",
      "train loss:0.0003550223178541133\n",
      "train loss:0.0009601475053886184\n",
      "train loss:0.006066914075590837\n",
      "train loss:0.000994923065383556\n",
      "train loss:0.002176123251505986\n",
      "train loss:0.0013524408783995429\n",
      "train loss:0.0005311018958157331\n",
      "train loss:0.0023214702914828834\n",
      "train loss:0.001746925708193281\n",
      "train loss:0.0013167171140096882\n",
      "train loss:0.0024876350071930567\n",
      "train loss:0.0006449837034801177\n",
      "train loss:0.0040505516248894044\n",
      "train loss:0.005629546241725874\n",
      "train loss:0.006279842590150536\n",
      "train loss:0.003501187730404797\n",
      "train loss:0.005024894030745933\n",
      "train loss:0.001715263137160019\n",
      "train loss:0.0042366476850762965\n",
      "train loss:0.000572938944794721\n",
      "train loss:0.0030439934705277934\n",
      "train loss:0.0005881568435383156\n",
      "train loss:0.002363243925609507\n",
      "train loss:0.0023841403666134157\n",
      "train loss:0.006827922777413292\n",
      "train loss:0.0028695815466831314\n",
      "train loss:0.015837675900577844\n",
      "train loss:0.0003727311984519826\n",
      "train loss:0.0029979161238396237\n",
      "train loss:0.0022462568566386574\n",
      "train loss:0.0004425269965366398\n",
      "train loss:0.0023323314135395303\n",
      "train loss:0.005916710513920517\n",
      "train loss:0.002438368733881928\n",
      "train loss:0.006357349632252001\n",
      "train loss:0.0026477658991083514\n",
      "train loss:0.006994051101404258\n",
      "train loss:0.002548153668622106\n",
      "train loss:0.001967691056120745\n",
      "train loss:0.0011066842409163955\n",
      "train loss:0.00040613204713708847\n",
      "train loss:0.009590741435426868\n",
      "train loss:0.0033117998521641325\n",
      "train loss:0.0017544437417140414\n",
      "train loss:0.00044136226728995557\n",
      "train loss:0.0011097833659359229\n",
      "train loss:0.030399905193531387\n",
      "train loss:0.0031697486169427465\n",
      "train loss:0.004756713029212496\n",
      "train loss:0.0034074473354872015\n",
      "train loss:0.002481212402914568\n",
      "train loss:0.00040488726305086835\n",
      "train loss:0.0020418221426353115\n",
      "train loss:0.009089407780089886\n",
      "train loss:0.003657344860503152\n",
      "train loss:0.00021238842032011773\n",
      "train loss:0.0019526415080938946\n",
      "train loss:0.01478526384118246\n",
      "train loss:0.008006576992668909\n",
      "train loss:0.0023803528550455965\n",
      "train loss:0.0013923295697950454\n",
      "train loss:0.0021026790790437677\n",
      "train loss:0.0029030558023568727\n",
      "train loss:0.018946779185993273\n",
      "train loss:0.004989360809668803\n",
      "train loss:0.003232603602617863\n",
      "train loss:0.0008494749621817359\n",
      "train loss:0.0073017892739775415\n",
      "train loss:0.007920333177334067\n",
      "train loss:0.003927486207270922\n",
      "train loss:0.002507720211576281\n",
      "train loss:0.0007293802253800237\n",
      "train loss:0.002418988365623617\n",
      "train loss:0.003714950330097766\n",
      "train loss:0.005426433146320061\n",
      "train loss:0.004142781298862454\n",
      "train loss:0.001307450878205385\n",
      "train loss:0.009036071123614714\n",
      "train loss:0.004313095031890856\n",
      "train loss:0.0018233128624765165\n",
      "train loss:0.0041263999715673814\n",
      "train loss:0.04520350129999314\n",
      "train loss:0.0042378105646318585\n",
      "train loss:0.0007607527394651618\n",
      "train loss:0.0008445385245091048\n",
      "train loss:0.00024442666028007986\n",
      "train loss:0.004974447762896565\n",
      "train loss:0.003444593514711262\n",
      "train loss:0.030859063766980336\n",
      "train loss:0.0030936161028409857\n",
      "train loss:0.0020908389551470797\n",
      "train loss:0.0063226559237229375\n",
      "train loss:0.0017321120532198025\n",
      "train loss:0.019172864162133606\n",
      "train loss:0.008217649248459382\n",
      "train loss:0.0025126773776304335\n",
      "train loss:0.0032814403187129103\n",
      "train loss:0.0035269601368588055\n",
      "train loss:0.00379588317808464\n",
      "train loss:0.0046657166590784675\n",
      "train loss:0.001140029283623675\n",
      "train loss:0.006709884285588036\n",
      "train loss:0.004389539253719093\n",
      "train loss:0.0016872396667249334\n",
      "train loss:0.006358405019311402\n",
      "train loss:0.0012874813016341342\n",
      "train loss:0.013703767771160424\n",
      "train loss:0.013003425963503545\n",
      "train loss:0.0016762616818239455\n",
      "train loss:0.003178857064795099\n",
      "train loss:0.00516433857466161\n",
      "train loss:0.0017980919463498187\n",
      "train loss:0.017738439799923504\n",
      "train loss:0.0031877350093987692\n",
      "train loss:0.003949781342698115\n",
      "train loss:0.014766557913285032\n",
      "train loss:0.002893782534892691\n",
      "train loss:0.0018739784189578264\n",
      "train loss:0.0014452162269959995\n",
      "train loss:0.00505977013265993\n",
      "train loss:0.0003615693703198139\n",
      "train loss:0.00938813157370144\n",
      "train loss:0.002601901380851075\n",
      "train loss:0.0013930105872820432\n",
      "train loss:0.015423661946831795\n",
      "train loss:0.0013080595050619934\n",
      "train loss:0.0008046410925764394\n",
      "train loss:0.0014038949295400046\n",
      "train loss:0.0026152156849921933\n",
      "train loss:0.0020227224326229347\n",
      "train loss:0.012642541060545284\n",
      "train loss:0.0048677839580280715\n",
      "train loss:0.0008775321323871736\n",
      "train loss:0.020542967772077984\n",
      "train loss:0.006003244985563032\n",
      "train loss:0.034096136301438706\n",
      "train loss:0.0016801899560201694\n",
      "train loss:0.00248913116793546\n",
      "train loss:0.0010522437182226216\n",
      "train loss:0.007322487051101063\n",
      "train loss:0.001416764892637082\n",
      "train loss:0.007766403442225924\n",
      "train loss:0.008525220191415644\n",
      "train loss:0.00793727424786607\n",
      "train loss:0.0016162641454016272\n",
      "train loss:0.005188994745678413\n",
      "train loss:0.002337585449466806\n",
      "train loss:0.01056477734635665\n",
      "train loss:0.011255453156213936\n",
      "train loss:0.0007569878626754889\n",
      "train loss:0.001471702032977135\n",
      "train loss:0.006633103539299975\n",
      "train loss:0.003192706910924932\n",
      "train loss:0.0026542570310709606\n",
      "train loss:0.0042142925457825196\n",
      "train loss:0.0036118082333820166\n",
      "train loss:0.00600580679475631\n",
      "train loss:0.00880383358960775\n",
      "train loss:0.007969783326126842\n",
      "train loss:0.003691755469933954\n",
      "train loss:0.0010622694574236665\n",
      "train loss:0.000350166373610027\n",
      "train loss:0.0014470656156043268\n",
      "train loss:0.002250314369024764\n",
      "train loss:0.0017525173155628424\n",
      "train loss:0.003783923410359687\n",
      "train loss:0.002252644426530225\n",
      "train loss:0.0003183388285427003\n",
      "train loss:0.0006682434355264219\n",
      "train loss:0.004275046478215245\n",
      "train loss:0.0021687034419430977\n",
      "train loss:0.004485982141530056\n",
      "train loss:0.00484241390008974\n",
      "train loss:0.0011366253197248987\n",
      "train loss:0.01790047236832715\n",
      "train loss:0.00031658162596679887\n",
      "train loss:0.007332187893124054\n",
      "train loss:0.0013601784817780136\n",
      "train loss:0.0024411262910584287\n",
      "train loss:0.0007606613477679329\n",
      "train loss:0.0002865019276479911\n",
      "train loss:0.001855199255711188\n",
      "train loss:0.000652080224918305\n",
      "train loss:0.004461410925331518\n",
      "train loss:0.002613373766150163\n",
      "train loss:0.007843745713962746\n",
      "train loss:0.0015625889833396716\n",
      "train loss:0.0020978122192551168\n",
      "train loss:0.0025617367376286533\n",
      "train loss:0.00447045605731776\n",
      "train loss:0.0027910274223468877\n",
      "train loss:0.004249609940494248\n",
      "train loss:0.006329653898422541\n",
      "train loss:0.003766712094870045\n",
      "train loss:0.003153528447328673\n",
      "train loss:0.0011759754521155122\n",
      "=== epoch:13, train acc:0.994, test acc:0.988 ===\n",
      "train loss:0.0018854930488827592\n",
      "train loss:0.006089071311697644\n",
      "train loss:0.0065522289416777265\n",
      "train loss:0.0027466079902732556\n",
      "train loss:0.00546968913809741\n",
      "train loss:0.0023493421457820777\n",
      "train loss:0.0006091867601724021\n",
      "train loss:0.004762981280405876\n",
      "train loss:0.0008677229123468424\n",
      "train loss:0.0017849001426521757\n",
      "train loss:0.0036038797149836595\n",
      "train loss:0.009285049736220036\n",
      "train loss:0.010745801100955825\n",
      "train loss:0.0018897922492024993\n",
      "train loss:0.004786558268676498\n",
      "train loss:0.001911617451444876\n",
      "train loss:0.005752945429614412\n",
      "train loss:0.0006049804017306567\n",
      "train loss:0.00019986940423565686\n",
      "train loss:0.042931726438467155\n",
      "train loss:0.007004147602814033\n",
      "train loss:0.0013220504306243658\n",
      "train loss:0.006956183816662333\n",
      "train loss:0.0008334229426981535\n",
      "train loss:0.0021154375533884405\n",
      "train loss:0.002474693060723164\n",
      "train loss:0.014076765025359596\n",
      "train loss:0.00024660307662635714\n",
      "train loss:0.0021285078852385595\n",
      "train loss:0.005212723483296235\n",
      "train loss:0.01646535689768907\n",
      "train loss:0.005925023534449141\n",
      "train loss:0.008575092541574833\n",
      "train loss:0.001696310946637632\n",
      "train loss:0.002332730983956253\n",
      "train loss:0.0013367161104049158\n",
      "train loss:0.0018982477541160095\n",
      "train loss:0.0014138132727905903\n",
      "train loss:0.0029616582525164954\n",
      "train loss:0.026861075658153533\n",
      "train loss:0.0012635234310833874\n",
      "train loss:0.0007392755680499212\n",
      "train loss:0.0010574262237390115\n",
      "train loss:0.0012314280642954677\n",
      "train loss:0.003087140367710356\n",
      "train loss:0.0016001387735286089\n",
      "train loss:0.004914583063529139\n",
      "train loss:0.023246906840385047\n",
      "train loss:0.001709408045716034\n",
      "train loss:0.0012518699009759283\n",
      "train loss:0.007900873024298559\n",
      "train loss:0.0015462012434419234\n",
      "train loss:0.007325889670984444\n",
      "train loss:0.004993388474504464\n",
      "train loss:0.0032307726518813144\n",
      "train loss:0.002403204375551142\n",
      "train loss:0.0008883266349574679\n",
      "train loss:0.003145819755870755\n",
      "train loss:0.0016907007591337672\n",
      "train loss:0.01167511429608109\n",
      "train loss:0.0008824631663681088\n",
      "train loss:0.006144456658388548\n",
      "train loss:0.006120767122071925\n",
      "train loss:0.0024689866618046253\n",
      "train loss:0.003250644904841703\n",
      "train loss:0.002915480397157406\n",
      "train loss:0.00041568100280232114\n",
      "train loss:0.0018233218608345245\n",
      "train loss:0.003526656108704857\n",
      "train loss:0.0023242398336538925\n",
      "train loss:0.0037797837966156906\n",
      "train loss:0.0029113274302214882\n",
      "train loss:0.007735866353200379\n",
      "train loss:0.009803269773890884\n",
      "train loss:0.0007561683443143801\n",
      "train loss:0.0011212541063909762\n",
      "train loss:0.00070391565930639\n",
      "train loss:0.0004680516991519529\n",
      "train loss:0.0014235744913244116\n",
      "train loss:0.0003009683413167627\n",
      "train loss:0.0035408379917584998\n",
      "train loss:0.0036560589013845753\n",
      "train loss:0.008207555601628513\n",
      "train loss:0.0015031915816609304\n",
      "train loss:0.0010930966478223554\n",
      "train loss:0.007871210970219446\n",
      "train loss:0.012992220213455195\n",
      "train loss:0.0015501988292290925\n",
      "train loss:0.00817172771493789\n",
      "train loss:0.03205627478459704\n",
      "train loss:0.0004462586814471395\n",
      "train loss:0.002702587148935717\n",
      "train loss:0.0006418157115316848\n",
      "train loss:0.0035463501727222425\n",
      "train loss:0.002877971917068616\n",
      "train loss:0.00044883888220653635\n",
      "train loss:0.019659119810979148\n",
      "train loss:0.0002997749686642703\n",
      "train loss:0.00020753382022052527\n",
      "train loss:0.002584299706792224\n",
      "train loss:0.0004959581215892864\n",
      "train loss:0.004304049863532431\n",
      "train loss:0.0016190295951790262\n",
      "train loss:0.0053650930164464835\n",
      "train loss:0.0004889131404807827\n",
      "train loss:0.0012750663534960515\n",
      "train loss:0.0039784305692583555\n",
      "train loss:0.0011307065501858686\n",
      "train loss:0.00505860477160979\n",
      "train loss:0.001858446074875922\n",
      "train loss:0.002623973139122574\n",
      "train loss:0.0016213216693605518\n",
      "train loss:0.0013531888993690904\n",
      "train loss:0.0017372216525052405\n",
      "train loss:0.00253857380197511\n",
      "train loss:0.003593128441093766\n",
      "train loss:0.0013241982538040736\n",
      "train loss:0.0052207038802313185\n",
      "train loss:0.0001247113213023599\n",
      "train loss:0.002925323147787609\n",
      "train loss:0.0068377311667322995\n",
      "train loss:0.07877628893916327\n",
      "train loss:0.003548148720242323\n",
      "train loss:0.0013811564318038177\n",
      "train loss:0.0010475028053250962\n",
      "train loss:0.0007059404489799839\n",
      "train loss:0.0010025835807031625\n",
      "train loss:0.003465829180432813\n",
      "train loss:0.02180348904456715\n",
      "train loss:0.001740560514353641\n",
      "train loss:0.00850417715405797\n",
      "train loss:0.011215644529377558\n",
      "train loss:0.004847022590565058\n",
      "train loss:0.007904331033717894\n",
      "train loss:0.0007103391143619979\n",
      "train loss:0.01350037905033628\n",
      "train loss:0.007977975618096383\n",
      "train loss:0.00015665429430243463\n",
      "train loss:0.003910620176967832\n",
      "train loss:0.012452963074457151\n",
      "train loss:0.000933686110884678\n",
      "train loss:0.01934438753018029\n",
      "train loss:0.0029482702783291846\n",
      "train loss:0.003516031841164724\n",
      "train loss:0.003719913486633905\n",
      "train loss:0.0012627916187502302\n",
      "train loss:0.0022697755581787844\n",
      "train loss:0.00823425363706577\n",
      "train loss:0.028998713390616427\n",
      "train loss:0.0010563266426583985\n",
      "train loss:0.0023780885446987284\n",
      "train loss:0.001736166260750664\n",
      "train loss:0.004326140656245925\n",
      "train loss:0.004288271569250499\n",
      "train loss:0.0031469159795345114\n",
      "train loss:0.006696111191598235\n",
      "train loss:0.017075196516808094\n",
      "train loss:0.007125672349886515\n",
      "train loss:0.0009304233823274986\n",
      "train loss:0.002728178006014831\n",
      "train loss:0.006604587224475021\n",
      "train loss:0.0035714497405367252\n",
      "train loss:0.001665519208506517\n",
      "train loss:0.002606118578357441\n",
      "train loss:0.020495529517411758\n",
      "train loss:0.007280375941368116\n",
      "train loss:0.004397840267977309\n",
      "train loss:0.0024330392913749234\n",
      "train loss:0.003768652440893873\n",
      "train loss:0.004411490963169114\n",
      "train loss:0.0032474339494487337\n",
      "train loss:0.001498214992038338\n",
      "train loss:0.0016654264423104485\n",
      "train loss:0.0035165289872420165\n",
      "train loss:0.002893146012253655\n",
      "train loss:0.00029886920167825423\n",
      "train loss:0.005220559129088251\n",
      "train loss:0.000825502947055096\n",
      "train loss:0.008378798119503457\n",
      "train loss:0.0037366745224694355\n",
      "train loss:0.0028423239028987695\n",
      "train loss:0.0013851297269760702\n",
      "train loss:0.0013409233922464015\n",
      "train loss:0.0019813547213210904\n",
      "train loss:0.017348665833370948\n",
      "train loss:0.001929268604377632\n",
      "train loss:0.0034153048944868896\n",
      "train loss:0.004345550609919744\n",
      "train loss:0.0007767197000741945\n",
      "train loss:0.004304586515244507\n",
      "train loss:0.0018835281870309667\n",
      "train loss:0.005761530285142781\n",
      "train loss:0.0017777614723155904\n",
      "train loss:0.005573480320932383\n",
      "train loss:0.0006688824837458028\n",
      "train loss:0.0006383762886375974\n",
      "train loss:0.003856820706682557\n",
      "train loss:0.00044602199564885444\n",
      "train loss:0.0050623506954839146\n",
      "train loss:0.0028935928199411783\n",
      "train loss:0.00827936852751671\n",
      "train loss:0.00595774543276394\n",
      "train loss:0.0005971456439497741\n",
      "train loss:0.004212145147242341\n",
      "train loss:0.0009442143110403008\n",
      "train loss:0.06961185472034909\n",
      "train loss:0.017982940646705574\n",
      "train loss:0.016539753733434505\n",
      "train loss:0.0028380943359005823\n",
      "train loss:0.0052466656215886765\n",
      "train loss:0.01744002828092001\n",
      "train loss:0.0012499446794398542\n",
      "train loss:0.002331613818936919\n",
      "train loss:0.001796804098147105\n",
      "train loss:0.0016778891279504028\n",
      "train loss:0.0010860238411543417\n",
      "train loss:0.004653862348536143\n",
      "train loss:0.001938809969571893\n",
      "train loss:0.000979221225819335\n",
      "train loss:0.0006053089957031147\n",
      "train loss:0.0034486655139162126\n",
      "train loss:0.011139549799304307\n",
      "train loss:0.005036059438192975\n",
      "train loss:0.0007348774675923777\n",
      "train loss:0.015523648327249246\n",
      "train loss:0.0004174926575001571\n",
      "train loss:0.0008892302175101197\n",
      "train loss:0.0022947358500828353\n",
      "train loss:0.0020765053615322093\n",
      "train loss:0.005015124144986113\n",
      "train loss:0.007121248090550041\n",
      "train loss:0.016831535033918443\n",
      "train loss:0.028182755207298373\n",
      "train loss:0.004647913048636532\n",
      "train loss:0.012903573140898189\n",
      "train loss:0.006098923339235237\n",
      "train loss:0.0020883878065282168\n",
      "train loss:0.004848574357856345\n",
      "train loss:0.013625583187821004\n",
      "train loss:0.009691203623918475\n",
      "train loss:0.0025048113527153886\n",
      "train loss:0.017560793059416158\n",
      "train loss:0.007771595806464756\n",
      "train loss:0.002988349861764058\n",
      "train loss:0.0028826421876967405\n",
      "train loss:0.032863272099462486\n",
      "train loss:0.0036643971744880076\n",
      "train loss:0.0008280410276346055\n",
      "train loss:0.002657253881185898\n",
      "train loss:0.003572280286586213\n",
      "train loss:0.00027199316076529907\n",
      "train loss:0.0035591020953768065\n",
      "train loss:0.0009448923118983421\n",
      "train loss:0.004299951414578546\n",
      "train loss:0.00434090685329524\n",
      "train loss:0.00048405097049004003\n",
      "train loss:0.041491143012925634\n",
      "train loss:0.004483015872310742\n",
      "train loss:0.0006709191263245005\n",
      "train loss:0.013979275851320692\n",
      "train loss:0.003748471824919998\n",
      "train loss:0.0006951825746699456\n",
      "train loss:0.0026537683177594606\n",
      "train loss:0.0021663193685247622\n",
      "train loss:0.0014694855853047961\n",
      "train loss:0.003334394548263661\n",
      "train loss:0.0011512085662124748\n",
      "train loss:0.0007195365352803173\n",
      "train loss:0.0038070804721292233\n",
      "train loss:0.0032572272874171315\n",
      "train loss:0.002177692793069991\n",
      "train loss:0.005597787921132232\n",
      "train loss:0.001149260977378213\n",
      "train loss:0.0004082269692579758\n",
      "train loss:0.017207208913696037\n",
      "train loss:0.0016977352235161584\n",
      "train loss:0.002783887319842019\n",
      "train loss:0.0013608174130865765\n",
      "train loss:0.03671636198782158\n",
      "train loss:0.002893194614004133\n",
      "train loss:0.004442328676994252\n",
      "train loss:0.0014594288982120078\n",
      "train loss:0.009504178040531129\n",
      "train loss:0.0006862011951445024\n",
      "train loss:0.000469070136883343\n",
      "train loss:0.0024022961448119887\n",
      "train loss:0.0012670324874670608\n",
      "train loss:0.006193912438728015\n",
      "train loss:0.002533460570108963\n",
      "train loss:0.001152257320288995\n",
      "train loss:0.002129194046362892\n",
      "train loss:0.002058000128279677\n",
      "train loss:0.0018603746108960036\n",
      "train loss:0.009211473097847199\n",
      "train loss:0.004684819389021014\n",
      "train loss:0.0007560484080810021\n",
      "train loss:0.001115882628499173\n",
      "train loss:0.0005036039524993988\n",
      "train loss:0.005193055299909461\n",
      "train loss:0.007990249287917436\n",
      "train loss:0.006240817744802444\n",
      "train loss:0.0005042533987872637\n",
      "train loss:0.005972976791091655\n",
      "train loss:0.005873301345478422\n",
      "train loss:0.0028339461137325776\n",
      "train loss:0.024935276591914513\n",
      "train loss:0.0007601206656945981\n",
      "train loss:0.0022654509275622744\n",
      "train loss:0.005083261422321541\n",
      "train loss:0.004073401752770954\n",
      "train loss:0.0025579581607932376\n",
      "train loss:0.0022791383276945985\n",
      "train loss:0.02693415646064925\n",
      "train loss:0.01087733763422508\n",
      "train loss:0.011055251921977531\n",
      "train loss:0.000372005617184097\n",
      "train loss:0.023832057289040934\n",
      "train loss:0.002782788838534536\n",
      "train loss:0.001573249983150973\n",
      "train loss:0.002931703277282506\n",
      "train loss:0.001708264891087461\n",
      "train loss:0.00022423305093671676\n",
      "train loss:0.00029791720682119475\n",
      "train loss:0.005443625610971149\n",
      "train loss:0.005697507481386262\n",
      "train loss:0.0004590803755346161\n",
      "train loss:9.689053063778418e-05\n",
      "train loss:0.004297703466700165\n",
      "train loss:0.005216833794636474\n",
      "train loss:0.004711278174724073\n",
      "train loss:0.0030956311489022227\n",
      "train loss:0.007618207031199516\n",
      "train loss:0.007236272209828929\n",
      "train loss:0.0018429111277894635\n",
      "train loss:0.0014591565833592726\n",
      "train loss:0.015398349293058049\n",
      "train loss:0.0004954219885002971\n",
      "train loss:0.002836848235125767\n",
      "train loss:0.004739036534565422\n",
      "train loss:0.0004241021538533379\n",
      "train loss:0.0005930419053579547\n",
      "train loss:0.0014902989148645632\n",
      "train loss:0.002646991963173146\n",
      "train loss:0.0026144381042118164\n",
      "train loss:0.002361586507935442\n",
      "train loss:0.0023350417511711656\n",
      "train loss:0.007810872286983302\n",
      "train loss:0.0005634836593128946\n",
      "train loss:0.003665902788761787\n",
      "train loss:0.0016272352579488325\n",
      "train loss:0.0021697746072134715\n",
      "train loss:0.0007005723069169957\n",
      "train loss:0.0028443493008074488\n",
      "train loss:0.0009960667866710923\n",
      "train loss:0.0025224334047078173\n",
      "train loss:0.0027371973912158755\n",
      "train loss:0.008880211450492212\n",
      "train loss:0.0017046895651385416\n",
      "train loss:0.005900049218892798\n",
      "train loss:0.003556227866425085\n",
      "train loss:0.0021834426487381863\n",
      "train loss:0.04605402393896561\n",
      "train loss:0.003793388189602882\n",
      "train loss:0.0025417393699023894\n",
      "train loss:0.002879144990955681\n",
      "train loss:0.007689070137159779\n",
      "train loss:0.032758001497929554\n",
      "train loss:0.0008942655226532285\n",
      "train loss:0.00010351719799664923\n",
      "train loss:0.00448800289602336\n",
      "train loss:0.002735537258576448\n",
      "train loss:0.00579745893744594\n",
      "train loss:0.0027721131111394953\n",
      "train loss:0.0006080631606993674\n",
      "train loss:0.002367603107405839\n",
      "train loss:0.0003712993375005015\n",
      "train loss:0.0004061111167582469\n",
      "train loss:0.007198465158471543\n",
      "train loss:0.0020562177906078326\n",
      "train loss:0.0013454119653459327\n",
      "train loss:0.0025681343634053307\n",
      "train loss:0.0032310026860069745\n",
      "train loss:0.0012152203307755644\n",
      "train loss:0.0004275326569848761\n",
      "train loss:0.0009404468180899902\n",
      "train loss:0.0007948157180052136\n",
      "train loss:0.004615101658063775\n",
      "train loss:0.004020409974499238\n",
      "train loss:0.0016732835239888558\n",
      "train loss:0.0032020284233717994\n",
      "train loss:0.0008169323048243518\n",
      "train loss:0.0033816717238458966\n",
      "train loss:0.000677598717873765\n",
      "train loss:0.002791101715935407\n",
      "train loss:0.0012361448397894806\n",
      "train loss:0.0010700191016249719\n",
      "train loss:0.005677653154901676\n",
      "train loss:0.0005599149102430937\n",
      "train loss:0.0036972363090865246\n",
      "train loss:0.0064868741525858295\n",
      "train loss:0.001098593537360848\n",
      "train loss:0.004127890375630206\n",
      "train loss:0.0038497782787998576\n",
      "train loss:0.0007651187412844807\n",
      "train loss:0.0007936501690386003\n",
      "train loss:0.00024910891211336384\n",
      "train loss:0.017445050193878726\n",
      "train loss:0.0019085889838132014\n",
      "train loss:0.001663131829366449\n",
      "train loss:0.0027445005532606244\n",
      "train loss:0.0006248813447388983\n",
      "train loss:0.0004631169772785983\n",
      "train loss:0.0014378878884963558\n",
      "train loss:0.0016349407614172243\n",
      "train loss:0.00019119211160685014\n",
      "train loss:0.009564687737044454\n",
      "train loss:0.0012214136135785649\n",
      "train loss:0.003696672558118687\n",
      "train loss:0.0018541844781630107\n",
      "train loss:0.001267745175771465\n",
      "train loss:0.004419889117434399\n",
      "train loss:0.0006495053325604544\n",
      "train loss:0.0020135278721315777\n",
      "train loss:0.019760659228867015\n",
      "train loss:0.002851140408712998\n",
      "train loss:0.0003940328731471788\n",
      "train loss:0.0006835369349552195\n",
      "train loss:0.0010408846834986803\n",
      "train loss:0.0011044703730248022\n",
      "train loss:0.0030523253049285983\n",
      "train loss:0.005270059406661262\n",
      "train loss:0.00045998877285976256\n",
      "train loss:0.0015283736600391951\n",
      "train loss:0.002128451455277437\n",
      "train loss:0.001257798382486379\n",
      "train loss:0.0010208712369083597\n",
      "train loss:0.003852399675250302\n",
      "train loss:0.0008790713047550373\n",
      "train loss:0.0007733136421767134\n",
      "train loss:0.004081190954275529\n",
      "train loss:0.0009229327273504058\n",
      "train loss:0.0045909592787456415\n",
      "train loss:0.0002148980263604004\n",
      "train loss:0.0005888473320166524\n",
      "train loss:0.00011545690240934715\n",
      "train loss:0.004888257946781166\n",
      "train loss:0.0006807137163351086\n",
      "train loss:0.0018815518193204513\n",
      "train loss:0.001788382789328636\n",
      "train loss:0.0046201830704803454\n",
      "train loss:0.0026204287344850806\n",
      "train loss:0.00429021656854904\n",
      "train loss:0.00578617629691542\n",
      "train loss:0.0018922991227015831\n",
      "train loss:0.020426519646131725\n",
      "train loss:0.0018020343995727441\n",
      "train loss:0.000412129421685288\n",
      "train loss:0.026729744629663772\n",
      "train loss:0.0014151649835909817\n",
      "train loss:0.009100478729860764\n",
      "train loss:0.012470226633796907\n",
      "train loss:0.0009228933919195633\n",
      "train loss:0.0003754652172420925\n",
      "train loss:0.0034522016392032613\n",
      "train loss:0.002326520027646318\n",
      "train loss:0.0024814419131251667\n",
      "train loss:0.0008264277757020365\n",
      "train loss:0.0016164453421982014\n",
      "train loss:0.0016809799637122497\n",
      "train loss:0.009166331684388207\n",
      "train loss:0.002149907612838612\n",
      "train loss:0.007393016342715048\n",
      "train loss:0.0029728560017358422\n",
      "train loss:0.0011896912496544983\n",
      "train loss:0.002380590163150002\n",
      "train loss:0.0005343517375136868\n",
      "train loss:0.009277865326851348\n",
      "train loss:0.001050984594002233\n",
      "train loss:0.0008195444427533087\n",
      "train loss:0.00147736703644476\n",
      "train loss:0.007170811501033639\n",
      "train loss:0.0006852342803392766\n",
      "train loss:0.003258125661946373\n",
      "train loss:0.0030540907144739103\n",
      "train loss:0.002739554402734395\n",
      "train loss:0.00028837540200947373\n",
      "train loss:0.001607114377555315\n",
      "train loss:0.0021871124651448113\n",
      "train loss:0.002150073868635854\n",
      "train loss:0.007806696813758952\n",
      "train loss:0.0009249503749187578\n",
      "train loss:0.0004599258183768399\n",
      "train loss:0.009830137123251937\n",
      "train loss:0.0012714118999735669\n",
      "train loss:0.004443167672528669\n",
      "train loss:0.0023044168961292005\n",
      "train loss:0.003583148894539179\n",
      "train loss:0.03293909807555223\n",
      "train loss:0.01147040175233003\n",
      "train loss:0.0031966393409375692\n",
      "train loss:0.0029974168572804868\n",
      "train loss:0.0002967849148988062\n",
      "train loss:0.0008275617863347705\n",
      "train loss:0.001991468735936071\n",
      "train loss:0.0018172238482316732\n",
      "train loss:0.0021509944414857094\n",
      "train loss:0.005890789844017474\n",
      "train loss:0.002182495980307491\n",
      "train loss:0.001689299207608331\n",
      "train loss:0.0021480255970541774\n",
      "train loss:0.002946011812689625\n",
      "train loss:0.00044064875407055765\n",
      "train loss:0.0009088765864398149\n",
      "train loss:0.0004233956910120752\n",
      "train loss:0.007599854740089288\n",
      "train loss:0.0011284678004699986\n",
      "train loss:0.034439465364546\n",
      "train loss:0.0004460672351097275\n",
      "train loss:0.0009020888245377697\n",
      "train loss:0.003312587851420868\n",
      "train loss:0.00021355184485453304\n",
      "train loss:0.0020762494445798313\n",
      "train loss:0.0022473247983633084\n",
      "train loss:0.0006146110952496513\n",
      "train loss:0.0033286899990227696\n",
      "train loss:0.000915422251271965\n",
      "train loss:0.026292183959566368\n",
      "train loss:0.004892658250034234\n",
      "train loss:0.001454392848809252\n",
      "train loss:0.004712364250642498\n",
      "train loss:0.0011310757503863408\n",
      "train loss:0.001237034973556395\n",
      "train loss:0.006626141213293335\n",
      "train loss:0.00032180724313468997\n",
      "train loss:0.005232742198076073\n",
      "train loss:0.009842135960506832\n",
      "train loss:0.0036073961457058507\n",
      "train loss:0.0008332433657053665\n",
      "train loss:0.003449856892697051\n",
      "train loss:0.005625709590255248\n",
      "train loss:0.003409926714662105\n",
      "train loss:0.0015018567951789888\n",
      "train loss:0.004541675333895395\n",
      "train loss:0.009258886017417445\n",
      "train loss:0.0019755272303855873\n",
      "train loss:0.000849184701849733\n",
      "train loss:0.00023316111154444576\n",
      "train loss:0.0021238333543425764\n",
      "train loss:0.013609859404393614\n",
      "train loss:0.0018758074644005262\n",
      "train loss:0.0005043849430782528\n",
      "train loss:0.0006376913756879213\n",
      "train loss:0.03042865085328128\n",
      "train loss:0.00046239447564368305\n",
      "train loss:0.0010282238402828721\n",
      "train loss:0.039967981976616475\n",
      "train loss:0.0001411892379465881\n",
      "train loss:0.0006614113731506262\n",
      "train loss:0.0016796684691195616\n",
      "train loss:0.0001304680681841643\n",
      "train loss:0.0005167238060022664\n",
      "train loss:0.0007499987228286034\n",
      "train loss:0.009025841789817154\n",
      "train loss:0.018421913781410407\n",
      "train loss:0.0007666832090448942\n",
      "train loss:0.008401831995647778\n",
      "train loss:0.017026433816892343\n",
      "train loss:0.00033191668361553795\n",
      "train loss:0.003337296978587889\n",
      "train loss:0.010348785275951065\n",
      "train loss:0.0008284789155744886\n",
      "train loss:0.002007329648496137\n",
      "train loss:0.0005300280359250025\n",
      "train loss:0.0024696168917001863\n",
      "train loss:0.003915262444248649\n",
      "train loss:0.003931005264672199\n",
      "train loss:0.0015131962691600032\n",
      "train loss:0.0026008918840541213\n",
      "train loss:0.0020446883383809893\n",
      "train loss:0.00912374156216548\n",
      "train loss:0.001032420545468315\n",
      "train loss:0.0010732360697429382\n",
      "train loss:0.0027086804683338407\n",
      "train loss:0.0014876937414859946\n",
      "train loss:0.00014633206210527044\n",
      "train loss:0.019952951032834357\n",
      "train loss:0.008412031763894797\n",
      "train loss:0.005474034339202135\n",
      "train loss:0.010160669814612737\n",
      "train loss:0.0007800979423759143\n",
      "train loss:0.005717274268813327\n",
      "train loss:0.004076500694497793\n",
      "train loss:0.0005130132674056368\n",
      "train loss:0.0003124029909602183\n",
      "train loss:0.00450159499493824\n",
      "train loss:0.0010284744122848932\n",
      "train loss:0.0005327345882864961\n",
      "train loss:0.00376578699877876\n",
      "train loss:0.02812575544008008\n",
      "train loss:0.00023820331672419224\n",
      "=== epoch:14, train acc:0.998, test acc:0.986 ===\n",
      "train loss:0.0015517060980521156\n",
      "train loss:0.003059875711957114\n",
      "train loss:0.007998700505370876\n",
      "train loss:0.00822541449219508\n",
      "train loss:0.0004123650277647638\n",
      "train loss:0.003284638154868732\n",
      "train loss:0.0014699746399306204\n",
      "train loss:0.000696495314061197\n",
      "train loss:0.0007843389300282785\n",
      "train loss:0.001437491522285569\n",
      "train loss:0.004369915838649801\n",
      "train loss:0.002289589447698716\n",
      "train loss:0.002158510224464774\n",
      "train loss:0.01085103647322535\n",
      "train loss:0.006200647646853364\n",
      "train loss:0.0006397823886862926\n",
      "train loss:0.000985830669183874\n",
      "train loss:0.032653136476826376\n",
      "train loss:0.001825232500573498\n",
      "train loss:0.001081437625988427\n",
      "train loss:0.0029328884542573954\n",
      "train loss:0.002066805157190453\n",
      "train loss:0.009072054670736114\n",
      "train loss:0.0036030818043721368\n",
      "train loss:0.06034367484645528\n",
      "train loss:0.013989223561935155\n",
      "train loss:0.0014276693786009979\n",
      "train loss:0.0016996101030103746\n",
      "train loss:0.0012735253024805666\n",
      "train loss:0.0015166308573052265\n",
      "train loss:0.0018533855517139943\n",
      "train loss:0.004861986456090263\n",
      "train loss:0.0014698891433433381\n",
      "train loss:0.005363730643257629\n",
      "train loss:0.0037773485070518296\n",
      "train loss:0.0016858191130317444\n",
      "train loss:0.00031954078065956016\n",
      "train loss:0.004150886361023993\n",
      "train loss:0.0063744437561150434\n",
      "train loss:0.0024826889207888985\n",
      "train loss:0.0032395673344960624\n",
      "train loss:0.0004486482756821921\n",
      "train loss:0.001879097263952563\n",
      "train loss:0.002117876405606608\n",
      "train loss:0.0027629578292321533\n",
      "train loss:0.004357185302117553\n",
      "train loss:0.0015187594730667368\n",
      "train loss:0.0017508254112461338\n",
      "train loss:0.007087501699206204\n",
      "train loss:0.0014863920941381756\n",
      "train loss:0.004745826117680093\n",
      "train loss:0.0009616434509453883\n",
      "train loss:0.0014992094992001142\n",
      "train loss:0.004799371954583337\n",
      "train loss:0.0003328191783288905\n",
      "train loss:0.0008672634950110054\n",
      "train loss:0.0032317425235860613\n",
      "train loss:0.0036663751859290035\n",
      "train loss:0.003913022636794709\n",
      "train loss:0.00666812578790602\n",
      "train loss:0.0015971645512530502\n",
      "train loss:0.002521624133883541\n",
      "train loss:0.003308616502097407\n",
      "train loss:0.00014448625050379716\n",
      "train loss:0.0006858571631565262\n",
      "train loss:0.0007145468913234789\n",
      "train loss:0.002503658902913024\n",
      "train loss:0.009046123860859021\n",
      "train loss:0.012979228048963313\n",
      "train loss:0.0033345543352197625\n",
      "train loss:0.0006449015519104973\n",
      "train loss:0.0007940071506797754\n",
      "train loss:0.006816441037210361\n",
      "train loss:0.0019634040057298573\n",
      "train loss:0.005495206765936169\n",
      "train loss:0.0027819002979964985\n",
      "train loss:0.0006345268301198307\n",
      "train loss:0.01757922313288932\n",
      "train loss:0.004845737545010133\n",
      "train loss:0.0018557474311232413\n",
      "train loss:0.0010456903778278273\n",
      "train loss:0.0025307270888296186\n",
      "train loss:0.017472145117815557\n",
      "train loss:0.01037057442847225\n",
      "train loss:0.005150044534665416\n",
      "train loss:0.00031326132728534857\n",
      "train loss:0.011128750890879528\n",
      "train loss:0.0003663533907666687\n",
      "train loss:0.0005344700433632107\n",
      "train loss:0.0005448473908573948\n",
      "train loss:0.0005277278160614618\n",
      "train loss:0.001719984328635644\n",
      "train loss:0.00015458762571725877\n",
      "train loss:0.006873231241197766\n",
      "train loss:0.015753342740394975\n",
      "train loss:0.001783467457618114\n",
      "train loss:0.0034965046331063188\n",
      "train loss:0.0004253077508332224\n",
      "train loss:0.0017595133088374433\n",
      "train loss:0.0005895502066293309\n",
      "train loss:0.0008040805407714377\n",
      "train loss:0.00021633133243515276\n",
      "train loss:0.00282638730457483\n",
      "train loss:0.0016734455874795953\n",
      "train loss:0.011497009023166775\n",
      "train loss:0.005901738704751208\n",
      "train loss:0.01208044253471855\n",
      "train loss:0.0005143874503187499\n",
      "train loss:0.0020818934419566983\n",
      "train loss:0.007021641231583766\n",
      "train loss:0.014362875133540988\n",
      "train loss:0.0007654022632803387\n",
      "train loss:0.0024092557775863017\n",
      "train loss:0.007581568427790869\n",
      "train loss:0.0009856225866287831\n",
      "train loss:0.0005322185189154068\n",
      "train loss:0.004835808639357405\n",
      "train loss:0.003163443384690337\n",
      "train loss:0.007804442537462017\n",
      "train loss:0.0011502562408812157\n",
      "train loss:0.003987862190484623\n",
      "train loss:0.0020618155035428964\n",
      "train loss:0.007909155018843334\n",
      "train loss:0.005501230852419901\n",
      "train loss:0.0006225476686455661\n",
      "train loss:0.0019953666321662093\n",
      "train loss:0.005243739506920888\n",
      "train loss:0.0009108551058921277\n",
      "train loss:0.0013677538511031248\n",
      "train loss:0.005817862612984036\n",
      "train loss:0.0028726044321375145\n",
      "train loss:0.00030758538950630186\n",
      "train loss:0.003986444651381228\n",
      "train loss:0.005798163185180703\n",
      "train loss:0.0012873013304249854\n",
      "train loss:0.0029236629756416617\n",
      "train loss:0.004217801816517892\n",
      "train loss:0.0012018983275435054\n",
      "train loss:0.0014395498957469736\n",
      "train loss:0.0018104604921551555\n",
      "train loss:0.0016320732141228414\n",
      "train loss:0.013087802030178319\n",
      "train loss:0.0003480733115687716\n",
      "train loss:0.0001856974675613965\n",
      "train loss:0.007066738233922969\n",
      "train loss:0.002808984802781144\n",
      "train loss:0.006967741861410364\n",
      "train loss:0.0008943510487097492\n",
      "train loss:0.0057210232141561455\n",
      "train loss:0.0008665656021816634\n",
      "train loss:0.0005296075746447157\n",
      "train loss:0.00026849623199848847\n",
      "train loss:0.0006189794546823329\n",
      "train loss:0.002180353746743946\n",
      "train loss:0.00219089575162042\n",
      "train loss:0.013228182666524637\n",
      "train loss:0.0027308642788758182\n",
      "train loss:0.006813555268272697\n",
      "train loss:0.004421307863185217\n",
      "train loss:0.0014764781414587386\n",
      "train loss:0.002332474206023963\n",
      "train loss:0.0019790509828666635\n",
      "train loss:0.0010236012902747266\n",
      "train loss:0.003828091076710427\n",
      "train loss:0.005651978832511374\n",
      "train loss:0.0004758624218440994\n",
      "train loss:0.0035553259563105817\n",
      "train loss:0.0033235170971483924\n",
      "train loss:0.0025596441667163116\n",
      "train loss:0.001801142721278851\n",
      "train loss:0.0026510942923767557\n",
      "train loss:0.0005243094195189753\n",
      "train loss:0.011387350271733286\n",
      "train loss:0.0007611963106269449\n",
      "train loss:0.00020182430492240617\n",
      "train loss:0.0019795460335537006\n",
      "train loss:0.004582870983704391\n",
      "train loss:0.0013318533722068335\n",
      "train loss:0.002005988341154821\n",
      "train loss:0.000686227999116202\n",
      "train loss:0.003654788388343425\n",
      "train loss:0.0048755512280105875\n",
      "train loss:0.0007660930813959406\n",
      "train loss:0.00985382715586846\n",
      "train loss:0.004144241446734029\n",
      "train loss:0.015289065277842928\n",
      "train loss:0.009770346916994821\n",
      "train loss:0.005079801900991566\n",
      "train loss:0.0038979796214660594\n",
      "train loss:8.15435205300696e-05\n",
      "train loss:0.0060124585045725\n",
      "train loss:0.0027055198336958797\n",
      "train loss:0.002644132902209386\n",
      "train loss:0.013287237322084155\n",
      "train loss:0.001440489999947406\n",
      "train loss:0.011700162647442282\n",
      "train loss:0.00987107438556723\n",
      "train loss:0.0013863434287173092\n",
      "train loss:0.046698301883378666\n",
      "train loss:0.0011922747402594895\n",
      "train loss:0.0038911143771263616\n",
      "train loss:0.006133261761274256\n",
      "train loss:0.022302624337179264\n",
      "train loss:0.0022479487318318144\n",
      "train loss:0.001606177342976281\n",
      "train loss:0.003430589640340078\n",
      "train loss:0.0012572921578849823\n",
      "train loss:0.0021278558117140446\n",
      "train loss:0.0074420753809763054\n",
      "train loss:0.00012520778669787986\n",
      "train loss:0.0009785746480420504\n",
      "train loss:0.000364107955490537\n",
      "train loss:0.004631562722966169\n",
      "train loss:0.006707425627396061\n",
      "train loss:0.0016122831786127298\n",
      "train loss:0.00345895510182068\n",
      "train loss:0.005585571266345089\n",
      "train loss:0.000774654991829844\n",
      "train loss:0.00040518359690557855\n",
      "train loss:0.0028068912388681854\n",
      "train loss:0.0005179157446339876\n",
      "train loss:0.0012390590742558706\n",
      "train loss:0.0012832572848764867\n",
      "train loss:0.009197839695230817\n",
      "train loss:0.0023584733466273907\n",
      "train loss:0.008970762488451266\n",
      "train loss:0.0034600256456567098\n",
      "train loss:0.0005267799855602649\n",
      "train loss:0.0021383528105002963\n",
      "train loss:0.002047391804187094\n",
      "train loss:0.0007534198619806864\n",
      "train loss:0.0017327075456192542\n",
      "train loss:0.0017378561127876404\n",
      "train loss:0.00014485152452715905\n",
      "train loss:0.0037832996466588237\n",
      "train loss:0.0021119679314419385\n",
      "train loss:0.00016234713145783276\n",
      "train loss:0.005752852831695287\n",
      "train loss:0.007905551060564142\n",
      "train loss:0.0005678583064747382\n",
      "train loss:0.0020650795005237362\n",
      "train loss:0.0016624055216657952\n",
      "train loss:0.006009460239217423\n",
      "train loss:0.0009864587221661773\n",
      "train loss:0.0008189265141323139\n",
      "train loss:0.001638818314316377\n",
      "train loss:0.0013365337742789276\n",
      "train loss:0.0014693888808695512\n",
      "train loss:0.001192689581682801\n",
      "train loss:0.0015262664276267947\n",
      "train loss:0.00039555228773348425\n",
      "train loss:0.005390377470942219\n",
      "train loss:0.0015187138499441158\n",
      "train loss:0.0026756738472379256\n",
      "train loss:0.007704143863787296\n",
      "train loss:0.0011170675577708649\n",
      "train loss:0.0036901748432710602\n",
      "train loss:0.0034728588505379913\n",
      "train loss:0.002579481676315936\n",
      "train loss:0.0026022849236135054\n",
      "train loss:0.0018363715514776227\n",
      "train loss:0.00014670733007061176\n",
      "train loss:0.0009258124489189407\n",
      "train loss:0.00025862073166502456\n",
      "train loss:0.0018407298316858128\n",
      "train loss:0.00456459139708899\n",
      "train loss:0.0033136962198879044\n",
      "train loss:0.0033459753138329103\n",
      "train loss:0.005884312605158549\n",
      "train loss:0.0007947097077301463\n",
      "train loss:0.0013308002693150453\n",
      "train loss:0.0008229877076624341\n",
      "train loss:0.003686256117215561\n",
      "train loss:0.0016332043269030481\n",
      "train loss:0.000876312392436243\n",
      "train loss:0.005274794623263582\n",
      "train loss:0.008488263766627169\n",
      "train loss:0.004250878349791238\n",
      "train loss:0.003110197905239339\n",
      "train loss:0.0011198587036783765\n",
      "train loss:0.003707063787945869\n",
      "train loss:0.0006068763594509184\n",
      "train loss:0.017064545562593948\n",
      "train loss:0.0010925857219282594\n",
      "train loss:0.0004043814976155758\n",
      "train loss:0.010145473733372951\n",
      "train loss:0.0021155998247895337\n",
      "train loss:0.003986481484745308\n",
      "train loss:0.0008241714273688358\n",
      "train loss:0.0015498104094320007\n",
      "train loss:0.0013071069478072619\n",
      "train loss:0.009101500084919181\n",
      "train loss:0.0003604684193601953\n",
      "train loss:0.003379188809642186\n",
      "train loss:0.0021754634922224137\n",
      "train loss:0.0011965857442769916\n",
      "train loss:0.002539597697855549\n",
      "train loss:0.010801876906369988\n",
      "train loss:0.0027501295018637307\n",
      "train loss:0.0017292156829912995\n",
      "train loss:0.0024602818724377778\n",
      "train loss:0.00030345744325422725\n",
      "train loss:0.012068943915826311\n",
      "train loss:0.0025008539841883137\n",
      "train loss:0.0025494441708918715\n",
      "train loss:0.009989159734413737\n",
      "train loss:0.0002118730339460352\n",
      "train loss:0.0013270779677926022\n",
      "train loss:0.0059538840703534735\n",
      "train loss:0.02074183153978459\n",
      "train loss:0.00026387051007333034\n",
      "train loss:0.006442494968023167\n",
      "train loss:0.007790798321285812\n",
      "train loss:0.014133464979456839\n",
      "train loss:0.007333705562546093\n",
      "train loss:0.035816738209022966\n",
      "train loss:0.001020173446764968\n",
      "train loss:0.006852315243275214\n",
      "train loss:0.0011347923631448453\n",
      "train loss:0.001585363282712996\n",
      "train loss:0.001761709304407126\n",
      "train loss:0.020422879478547026\n",
      "train loss:0.005223055998223224\n",
      "train loss:0.00044353820100901406\n",
      "train loss:0.00022629255976032165\n",
      "train loss:0.005487298607575153\n",
      "train loss:0.002779472973324752\n",
      "train loss:0.003824725016570242\n",
      "train loss:0.003555699983066279\n",
      "train loss:0.0009511621567024346\n",
      "train loss:6.942504885792413e-05\n",
      "train loss:0.0015171944700586926\n",
      "train loss:0.024489616799710037\n",
      "train loss:0.004205415763600872\n",
      "train loss:0.004608255697546037\n",
      "train loss:0.0009569695228342406\n",
      "train loss:0.0091711088511159\n",
      "train loss:0.0030108297488403413\n",
      "train loss:0.0007522608456002473\n",
      "train loss:0.007583280851931552\n",
      "train loss:0.0016942811609677159\n",
      "train loss:0.0016064835579476305\n",
      "train loss:0.0011677458756790802\n",
      "train loss:0.0034897843237974902\n",
      "train loss:0.0012756297931430366\n",
      "train loss:0.007432184820854057\n",
      "train loss:0.000486598550161534\n",
      "train loss:0.0030772147976399883\n",
      "train loss:0.001160750943595047\n",
      "train loss:0.001639922300966674\n",
      "train loss:0.002151974591173938\n",
      "train loss:0.00026870644428046155\n",
      "train loss:0.0014068609194249782\n",
      "train loss:0.0009991905808608235\n",
      "train loss:0.0005144683967797894\n",
      "train loss:0.00741460146954243\n",
      "train loss:0.000736666264125061\n",
      "train loss:0.000423023838898289\n",
      "train loss:0.002452773984400196\n",
      "train loss:0.01200361284712563\n",
      "train loss:0.0019238234317591268\n",
      "train loss:0.00200999342387258\n",
      "train loss:0.0015014779787333155\n",
      "train loss:0.004705717027907202\n",
      "train loss:0.0009685063920504046\n",
      "train loss:0.0050990234026204164\n",
      "train loss:0.003399904833079339\n",
      "train loss:0.0016235997532262722\n",
      "train loss:0.01084251282791826\n",
      "train loss:0.002694754601903894\n",
      "train loss:0.0019158952923363992\n",
      "train loss:0.00016561985989494343\n",
      "train loss:0.002120729836515484\n",
      "train loss:0.0005199383616339318\n",
      "train loss:0.0012181796244688243\n",
      "train loss:0.012787537297354833\n",
      "train loss:0.0027895867651673584\n",
      "train loss:0.012107181284629263\n",
      "train loss:0.002307625121679568\n",
      "train loss:0.000651871253534746\n",
      "train loss:0.002397996017774858\n",
      "train loss:0.0012942710287730667\n",
      "train loss:0.020035053600447886\n",
      "train loss:0.004209563256130913\n",
      "train loss:0.0061379485131423306\n",
      "train loss:0.003982914671969975\n",
      "train loss:0.0015399174700063284\n",
      "train loss:0.0006639441191797202\n",
      "train loss:6.642723041789918e-05\n",
      "train loss:0.003350753326488005\n",
      "train loss:0.0029743033331435576\n",
      "train loss:0.0010818414132441783\n",
      "train loss:0.008538765564643263\n",
      "train loss:0.0026793137120778047\n",
      "train loss:0.001206347490230314\n",
      "train loss:0.005618534454224258\n",
      "train loss:0.0022123679387666072\n",
      "train loss:0.006297347919477317\n",
      "train loss:0.002334298456776298\n",
      "train loss:0.0001418146700362268\n",
      "train loss:0.0001644952869781267\n",
      "train loss:0.019302428300652617\n",
      "train loss:0.00283990869404405\n",
      "train loss:0.007647678146108425\n",
      "train loss:0.0035470862277932535\n",
      "train loss:0.01519157293519479\n",
      "train loss:0.002837303452581586\n",
      "train loss:0.0009863672797258405\n",
      "train loss:0.002317765758119662\n",
      "train loss:0.001463515770248062\n",
      "train loss:0.0005890088835183709\n",
      "train loss:0.000392571917139186\n",
      "train loss:0.0007702685129118426\n",
      "train loss:0.00011878759271649435\n",
      "train loss:0.0008445885998320894\n",
      "train loss:0.025404668736948303\n",
      "train loss:0.0008680486069937922\n",
      "train loss:0.0027848671427685816\n",
      "train loss:0.0016491471928328704\n",
      "train loss:0.0010674555351413045\n",
      "train loss:0.001985148960160153\n",
      "train loss:0.001969687885175149\n",
      "train loss:0.003283370528698464\n",
      "train loss:0.0021702184788495583\n",
      "train loss:0.0011910582973994833\n",
      "train loss:0.047037948811767254\n",
      "train loss:0.0016446275625322624\n",
      "train loss:0.0007619447320531166\n",
      "train loss:0.0004037761943390543\n",
      "train loss:0.0046289490083316846\n",
      "train loss:0.0001005733386109752\n",
      "train loss:0.003009576135658133\n",
      "train loss:0.0044113806168939946\n",
      "train loss:0.0020784189199879043\n",
      "train loss:0.0008451027445644764\n",
      "train loss:0.00015012375594325282\n",
      "train loss:0.0012639765688734767\n",
      "train loss:0.00041424586469154915\n",
      "train loss:0.0021469259637301695\n",
      "train loss:0.0037985853294039023\n",
      "train loss:0.00028063783043358044\n",
      "train loss:0.0033473748578055945\n",
      "train loss:0.0001787688621907609\n",
      "train loss:0.008187430073536837\n",
      "train loss:0.011487981085655026\n",
      "train loss:0.0017820161855100305\n",
      "train loss:0.003106757895367089\n",
      "train loss:0.0002400231486160778\n",
      "train loss:0.0014955211292189258\n",
      "train loss:0.0009170297798488166\n",
      "train loss:0.002499790575689818\n",
      "train loss:0.0011380786998949706\n",
      "train loss:0.0021158614449309386\n",
      "train loss:0.0008849728417520973\n",
      "train loss:0.004607115280353639\n",
      "train loss:0.0022685440615070615\n",
      "train loss:0.004771964712173366\n",
      "train loss:0.002374727170734098\n",
      "train loss:0.001263568275337863\n",
      "train loss:0.0013623065931595312\n",
      "train loss:0.00034991660601723555\n",
      "train loss:0.00408978556977828\n",
      "train loss:0.00495857114040102\n",
      "train loss:0.0016049539089799509\n",
      "train loss:0.0017338544457795111\n",
      "train loss:0.0005216894800798326\n",
      "train loss:0.0013068566697332137\n",
      "train loss:0.007932866849054913\n",
      "train loss:0.002846291036490215\n",
      "train loss:0.0012611666504204178\n",
      "train loss:0.003165708856649526\n",
      "train loss:0.0011504608497366884\n",
      "train loss:0.0022520316989102524\n",
      "train loss:0.0020904484044206788\n",
      "train loss:0.0017301811315066612\n",
      "train loss:0.0034404413962711195\n",
      "train loss:0.00748185117846619\n",
      "train loss:0.004411167620104288\n",
      "train loss:0.0008701796093603064\n",
      "train loss:0.003505119036991581\n",
      "train loss:0.00423960403865292\n",
      "train loss:0.0015094093867817307\n",
      "train loss:0.0007066242069307816\n",
      "train loss:0.000255919850176716\n",
      "train loss:0.004406485969010258\n",
      "train loss:0.0006170698424874863\n",
      "train loss:0.000706033377520923\n",
      "train loss:0.0002527566486696087\n",
      "train loss:0.0017705092599163204\n",
      "train loss:0.003232308041358135\n",
      "train loss:0.000530112385173719\n",
      "train loss:0.013514983830865288\n",
      "train loss:0.013179141511427708\n",
      "train loss:0.001062924411280017\n",
      "train loss:0.0013886346613218297\n",
      "train loss:0.006546546214978562\n",
      "train loss:0.0007896995136173322\n",
      "train loss:0.00417117066398325\n",
      "train loss:0.04214535828661588\n",
      "train loss:0.00022939872873803402\n",
      "train loss:0.004915901013524392\n",
      "train loss:0.005776588494776835\n",
      "train loss:0.0110989637326918\n",
      "train loss:0.003729057314281975\n",
      "train loss:0.04540250633535732\n",
      "train loss:0.0078811977732411\n",
      "train loss:0.00044988160479541585\n",
      "train loss:0.0015746672863621658\n",
      "train loss:0.0008959372053154234\n",
      "train loss:0.0021079712358045804\n",
      "train loss:0.0068266492765831745\n",
      "train loss:0.0006856254683044801\n",
      "train loss:0.0026192813637242515\n",
      "train loss:0.006353395753262291\n",
      "train loss:0.007158942765690646\n",
      "train loss:0.03066226340516201\n",
      "train loss:0.0012462728780651868\n",
      "train loss:0.0005066362249260884\n",
      "train loss:0.00021530187671021172\n",
      "train loss:0.00032230263564849993\n",
      "train loss:0.00034666771684948314\n",
      "train loss:0.00502304507710796\n",
      "train loss:0.0015970953230238583\n",
      "train loss:0.002040535955358461\n",
      "train loss:0.00027406784480754566\n",
      "train loss:0.0020471525639686222\n",
      "train loss:0.00038307083641869576\n",
      "train loss:0.006906638634893103\n",
      "train loss:0.0009704937321502986\n",
      "train loss:0.00022582360997482908\n",
      "train loss:0.007432682116397359\n",
      "train loss:0.0032541416667142\n",
      "train loss:0.0009516386165834963\n",
      "train loss:0.05770892480861777\n",
      "train loss:0.001197259389802809\n",
      "train loss:0.0019117765893499198\n",
      "train loss:0.0006329806482680956\n",
      "train loss:0.01301025808971113\n",
      "train loss:0.0010818606149559122\n",
      "train loss:0.027752204768451572\n",
      "train loss:0.00583199716788865\n",
      "train loss:0.0005076182870111867\n",
      "train loss:0.0024548226919601803\n",
      "train loss:0.01584779765414752\n",
      "train loss:0.003162069471331442\n",
      "train loss:0.0010089891212639271\n",
      "train loss:0.005304307627268655\n",
      "train loss:0.003719209783222966\n",
      "train loss:0.002032452519821053\n",
      "train loss:0.0016186918118316364\n",
      "train loss:0.005386861751700503\n",
      "train loss:0.026243683152450573\n",
      "train loss:0.00032309791798541094\n",
      "train loss:0.02348786011798247\n",
      "train loss:0.002705226883204755\n",
      "train loss:0.0010662977125986898\n",
      "train loss:0.0033021131845122065\n",
      "train loss:0.0024882375253927214\n",
      "train loss:0.00024539292106108454\n",
      "train loss:0.001133927614613175\n",
      "train loss:0.003352529818913975\n",
      "train loss:0.001093028787701378\n",
      "train loss:0.0020954411193555966\n",
      "train loss:0.016384333372095335\n",
      "train loss:0.00406290331700426\n",
      "train loss:0.0012737606785699993\n",
      "train loss:0.0008380229359833733\n",
      "train loss:0.003480063338820476\n",
      "train loss:0.0017279946135186955\n",
      "train loss:0.0033500860231948848\n",
      "train loss:0.004306628779751721\n",
      "train loss:0.0024598895479664997\n",
      "train loss:0.004196810068132852\n",
      "train loss:0.0026359275710483064\n",
      "train loss:0.0037872556756310114\n",
      "train loss:0.003712836389739903\n",
      "train loss:0.0024199088662746463\n",
      "train loss:0.0014657041852865996\n",
      "train loss:0.0073311192900442\n",
      "train loss:0.00544137645433931\n",
      "train loss:0.0018242332651866378\n",
      "train loss:0.004971882713860547\n",
      "train loss:0.002586996642162551\n",
      "train loss:0.0026196019900351485\n",
      "train loss:0.005938812597451232\n",
      "train loss:0.0052095390183526605\n",
      "train loss:0.0013783313571381517\n",
      "train loss:0.004608229293139036\n",
      "train loss:0.0010193040858078799\n",
      "train loss:0.0020576393051521453\n",
      "train loss:0.0023883366602257096\n",
      "train loss:0.0019108535897244172\n",
      "train loss:0.006708452199507542\n",
      "train loss:0.003858375261226159\n",
      "train loss:0.0023613874126089144\n",
      "train loss:0.003397146482149063\n",
      "train loss:0.00028431567869466036\n",
      "train loss:0.002033405503404181\n",
      "train loss:0.0017209175402679742\n",
      "train loss:0.010876538942446088\n",
      "=== epoch:15, train acc:0.996, test acc:0.987 ===\n",
      "train loss:0.006403162710676805\n",
      "train loss:0.0016101114832092868\n",
      "train loss:0.0039377792701365205\n",
      "train loss:0.022191974416879433\n",
      "train loss:0.002859049151612982\n",
      "train loss:0.000721276235182301\n",
      "train loss:0.0021156283658515197\n",
      "train loss:0.006151300899209499\n",
      "train loss:0.001232980008309275\n",
      "train loss:0.0007099292505709793\n",
      "train loss:0.004250451944701566\n",
      "train loss:0.0022153753768680146\n",
      "train loss:0.003118894882618364\n",
      "train loss:0.001019976456784004\n",
      "train loss:0.012813728320848605\n",
      "train loss:0.0006576941795248198\n",
      "train loss:0.00631452130272933\n",
      "train loss:0.0014815261269224696\n",
      "train loss:0.002520099658042665\n",
      "train loss:0.004778817824782701\n",
      "train loss:0.0030219489967688944\n",
      "train loss:0.0004797037988953469\n",
      "train loss:0.005406817957500215\n",
      "train loss:0.0022134306206954917\n",
      "train loss:0.0020930253317904667\n",
      "train loss:0.0008858662434091122\n",
      "train loss:0.00010143761266115203\n",
      "train loss:0.00043400009109655964\n",
      "train loss:0.0012626279485492941\n",
      "train loss:0.00357802663157346\n",
      "train loss:0.00668180606643678\n",
      "train loss:0.013859494026295216\n",
      "train loss:0.007463433294451392\n",
      "train loss:0.00036711630263323874\n",
      "train loss:0.023851893198173154\n",
      "train loss:0.00043823361607374844\n",
      "train loss:0.0017307057410926733\n",
      "train loss:0.008273125032036806\n",
      "train loss:0.00107268668644683\n",
      "train loss:0.006275438531995272\n",
      "train loss:0.00033214745046582\n",
      "train loss:0.004153216349539349\n",
      "train loss:0.004581563536433394\n",
      "train loss:0.006815424777017371\n",
      "train loss:0.0008789847905676682\n",
      "train loss:0.0014313056330603352\n",
      "train loss:0.002482725381544598\n",
      "train loss:0.0031220921311199785\n",
      "train loss:0.004364553389100304\n",
      "train loss:0.00022503575364754645\n",
      "train loss:0.004964869017683946\n",
      "train loss:0.000874465220942425\n",
      "train loss:0.003425081155900783\n",
      "train loss:0.0013608033789951454\n",
      "train loss:0.03364746912012742\n",
      "train loss:0.002176240798891157\n",
      "train loss:0.0005011165155002963\n",
      "train loss:0.007491917060954741\n",
      "train loss:0.0013019796479860695\n",
      "train loss:0.008402468175609702\n",
      "train loss:0.00015302547738640392\n",
      "train loss:0.004477319691116098\n",
      "train loss:0.0015484111332288264\n",
      "train loss:0.004371983428656161\n",
      "train loss:0.002160135942409761\n",
      "train loss:0.0009717317166919864\n",
      "train loss:0.0009896516239133483\n",
      "train loss:0.05300512336763937\n",
      "train loss:0.0020663812615892532\n",
      "train loss:0.0010842419535419408\n",
      "train loss:0.002597479295539354\n",
      "train loss:0.0048779561025015595\n",
      "train loss:0.006223858804638852\n",
      "train loss:0.004424077697022937\n",
      "train loss:0.0007083673539652609\n",
      "train loss:0.008156387366053931\n",
      "train loss:0.0012826250040530484\n",
      "train loss:0.0068733386917390425\n",
      "train loss:0.0016141192948050012\n",
      "train loss:0.0006362951265317615\n",
      "train loss:0.007712744660522055\n",
      "train loss:0.001867377303321223\n",
      "train loss:0.0004429117884376113\n",
      "train loss:0.00435886318192374\n",
      "train loss:0.0030044772247497303\n",
      "train loss:0.006307717424916775\n",
      "train loss:0.004456411892440063\n",
      "train loss:0.023165881709807074\n",
      "train loss:0.0007367082452422223\n",
      "train loss:0.002102920381154266\n",
      "train loss:0.0014770428993899263\n",
      "train loss:0.010240779015975027\n",
      "train loss:0.003326690390094032\n",
      "train loss:0.003742437482141272\n",
      "train loss:0.0014847249927369469\n",
      "train loss:0.012136615899442031\n",
      "train loss:0.002750905436127214\n",
      "train loss:0.005706938789575154\n",
      "train loss:0.0011406827598445315\n",
      "train loss:0.00042127841963527935\n",
      "train loss:0.04403667362410481\n",
      "train loss:0.002721823344482108\n",
      "train loss:0.003822749776144828\n",
      "train loss:0.0065787552037207386\n",
      "train loss:0.00020454417118626135\n",
      "train loss:0.0008623142847018688\n",
      "train loss:0.003965401475435989\n",
      "train loss:0.00410447137549249\n",
      "train loss:0.0050530891030999385\n",
      "train loss:0.007830812704945962\n",
      "train loss:0.005727856893687535\n",
      "train loss:0.0066338585270179174\n",
      "train loss:0.001535274930064807\n",
      "train loss:0.0006196723937321201\n",
      "train loss:0.001157803929630281\n",
      "train loss:0.002685110331181231\n",
      "train loss:0.0028491449577643393\n",
      "train loss:0.001927541595238281\n",
      "train loss:0.0027435485611775924\n",
      "train loss:0.026764848486118084\n",
      "train loss:0.0013125631403396363\n",
      "train loss:0.0015448596151087727\n",
      "train loss:0.00023485900778653254\n",
      "train loss:0.0012526224923707324\n",
      "train loss:0.0028664153336357932\n",
      "train loss:0.001726922452125423\n",
      "train loss:0.00023623387658519947\n",
      "train loss:0.0037523615637460542\n",
      "train loss:0.0015426088709530378\n",
      "train loss:0.0025688301415290214\n",
      "train loss:0.001727571748531163\n",
      "train loss:0.0021124211658526734\n",
      "train loss:0.0014010628068507466\n",
      "train loss:0.006110517915195058\n",
      "train loss:0.0005752589316245803\n",
      "train loss:0.011665980225238395\n",
      "train loss:0.0042660857101150355\n",
      "train loss:0.009553447385416918\n",
      "train loss:0.00206544501094553\n",
      "train loss:0.0006639615151772482\n",
      "train loss:0.0007577114848011427\n",
      "train loss:5.91503007993869e-05\n",
      "train loss:0.0005777676958166589\n",
      "train loss:4.397383519393099e-05\n",
      "train loss:0.0006563555439624901\n",
      "train loss:0.0007712866456942862\n",
      "train loss:0.006946354084840736\n",
      "train loss:0.0004947864837814388\n",
      "train loss:0.0011193079820368556\n",
      "train loss:0.01020705672861095\n",
      "train loss:3.564666452856942e-05\n",
      "train loss:0.004009196433842119\n",
      "train loss:0.0021227777220132866\n",
      "train loss:0.0019071281307454474\n",
      "train loss:0.0064575061944891175\n",
      "train loss:0.018725981281966862\n",
      "train loss:0.014547405368803546\n",
      "train loss:0.006469574885965343\n",
      "train loss:0.0009475971955916191\n",
      "train loss:0.004673891512635948\n",
      "train loss:0.0015340165668299105\n",
      "train loss:0.0009701752873402506\n",
      "train loss:0.028268493656481146\n",
      "train loss:0.0005967793655054447\n",
      "train loss:0.0023677600459534633\n",
      "train loss:0.0002627920016049026\n",
      "train loss:0.002056669514511128\n",
      "train loss:0.0009632658893962101\n",
      "train loss:0.0023137054579993907\n",
      "train loss:0.0008210283058781358\n",
      "train loss:0.002321731646696518\n",
      "train loss:0.012050267256092288\n",
      "train loss:0.0055939709821852465\n",
      "train loss:0.0761432495902149\n",
      "train loss:0.0010728210901665477\n",
      "train loss:0.0009063672850688665\n",
      "train loss:0.0002561064056614395\n",
      "train loss:0.0008861534570422714\n",
      "train loss:0.0017049869295906322\n",
      "train loss:0.00038102878159110195\n",
      "train loss:0.003240627778847827\n",
      "train loss:0.004876882778370434\n",
      "train loss:0.0007589376705385461\n",
      "train loss:0.00011796223067742153\n",
      "train loss:0.004951106701327857\n",
      "train loss:0.0004172642150739463\n",
      "train loss:0.0009294199964985263\n",
      "train loss:0.00277836909822267\n",
      "train loss:0.001369633963546672\n",
      "train loss:0.0002692093111154253\n",
      "train loss:0.0011972202318141923\n",
      "train loss:0.0026904200680163974\n",
      "train loss:0.0003625181007854873\n",
      "train loss:0.0021756105064675555\n",
      "train loss:0.002370436605899921\n",
      "train loss:0.008878321134710121\n",
      "train loss:0.000813114940168044\n",
      "train loss:0.0017825897410667817\n",
      "train loss:0.00187359854904293\n",
      "train loss:0.001137068712899525\n",
      "train loss:0.0009528951954536193\n",
      "train loss:0.0003519224212157518\n",
      "train loss:0.0008404039372775221\n",
      "train loss:0.04330506707517787\n",
      "train loss:0.00045033093040273124\n",
      "train loss:0.0009703791637397584\n",
      "train loss:0.0005513145418454589\n",
      "train loss:0.00237264226028278\n",
      "train loss:0.0011604243463734115\n",
      "train loss:0.0004026758453027882\n",
      "train loss:0.0014206150281641666\n",
      "train loss:0.001540463064461455\n",
      "train loss:0.018839992675460812\n",
      "train loss:0.0003590646426657755\n",
      "train loss:0.0005954003705001331\n",
      "train loss:0.0014737447280677005\n",
      "train loss:0.00031321566082238037\n",
      "train loss:0.0003904496392411936\n",
      "train loss:0.005320086290386327\n",
      "train loss:0.0044079680588366334\n",
      "train loss:0.045859294119507135\n",
      "train loss:0.0032993791999996708\n",
      "train loss:0.0004694246332773512\n",
      "train loss:0.004852577967501731\n",
      "train loss:0.008088297804368509\n",
      "train loss:0.00318386929100973\n",
      "train loss:0.0019446376806706\n",
      "train loss:0.0003470383539873558\n",
      "train loss:0.007929680319263076\n",
      "train loss:0.006633660120447981\n",
      "train loss:0.003898628275897457\n",
      "train loss:0.008548254612701943\n",
      "train loss:0.0006064224381990828\n",
      "train loss:0.0003374405247196668\n",
      "train loss:0.012417665942541447\n",
      "train loss:0.007404966553266801\n",
      "train loss:0.007050969325477771\n",
      "train loss:0.009886704737985365\n",
      "train loss:0.00010499647618185567\n",
      "train loss:0.0021575171757372016\n",
      "train loss:0.0009112921249000611\n",
      "train loss:0.0010606145710027205\n",
      "train loss:0.002632128333168487\n",
      "train loss:0.002090434712681892\n",
      "train loss:0.0009901416811545767\n",
      "train loss:0.0011002551471897403\n",
      "train loss:0.006692194211020175\n",
      "train loss:0.0002891138442779871\n",
      "train loss:0.019413791267336312\n",
      "train loss:0.004142058208577412\n",
      "train loss:0.0006004480905692075\n",
      "train loss:0.0013080976198525146\n",
      "train loss:0.0017380297641440689\n",
      "train loss:0.001384228162693624\n",
      "train loss:0.004099115231731026\n",
      "train loss:0.00043829082375205727\n",
      "train loss:0.009962947131655698\n",
      "train loss:0.0025262745327453567\n",
      "train loss:0.0006784241997113656\n",
      "train loss:0.011559806431861643\n",
      "train loss:0.00010086663724903739\n",
      "train loss:0.0038728614520794676\n",
      "train loss:0.00823256798285902\n",
      "train loss:0.015114470026390712\n",
      "train loss:0.0027121421180904075\n",
      "train loss:0.0025020693763005597\n",
      "train loss:0.0037627122867547164\n",
      "train loss:0.0027285606294294067\n",
      "train loss:0.00020514187009119088\n",
      "train loss:0.0007582651953771564\n",
      "train loss:0.00037507670777589834\n",
      "train loss:0.00426547063337328\n",
      "train loss:0.0004974611983202213\n",
      "train loss:0.0010371819385717623\n",
      "train loss:0.0002857710601548807\n",
      "train loss:0.0016402771756482732\n",
      "train loss:0.006124191358458537\n",
      "train loss:0.001092103356695863\n",
      "train loss:0.002694838946970331\n",
      "train loss:0.0007101356489110297\n",
      "train loss:0.006155087439165566\n",
      "train loss:0.0022381893114408126\n",
      "train loss:0.00016661920582927876\n",
      "train loss:0.007591004887381042\n",
      "train loss:0.000200144469493819\n",
      "train loss:0.0002876875364464322\n",
      "train loss:0.009069327975697827\n",
      "train loss:0.014403271595473322\n",
      "train loss:0.0001464314747434019\n",
      "train loss:0.0006437730026365404\n",
      "train loss:0.0010931483240146842\n",
      "train loss:0.0005421852339619242\n",
      "train loss:0.004285371284982941\n",
      "train loss:0.00013191444953386194\n",
      "train loss:0.004469273126277807\n",
      "train loss:0.0019933732105104785\n",
      "train loss:0.0018102876882927308\n",
      "train loss:0.003016629344467966\n",
      "train loss:0.0015225345794382525\n",
      "train loss:0.0003709002230012971\n",
      "train loss:0.00010135236294222033\n",
      "train loss:0.008468721871172846\n",
      "train loss:0.0005621098793006172\n",
      "train loss:0.0002926303882595847\n",
      "train loss:0.00024217790776227062\n",
      "train loss:0.0013950984836771495\n",
      "train loss:0.005893734703384295\n",
      "train loss:0.0003681792718338178\n",
      "train loss:0.0007389665538978001\n",
      "train loss:0.005221195748778165\n",
      "train loss:0.001425840777810149\n",
      "train loss:0.001211894005731695\n",
      "train loss:0.0007755472228504325\n",
      "train loss:0.006287485926596108\n",
      "train loss:0.0028933886569388377\n",
      "train loss:0.0025295152183589355\n",
      "train loss:0.002817291205519843\n",
      "train loss:0.0045929931327519\n",
      "train loss:0.001795134757285799\n",
      "train loss:0.005511216863714096\n",
      "train loss:0.002194894784148489\n",
      "train loss:0.0027328080767212905\n",
      "train loss:0.002207647760692699\n",
      "train loss:0.0015865018034454574\n",
      "train loss:0.0004044735073195935\n",
      "train loss:0.001943421728134031\n",
      "train loss:0.005634864816709765\n",
      "train loss:0.0005701735781663603\n",
      "train loss:0.007902124170784787\n",
      "train loss:0.002111033178280869\n",
      "train loss:0.000955174797270741\n",
      "train loss:0.003606370643804844\n",
      "train loss:7.052959208087923e-05\n",
      "train loss:0.00331763980736969\n",
      "train loss:0.002546566413850908\n",
      "train loss:0.0005852231926234986\n",
      "train loss:0.003909129462157545\n",
      "train loss:0.004824866819663586\n",
      "train loss:0.001228778413929946\n",
      "train loss:0.0036450951493767606\n",
      "train loss:0.0022341002069562322\n",
      "train loss:0.001533060343453542\n",
      "train loss:0.0005204648114455468\n",
      "train loss:0.0010989421696124078\n",
      "train loss:0.0011330608662420327\n",
      "train loss:0.00044920704959239407\n",
      "train loss:0.003990971345982452\n",
      "train loss:0.0014170057358068023\n",
      "train loss:0.0004836804489012046\n",
      "train loss:0.0016582970242876376\n",
      "train loss:0.00048791737219243804\n",
      "train loss:0.0009142685466686872\n",
      "train loss:4.521768063944688e-05\n",
      "train loss:0.01156028928694734\n",
      "train loss:0.0037627637381197664\n",
      "train loss:0.0023050380478852033\n",
      "train loss:0.0032892207524601426\n",
      "train loss:0.0010449113556018613\n",
      "train loss:0.00533807283839975\n",
      "train loss:0.00019012761440389758\n",
      "train loss:0.0005145571532081309\n",
      "train loss:0.0013839614313921182\n",
      "train loss:0.0015918535640846248\n",
      "train loss:0.0003535270821468487\n",
      "train loss:0.0017015743291502025\n",
      "train loss:0.0006494633405253962\n",
      "train loss:0.00128988890735199\n",
      "train loss:0.00015340568851646456\n",
      "train loss:0.000361121351823058\n",
      "train loss:0.0005077935575674919\n",
      "train loss:0.00036277219466986365\n",
      "train loss:0.0002691066226572692\n",
      "train loss:0.0024493404256861846\n",
      "train loss:0.0020837051660725628\n",
      "train loss:0.0007192604641340865\n",
      "train loss:0.001836411641103283\n",
      "train loss:0.018775236480808265\n",
      "train loss:0.0017309142482796467\n",
      "train loss:0.000485543202925469\n",
      "train loss:0.001309776334182535\n",
      "train loss:0.0006552337942727991\n",
      "train loss:4.943819404106508e-05\n",
      "train loss:0.00044220805997847084\n",
      "train loss:0.0005665150471561091\n",
      "train loss:0.0008894745688966785\n",
      "train loss:0.0004835845038056164\n",
      "train loss:0.00845431568612461\n",
      "train loss:0.0007331951272053618\n",
      "train loss:0.00040697459050692124\n",
      "train loss:3.477281667451262e-05\n",
      "train loss:0.0005059178579472423\n",
      "train loss:0.0008583847541852025\n",
      "train loss:0.006437120482236889\n",
      "train loss:0.001585474961534546\n",
      "train loss:0.00605698085965844\n",
      "train loss:0.0013736045803729503\n",
      "train loss:0.00045285104705731957\n",
      "train loss:0.0028285070752670075\n",
      "train loss:0.0002845410638704501\n",
      "train loss:0.0001917871754677095\n",
      "train loss:0.0025903875376441458\n",
      "train loss:0.0015571150573948217\n",
      "train loss:0.0013426768430490304\n",
      "train loss:0.0008867312464625878\n",
      "train loss:0.00022249930091985183\n",
      "train loss:0.0005715979448474802\n",
      "train loss:0.0024134469349774796\n",
      "train loss:0.0007844653727818035\n",
      "train loss:0.0014304088007684051\n",
      "train loss:0.0009367693108217083\n",
      "train loss:0.0016849767577146336\n",
      "train loss:0.002092764395098726\n",
      "train loss:0.018952289222959787\n",
      "train loss:6.208924965249789e-05\n",
      "train loss:0.001321727585761754\n",
      "train loss:0.0001856707738976314\n",
      "train loss:0.0020583752609720763\n",
      "train loss:0.00414687533366339\n",
      "train loss:0.001540225511271082\n",
      "train loss:0.0016912435079440582\n",
      "train loss:0.003990164501154677\n",
      "train loss:0.0022900790890260513\n",
      "train loss:6.839477006694151e-05\n",
      "train loss:0.002010685846706644\n",
      "train loss:0.0017462559177915758\n",
      "train loss:0.001779771250302048\n",
      "train loss:0.000694071957416057\n",
      "train loss:0.002395088138004693\n",
      "train loss:0.001656050224881313\n",
      "train loss:0.0011604607171937032\n",
      "train loss:0.00019283321492218422\n",
      "train loss:0.0007288838383907316\n",
      "train loss:0.0053270615971410555\n",
      "train loss:0.0017363352803680886\n",
      "train loss:0.0009708504045680316\n",
      "train loss:0.000959799962589839\n",
      "train loss:0.00035219265967629886\n",
      "train loss:0.0011014690085241075\n",
      "train loss:0.004463946504897792\n",
      "train loss:0.00167009192962175\n",
      "train loss:0.004746599885149042\n",
      "train loss:0.0014238467106751406\n",
      "train loss:0.00572888514776288\n",
      "train loss:0.0004474411550916145\n",
      "train loss:0.004126554935446506\n",
      "train loss:0.001997535928556704\n",
      "train loss:0.0002601690600092363\n",
      "train loss:0.010698050126962334\n",
      "train loss:0.0005471227766557038\n",
      "train loss:0.004411002009493617\n",
      "train loss:0.0011093709632637768\n",
      "train loss:0.0029522160887260574\n",
      "train loss:0.003306289071985882\n",
      "train loss:0.003667337536300265\n",
      "train loss:0.0013653329509085007\n",
      "train loss:0.01829658889874028\n",
      "train loss:0.0005686353540143978\n",
      "train loss:0.0013444901753253563\n",
      "train loss:0.00046319328722106706\n",
      "train loss:0.0003213787075233119\n",
      "train loss:0.002778148266181045\n",
      "train loss:0.004257212620928671\n",
      "train loss:0.003167915284448635\n",
      "train loss:0.00015750306380040216\n",
      "train loss:0.0020148981513974664\n",
      "train loss:0.003170624844415154\n",
      "train loss:0.0014086802978788867\n",
      "train loss:0.0024610534324675105\n",
      "train loss:0.0007150494420545299\n",
      "train loss:0.00016118442220531558\n",
      "train loss:0.00016836848281867218\n",
      "train loss:0.0007976066603751334\n",
      "train loss:0.001132183998619566\n",
      "train loss:0.0019626220748986483\n",
      "train loss:0.0035402819135152835\n",
      "train loss:0.000579511688297172\n",
      "train loss:0.0012570662183815976\n",
      "train loss:0.0037914583801721634\n",
      "train loss:0.0013894504386830133\n",
      "train loss:0.0007406149673160905\n",
      "train loss:0.0010644941990767588\n",
      "train loss:0.00465654940934606\n",
      "train loss:0.0003673962704791778\n",
      "train loss:0.0037855709838096273\n",
      "train loss:0.00028703966299677104\n",
      "train loss:0.00012830407207380462\n",
      "train loss:0.002240753166285736\n",
      "train loss:9.84790645888685e-05\n",
      "train loss:0.0013223040400349168\n",
      "train loss:0.002302120201991412\n",
      "train loss:0.0025091363999550052\n",
      "train loss:0.0031627641880430145\n",
      "train loss:0.0023012147490421558\n",
      "train loss:0.0025146273829559167\n",
      "train loss:0.0012474092450423541\n",
      "train loss:0.00048429427670180147\n",
      "train loss:0.00042048073065379727\n",
      "train loss:0.0025967013777251275\n",
      "train loss:0.0004007307851924583\n",
      "train loss:0.0009438557812340862\n",
      "train loss:0.004117330240227945\n",
      "train loss:0.003546398062520134\n",
      "train loss:0.0031207178710721604\n",
      "train loss:0.00033887527842400123\n",
      "train loss:0.0013162545555017843\n",
      "train loss:0.0018386047876178984\n",
      "train loss:0.004945320216352297\n",
      "train loss:0.0029649659290485776\n",
      "train loss:0.0005467249021777535\n",
      "train loss:0.0030823528111205843\n",
      "train loss:0.0006041727513865611\n",
      "train loss:0.001445252872507033\n",
      "train loss:0.00037217514813512876\n",
      "train loss:0.0010655674960528055\n",
      "train loss:0.0021688551488578175\n",
      "train loss:0.00413109291803038\n",
      "train loss:0.0019106881373991014\n",
      "train loss:0.002142687981612903\n",
      "train loss:0.00020035830954970063\n",
      "train loss:0.00028697529121554606\n",
      "train loss:0.002473123036949341\n",
      "train loss:0.007422017154063106\n",
      "train loss:0.0015157669970624174\n",
      "train loss:0.0009662877418251289\n",
      "train loss:0.00037443459569858214\n",
      "train loss:0.0017704887258833547\n",
      "train loss:0.0018048125243391039\n",
      "train loss:0.0006504918535406599\n",
      "train loss:0.007426808405700041\n",
      "train loss:0.00045870021384458606\n",
      "train loss:0.0020614637876285925\n",
      "train loss:0.003605560591165553\n",
      "train loss:0.000818670388666179\n",
      "train loss:0.0013334499116478985\n",
      "train loss:0.002172965055944275\n",
      "train loss:0.00170525296926445\n",
      "train loss:0.0005861710648367413\n",
      "train loss:0.00173920519024097\n",
      "train loss:0.0005675467484465312\n",
      "train loss:0.0020684266948502723\n",
      "train loss:0.004809843468624433\n",
      "train loss:0.001991509104665638\n",
      "train loss:0.0008908848680947111\n",
      "train loss:0.0004955398910615407\n",
      "train loss:0.00010193081880309925\n",
      "train loss:0.0008241293131139204\n",
      "train loss:0.00217799304956879\n",
      "train loss:0.00020377017307805813\n",
      "train loss:0.0029849161924950696\n",
      "train loss:0.000631965362671877\n",
      "train loss:0.00041592246254835963\n",
      "train loss:0.0018998703714326458\n",
      "train loss:0.0007482495425034424\n",
      "train loss:0.0017833604925519238\n",
      "train loss:0.0015194808618019446\n",
      "train loss:0.00044284375851964895\n",
      "train loss:0.001852794096055159\n",
      "train loss:0.0009596481172858695\n",
      "train loss:7.525215740769928e-05\n",
      "train loss:0.0038243524037962105\n",
      "train loss:0.000641656893512263\n",
      "train loss:0.0030355160238696695\n",
      "train loss:0.0024057059895183845\n",
      "train loss:0.00021727319323748824\n",
      "train loss:0.0020294514118638003\n",
      "train loss:0.005739506797409885\n",
      "train loss:0.006043309918924615\n",
      "train loss:0.0009297818730182001\n",
      "train loss:9.991747997579214e-05\n",
      "train loss:0.0016583997739142077\n",
      "train loss:0.0004896553549496337\n",
      "train loss:0.0006147282643556927\n",
      "train loss:0.002426502058848479\n",
      "train loss:0.00559002535421056\n",
      "train loss:0.0012954839943622634\n",
      "train loss:0.003888471025249194\n",
      "train loss:0.0018272499421432794\n",
      "train loss:0.002942551102173357\n",
      "train loss:0.017449950311291915\n",
      "train loss:0.0023281634082965106\n",
      "train loss:7.129617684727329e-05\n",
      "train loss:6.804971963737433e-05\n",
      "train loss:0.0009699981981487867\n",
      "train loss:0.002279633218207403\n",
      "train loss:0.0005834378085039628\n",
      "train loss:0.0013981277230346249\n",
      "train loss:0.0013952038215842635\n",
      "train loss:0.0036029792703356905\n",
      "train loss:0.0032089768985621397\n",
      "train loss:0.0005838980584835691\n",
      "train loss:0.009097636512232284\n",
      "train loss:0.0015964956698417952\n",
      "train loss:0.0052585655354858915\n",
      "train loss:0.003229852491326165\n",
      "train loss:0.000983762317721871\n",
      "train loss:7.81701488990382e-06\n",
      "train loss:0.009307197292433601\n",
      "train loss:0.00409301289031921\n",
      "train loss:0.0012547315943180729\n",
      "train loss:0.0010518836281882334\n",
      "=== epoch:16, train acc:0.995, test acc:0.989 ===\n",
      "train loss:0.004554338933768573\n",
      "train loss:0.00024570010933301195\n",
      "train loss:0.001818032190671713\n",
      "train loss:0.008315805745088249\n",
      "train loss:0.00012798151166343733\n",
      "train loss:0.00044982036524254067\n",
      "train loss:0.007913169520063988\n",
      "train loss:0.0003135370467161873\n",
      "train loss:0.0040061958571080344\n",
      "train loss:0.00011844918574793502\n",
      "train loss:0.0005216905357862229\n",
      "train loss:0.00047413853137565423\n",
      "train loss:0.0010105340940071048\n",
      "train loss:0.006849386633567358\n",
      "train loss:0.00025393648004871217\n",
      "train loss:0.00036121564339754614\n",
      "train loss:0.0014065690478071765\n",
      "train loss:0.0007246488871204837\n",
      "train loss:0.0002838105188688591\n",
      "train loss:0.0006282233739558306\n",
      "train loss:0.001972391276618982\n",
      "train loss:0.0009717933984833123\n",
      "train loss:0.00023426321520061237\n",
      "train loss:0.00391924110109689\n",
      "train loss:0.0006428852918542375\n",
      "train loss:0.0025871958869326055\n",
      "train loss:9.09462634944901e-05\n",
      "train loss:0.001654297816440767\n",
      "train loss:0.0016434100342521969\n",
      "train loss:0.000392092845576243\n",
      "train loss:0.000374272774802515\n",
      "train loss:0.03182353332092393\n",
      "train loss:0.0001947879009285833\n",
      "train loss:0.0034235222192856613\n",
      "train loss:0.002280723642384079\n",
      "train loss:0.002433372438774385\n",
      "train loss:0.0012228401111558371\n",
      "train loss:0.0008664408242009433\n",
      "train loss:0.002712190347389236\n",
      "train loss:0.0053255848787467945\n",
      "train loss:0.0037025162392572\n",
      "train loss:0.0022082459463024285\n",
      "train loss:0.00019312300746719447\n",
      "train loss:0.0015547254236458813\n",
      "train loss:0.0006674039489881146\n",
      "train loss:0.0023544491539377495\n",
      "train loss:0.0003059486221883172\n",
      "train loss:0.000771607831140514\n",
      "train loss:0.005091083749012776\n",
      "train loss:0.0011937606278630403\n",
      "train loss:0.006855909711333068\n",
      "train loss:5.5484012715571576e-05\n",
      "train loss:0.001650676827724262\n",
      "train loss:0.0010804607296107593\n",
      "train loss:0.0005054458403923099\n",
      "train loss:0.0025203390915602302\n",
      "train loss:0.007549183622211333\n",
      "train loss:2.6257186071099497e-05\n",
      "train loss:0.0036130800555565137\n",
      "train loss:0.004777026726302101\n",
      "train loss:0.012415344409092064\n",
      "train loss:0.0034270953415778765\n",
      "train loss:0.00029019043823754956\n",
      "train loss:4.0400376029759196e-05\n",
      "train loss:0.0020457844891118493\n",
      "train loss:0.0028002873916730935\n",
      "train loss:0.0030165340032748157\n",
      "train loss:0.0031371333778405404\n",
      "train loss:0.0003840199372091395\n",
      "train loss:0.00011591763400116305\n",
      "train loss:0.0013075017447949414\n",
      "train loss:0.0016357657772599669\n",
      "train loss:0.002712432742269848\n",
      "train loss:0.0007354955215304273\n",
      "train loss:0.0012994451881276215\n",
      "train loss:0.0009657611634148766\n",
      "train loss:0.002352063981900154\n",
      "train loss:0.0012874677549851948\n",
      "train loss:0.0001990132775155858\n",
      "train loss:0.001238076787519314\n",
      "train loss:0.0002811309147569101\n",
      "train loss:0.00621406733116313\n",
      "train loss:0.0022226675491083306\n",
      "train loss:0.0007146450031939723\n",
      "train loss:0.0009381464039269479\n",
      "train loss:0.008371216781191827\n",
      "train loss:0.000666771623393725\n",
      "train loss:0.0012810240051187183\n",
      "train loss:0.0016746350640893949\n",
      "train loss:0.0007752548625255282\n",
      "train loss:0.000381066053691623\n",
      "train loss:0.003357277478561404\n",
      "train loss:0.008132221516485724\n",
      "train loss:0.0015428901256192109\n",
      "train loss:0.001572666343083355\n",
      "train loss:0.00284552860347254\n",
      "train loss:0.0016020629013506677\n",
      "train loss:0.0005273096807281704\n",
      "train loss:0.007592174752042478\n",
      "train loss:0.033194795108808385\n",
      "train loss:0.04753010451383356\n",
      "train loss:0.003603434436113382\n",
      "train loss:0.0015718587185440211\n",
      "train loss:0.002921491636681152\n",
      "train loss:0.003100120213420387\n",
      "train loss:0.003165635917178562\n",
      "train loss:0.004894546888266306\n",
      "train loss:0.00029603122793040614\n",
      "train loss:0.001567971444157281\n",
      "train loss:0.0018645727345752714\n",
      "train loss:0.0012889489146022302\n",
      "train loss:0.0010584956372706412\n",
      "train loss:0.007911368600558563\n",
      "train loss:0.0011702299744195375\n",
      "train loss:0.007889210061316813\n",
      "train loss:0.0013567346607096032\n",
      "train loss:0.017072046100951775\n",
      "train loss:0.0010051665644995934\n",
      "train loss:0.002935562148230667\n",
      "train loss:0.01589402734802167\n",
      "train loss:0.0009588670613880494\n",
      "train loss:0.006435275452612522\n",
      "train loss:0.00014575955263502094\n",
      "train loss:0.0004759408431683506\n",
      "train loss:0.0007938020032189754\n",
      "train loss:0.0017570368699321706\n",
      "train loss:0.004084883088986298\n",
      "train loss:0.002569016995045063\n",
      "train loss:0.0023928907932486993\n",
      "train loss:0.002243019654110716\n",
      "train loss:0.024169102544911857\n",
      "train loss:0.0007911770913624112\n",
      "train loss:0.007114499015191606\n",
      "train loss:0.0016686374679024693\n",
      "train loss:0.0012825231833477708\n",
      "train loss:0.0016048327435033128\n",
      "train loss:0.00188675235842898\n",
      "train loss:0.0038749411389787975\n",
      "train loss:0.00026509387883281234\n",
      "train loss:0.0022945764526732236\n",
      "train loss:0.0027195777317349655\n",
      "train loss:0.0021669799682596537\n",
      "train loss:0.006273521979972254\n",
      "train loss:0.0010130892414614693\n",
      "train loss:0.0012706212345469697\n",
      "train loss:0.0028090052166671524\n",
      "train loss:0.0002185063772012958\n",
      "train loss:0.0002400077277700186\n",
      "train loss:0.0014820908105830696\n",
      "train loss:8.384099221685429e-05\n",
      "train loss:0.0017829781350652144\n",
      "train loss:0.0010430915317578117\n",
      "train loss:0.001781641107109429\n",
      "train loss:0.00015162399885272333\n",
      "train loss:0.06595681485786622\n",
      "train loss:0.001441999800783121\n",
      "train loss:0.004214145056663459\n",
      "train loss:0.0010467302460866461\n",
      "train loss:0.002379738935429612\n",
      "train loss:0.0007152679545790252\n",
      "train loss:0.0005602257518695824\n",
      "train loss:0.001260130525672382\n",
      "train loss:0.000435290734316888\n",
      "train loss:0.0036943872479874317\n",
      "train loss:0.00029657883474789774\n",
      "train loss:6.733120201027104e-05\n",
      "train loss:0.00036877505792204976\n",
      "train loss:0.0012515074537909631\n",
      "train loss:0.001722878979513264\n",
      "train loss:0.0008055682971101387\n",
      "train loss:0.0023162253989915957\n",
      "train loss:0.0036023532953592297\n",
      "train loss:0.0005676450539124299\n",
      "train loss:0.0008162400239623885\n",
      "train loss:0.0018123083110083225\n",
      "train loss:0.001824101088720998\n",
      "train loss:0.0038933733288132872\n",
      "train loss:0.0022649691568244626\n",
      "train loss:0.0027501216004285367\n",
      "train loss:0.0008645069504189985\n",
      "train loss:0.0005164496771534897\n",
      "train loss:0.0022954968598187077\n",
      "train loss:0.0013240091416531754\n",
      "train loss:0.006944520839555779\n",
      "train loss:0.0016834963096351765\n",
      "train loss:9.889939377397093e-05\n",
      "train loss:0.00017745461234356503\n",
      "train loss:4.413912726686317e-05\n",
      "train loss:0.0014452002460385784\n",
      "train loss:0.003976808527317544\n",
      "train loss:0.0008952787518377883\n",
      "train loss:0.003908206736357592\n",
      "train loss:0.0016395186182319712\n",
      "train loss:0.0011861267531627989\n",
      "train loss:0.0014782543764738265\n",
      "train loss:0.00038317543132031207\n",
      "train loss:0.0007247270493606797\n",
      "train loss:0.0013013064413662748\n",
      "train loss:0.0008908702183419491\n",
      "train loss:0.0009341098052878821\n",
      "train loss:0.0007007279230170936\n",
      "train loss:0.0008550377238760086\n",
      "train loss:0.0004426651443415398\n",
      "train loss:0.0002161303169522572\n",
      "train loss:0.0005549132589085409\n",
      "train loss:0.0011686763152883254\n",
      "train loss:0.00010156308387376885\n",
      "train loss:0.0006263308758578005\n",
      "train loss:0.00012291447436526217\n",
      "train loss:0.004981759944939073\n",
      "train loss:0.002358504378218644\n",
      "train loss:0.007227953532124672\n",
      "train loss:0.00034606803315817314\n",
      "train loss:0.00014528102372023683\n",
      "train loss:0.003068610857051139\n",
      "train loss:0.0016156043092836767\n",
      "train loss:0.0012737049942575128\n",
      "train loss:0.0023307657361048752\n",
      "train loss:0.005443468918813638\n",
      "train loss:0.0025375270229911233\n",
      "train loss:0.002702247021705686\n",
      "train loss:0.001034872761692638\n",
      "train loss:0.0026866562203277282\n",
      "train loss:0.0024032156004864195\n",
      "train loss:0.00017349951681743078\n",
      "train loss:0.00155777903505805\n",
      "train loss:0.0022332155520707452\n",
      "train loss:0.0005542922979353787\n",
      "train loss:0.0026294122214231635\n",
      "train loss:0.0034043793543991822\n",
      "train loss:0.0009392554179500816\n",
      "train loss:0.0038134121393662316\n",
      "train loss:0.000719699817307081\n",
      "train loss:0.022391305656317587\n",
      "train loss:0.0008818110671284027\n",
      "train loss:9.637007850461402e-05\n",
      "train loss:0.00026883872585690825\n",
      "train loss:0.0027261652348261733\n",
      "train loss:0.002197667018951627\n",
      "train loss:0.002409654554580939\n",
      "train loss:0.0033380205901071013\n",
      "train loss:0.0019401909168362474\n",
      "train loss:0.00046890329628640926\n",
      "train loss:0.0038233818046531794\n",
      "train loss:0.00010966620623438865\n",
      "train loss:0.0009774841493430913\n",
      "train loss:0.0002711298449730883\n",
      "train loss:0.00021002256707557443\n",
      "train loss:0.0010998494987021368\n",
      "train loss:0.00018385046667458753\n",
      "train loss:0.0006642850948276905\n",
      "train loss:0.002830817448096906\n",
      "train loss:0.00041906812396585373\n",
      "train loss:0.020632836003776314\n",
      "train loss:0.001878220024868509\n",
      "train loss:0.0009162129678779491\n",
      "train loss:0.001733942291104408\n",
      "train loss:0.0023066509100654544\n",
      "train loss:0.000224314217971026\n",
      "train loss:0.005133392469622747\n",
      "train loss:0.0002176810687684801\n",
      "train loss:0.001346118990754207\n",
      "train loss:0.0008580058034619997\n",
      "train loss:0.004710789850153541\n",
      "train loss:0.0005275445840261034\n",
      "train loss:0.0030362309035314853\n",
      "train loss:0.0002491843690507998\n",
      "train loss:0.0004651531035989119\n",
      "train loss:0.00011038949340561731\n",
      "train loss:0.003560072185925646\n",
      "train loss:0.0042692543444644284\n",
      "train loss:0.0004420374539154759\n",
      "train loss:0.0001807048319101145\n",
      "train loss:0.00022507302340087136\n",
      "train loss:0.008134335810467746\n",
      "train loss:0.00042048414686983877\n",
      "train loss:0.0004917537612970475\n",
      "train loss:0.0010856948300064335\n",
      "train loss:0.0008244513543033527\n",
      "train loss:0.0005370489451715188\n",
      "train loss:0.0022124213295128124\n",
      "train loss:0.0012611620937301\n",
      "train loss:0.0008103369585978061\n",
      "train loss:0.0018132521224433799\n",
      "train loss:0.00038199677700571824\n",
      "train loss:0.0005040811935079628\n",
      "train loss:0.002117925381052285\n",
      "train loss:0.00044175271328473673\n",
      "train loss:0.0017647727225886286\n",
      "train loss:0.0003644467929650567\n",
      "train loss:0.0010216311250787335\n",
      "train loss:0.002258857376896611\n",
      "train loss:0.0009766814454099258\n",
      "train loss:0.000943422586103201\n",
      "train loss:0.0010236950497712798\n",
      "train loss:0.00038955520534163034\n",
      "train loss:0.001175852611847447\n",
      "train loss:0.029640221525546524\n",
      "train loss:0.002030301591524271\n",
      "train loss:0.0012864792584454665\n",
      "train loss:0.0031686973719832496\n",
      "train loss:0.001369015399886192\n",
      "train loss:0.0009329725585554953\n",
      "train loss:0.00648440232926037\n",
      "train loss:0.0002582064754282684\n",
      "train loss:0.0008321366511945721\n",
      "train loss:0.006572754619951165\n",
      "train loss:0.015800584502999527\n",
      "train loss:0.003339358640178062\n",
      "train loss:0.0003758382566428853\n",
      "train loss:0.001497925121262359\n",
      "train loss:0.0015734285957514312\n",
      "train loss:0.004655209797191369\n",
      "train loss:0.00014858715423226177\n",
      "train loss:0.000543110791612035\n",
      "train loss:0.001298681272169854\n",
      "train loss:0.00025254326329292185\n",
      "train loss:4.618874253576256e-05\n",
      "train loss:0.007156492286220695\n",
      "train loss:0.003835939130169965\n",
      "train loss:0.004669693641356208\n",
      "train loss:0.0001683335776915944\n",
      "train loss:0.006004415169403678\n",
      "train loss:0.0004255276704209369\n",
      "train loss:0.0020448090517093233\n",
      "train loss:0.0008710106717122397\n",
      "train loss:0.0015623195976518433\n",
      "train loss:0.0014588648078042747\n",
      "train loss:0.00041039495270703616\n",
      "train loss:0.0017303893142543614\n",
      "train loss:0.0019115472568042163\n",
      "train loss:0.0013876213158564915\n",
      "train loss:0.0005274446908732426\n",
      "train loss:0.0005966836202082581\n",
      "train loss:0.002212630454817296\n",
      "train loss:0.0006842224972426035\n",
      "train loss:0.0012969770317600325\n",
      "train loss:0.0034506500552077117\n",
      "train loss:0.005401665745681608\n",
      "train loss:0.0012890496953682617\n",
      "train loss:0.00037438792902669255\n",
      "train loss:0.0010363724789375012\n",
      "train loss:0.0011088667892329243\n",
      "train loss:0.0034411672754764643\n",
      "train loss:0.0029227118315960088\n",
      "train loss:0.00017225311629756823\n",
      "train loss:0.006133783984890172\n",
      "train loss:0.0009928206191161474\n",
      "train loss:0.001005932855223231\n",
      "train loss:0.0007834752645295677\n",
      "train loss:0.0008615709146315935\n",
      "train loss:0.0032557219986474543\n",
      "train loss:0.00016503359940762141\n",
      "train loss:0.005621105771626771\n",
      "train loss:0.0011180678961618539\n",
      "train loss:0.0011272615793994308\n",
      "train loss:0.007580245618892184\n",
      "train loss:0.000745216029876799\n",
      "train loss:0.0006857414046732083\n",
      "train loss:0.0022392035312257413\n",
      "train loss:0.0007429949981533723\n",
      "train loss:0.004298941518882914\n",
      "train loss:0.00046381053695520626\n",
      "train loss:0.0002061776351838707\n",
      "train loss:0.003007219060628305\n",
      "train loss:0.0020710934449646107\n",
      "train loss:0.00019116395643505762\n",
      "train loss:0.004968158380960564\n",
      "train loss:0.0025672931555722842\n",
      "train loss:0.002334090017643663\n",
      "train loss:9.786837668896974e-05\n",
      "train loss:0.001007708262810325\n",
      "train loss:0.0008685399873974102\n",
      "train loss:0.0008452579558309887\n",
      "train loss:0.007289636735531128\n",
      "train loss:0.0026616342994234604\n",
      "train loss:0.0005638768588261335\n",
      "train loss:0.0013689918465263184\n",
      "train loss:0.007265409749083378\n",
      "train loss:0.0011927702900160736\n",
      "train loss:0.04565946085781149\n",
      "train loss:0.0011184224263537609\n",
      "train loss:0.00013080450602326736\n",
      "train loss:0.0016802211754290825\n",
      "train loss:0.002215142388910421\n",
      "train loss:0.0022827519935737315\n",
      "train loss:0.001028160346495383\n",
      "train loss:0.0002861480145910983\n",
      "train loss:0.0006251454970713724\n",
      "train loss:0.0012059379441813115\n",
      "train loss:0.002786123009973932\n",
      "train loss:0.002225586103660818\n",
      "train loss:0.0028718587335985566\n",
      "train loss:0.002070249001557065\n",
      "train loss:0.0002940619844877105\n",
      "train loss:0.0007292366202861341\n",
      "train loss:0.003696406026104923\n",
      "train loss:0.002118687097341414\n",
      "train loss:0.0020351985651704055\n",
      "train loss:0.0003444902136037522\n",
      "train loss:0.00420732110338337\n",
      "train loss:0.0017300848772643684\n",
      "train loss:0.017450011006843576\n",
      "train loss:0.0031421889118914024\n",
      "train loss:0.00299599127080102\n",
      "train loss:0.0016981990620926876\n",
      "train loss:0.003083382448154805\n",
      "train loss:0.0038480214800796146\n",
      "train loss:0.001917329820372662\n",
      "train loss:0.007240982783110266\n",
      "train loss:0.00511544926082965\n",
      "train loss:0.001446807824535325\n",
      "train loss:0.00014352066492972395\n",
      "train loss:0.00140086038667546\n",
      "train loss:0.0008343276516879133\n",
      "train loss:0.0031423124727289363\n",
      "train loss:0.002310097227332026\n",
      "train loss:0.001319716398525983\n",
      "train loss:0.0030757048872112904\n",
      "train loss:0.00038465714263719676\n",
      "train loss:0.0002096637911555578\n",
      "train loss:0.00035671871684410275\n",
      "train loss:0.0035825904349837037\n",
      "train loss:0.0017573891019909435\n",
      "train loss:0.006372527588152588\n",
      "train loss:0.0001209353797169261\n",
      "train loss:0.00016193549057667942\n",
      "train loss:0.025164427253108083\n",
      "train loss:0.0008038228641526382\n",
      "train loss:0.0005830375758219446\n",
      "train loss:0.0006640399147510548\n",
      "train loss:0.001403989941512674\n",
      "train loss:0.0044572889506430055\n",
      "train loss:0.000826527813762349\n",
      "train loss:0.0022310297593614347\n",
      "train loss:0.0012851242339725019\n",
      "train loss:0.0004201526300300936\n",
      "train loss:0.0033467714777842927\n",
      "train loss:0.0008124353024569402\n",
      "train loss:0.001987603220550813\n",
      "train loss:0.0020932244357799597\n",
      "train loss:0.0058309471234893415\n",
      "train loss:0.0004347915701240451\n",
      "train loss:0.00381709982159001\n",
      "train loss:0.005301716634188262\n",
      "train loss:0.00013530899396328914\n",
      "train loss:0.001530338559451698\n",
      "train loss:0.00040258405840139233\n",
      "train loss:0.000578315590480392\n",
      "train loss:0.0002536375016158066\n",
      "train loss:0.00033943144960495684\n",
      "train loss:0.0003419709159430723\n",
      "train loss:0.0002865160881862505\n",
      "train loss:0.0033611438488795426\n",
      "train loss:0.0018567344514880781\n",
      "train loss:8.145964158667468e-05\n",
      "train loss:0.0004652180313157792\n",
      "train loss:0.0018122375906702679\n",
      "train loss:0.0005304082725306577\n",
      "train loss:0.001548605205830647\n",
      "train loss:0.0005214973895713951\n",
      "train loss:0.0005378615133399031\n",
      "train loss:0.0006527024208345799\n",
      "train loss:0.0008949714416169578\n",
      "train loss:0.002378275779942051\n",
      "train loss:0.00017646557015095352\n",
      "train loss:0.0022306017188612397\n",
      "train loss:0.0020448468012498684\n",
      "train loss:0.0022861909564629405\n",
      "train loss:0.0005479359889278991\n",
      "train loss:0.0004977235111776781\n",
      "train loss:0.0012317426401180726\n",
      "train loss:0.0017849613053611399\n",
      "train loss:0.002604010500499632\n",
      "train loss:0.00026130255936026534\n",
      "train loss:0.014670396094196658\n",
      "train loss:0.0002279936134683684\n",
      "train loss:0.001288829631868142\n",
      "train loss:0.00022791177717257854\n",
      "train loss:0.0001855763137893087\n",
      "train loss:0.0010723097452742943\n",
      "train loss:0.00024639693571898403\n",
      "train loss:0.004055959467779662\n",
      "train loss:0.0003313293491104861\n",
      "train loss:0.001322412842146554\n",
      "train loss:0.0019007999580570975\n",
      "train loss:0.0020476843617570325\n",
      "train loss:0.002462393454747187\n",
      "train loss:0.00183856924109397\n",
      "train loss:0.002480179810923574\n",
      "train loss:0.0003966839178664018\n",
      "train loss:0.0021452912811367403\n",
      "train loss:0.000500012438689863\n",
      "train loss:0.001822548397824126\n",
      "train loss:0.0024070343311804947\n",
      "train loss:0.0004981403794172681\n",
      "train loss:0.00018689917438449111\n",
      "train loss:0.0005847230379960913\n",
      "train loss:0.0008375701004211912\n",
      "train loss:0.003956760108025599\n",
      "train loss:0.0005737666642321382\n",
      "train loss:0.00041411097830934286\n",
      "train loss:0.0004165664308921875\n",
      "train loss:0.0013415908385103331\n",
      "train loss:0.017998133063637203\n",
      "train loss:0.0007607143311697738\n",
      "train loss:0.001629521061797824\n",
      "train loss:0.001175159624591838\n",
      "train loss:0.00030088406736083676\n",
      "train loss:0.00016819383162206686\n",
      "train loss:6.510697640614245e-05\n",
      "train loss:0.0017264255526420946\n",
      "train loss:0.00015944758396691232\n",
      "train loss:0.0009230183770701975\n",
      "train loss:0.00025161056314360806\n",
      "train loss:0.00045581248239290204\n",
      "train loss:0.00040116249287345694\n",
      "train loss:0.01168553849087313\n",
      "train loss:0.0028132066398151834\n",
      "train loss:0.00020074135506475296\n",
      "train loss:0.00233837825735174\n",
      "train loss:0.0019240375213728231\n",
      "train loss:0.00020604898157694886\n",
      "train loss:0.0009620249627356521\n",
      "train loss:0.0010959823931417304\n",
      "train loss:0.00343345702779446\n",
      "train loss:0.0021090458482092398\n",
      "train loss:0.0009017192108807327\n",
      "train loss:0.0020563818264584346\n",
      "train loss:0.0003720493369135474\n",
      "train loss:0.0003388120223209513\n",
      "train loss:0.0004486843358367592\n",
      "train loss:0.00042778814834408004\n",
      "train loss:0.003440415529252379\n",
      "train loss:0.00483322480767418\n",
      "train loss:0.0011447189084883105\n",
      "train loss:0.0017352483259330783\n",
      "train loss:0.00026109573944540885\n",
      "train loss:0.0014486284035778796\n",
      "train loss:0.0004256031831528815\n",
      "train loss:0.0003011457202237711\n",
      "train loss:0.0005692116306473379\n",
      "train loss:0.001953987863714198\n",
      "train loss:0.0008240798945513923\n",
      "train loss:0.0006578401277194844\n",
      "train loss:0.002388227036951349\n",
      "train loss:0.0018612078608354792\n",
      "train loss:0.00013864460541915054\n",
      "train loss:0.0016123767002918779\n",
      "train loss:0.0019078302651691164\n",
      "train loss:0.000511279814912358\n",
      "train loss:0.00031809094827150704\n",
      "train loss:0.005524314637975298\n",
      "train loss:0.0010371921536052459\n",
      "train loss:0.017648725520460713\n",
      "train loss:0.0001804939406509628\n",
      "train loss:0.0004788438976333423\n",
      "train loss:0.0008857650517812403\n",
      "train loss:0.00011924406247699272\n",
      "train loss:0.007450080007390505\n",
      "train loss:0.003423121386847434\n",
      "train loss:0.0002713697497565975\n",
      "train loss:0.0002421664392078313\n",
      "train loss:0.0001033520636387032\n",
      "train loss:0.0008925059516897253\n",
      "train loss:0.0017763987919070868\n",
      "train loss:0.0004954607154924866\n",
      "train loss:0.0003826643713689972\n",
      "train loss:0.004499687925558115\n",
      "train loss:0.0014869811174483805\n",
      "train loss:0.0019312906947520758\n",
      "train loss:0.002835135044179203\n",
      "train loss:0.0007327434476553359\n",
      "train loss:0.0021532759626542663\n",
      "train loss:0.0007635751372276151\n",
      "train loss:0.0011562277096292045\n",
      "train loss:0.001977877847005183\n",
      "train loss:0.0006782587453348416\n",
      "train loss:0.00043584738788456784\n",
      "train loss:0.0017591580221841957\n",
      "train loss:0.000356846668004422\n",
      "train loss:0.0006413755574647093\n",
      "train loss:0.0007571087316200114\n",
      "train loss:0.0002689797502053267\n",
      "train loss:0.019133945168304245\n",
      "train loss:0.0031981489766509993\n",
      "train loss:0.0017988629440616522\n",
      "train loss:0.00018310925375387684\n",
      "train loss:0.0008485813448303636\n",
      "train loss:0.00041379858887017923\n",
      "train loss:0.004020759967448565\n",
      "train loss:0.0003933286164418874\n",
      "train loss:0.00014146111476515032\n",
      "train loss:0.0002440228833303916\n",
      "train loss:0.00026391292474688805\n",
      "train loss:0.0027612950936067417\n",
      "train loss:0.002189379176827147\n",
      "train loss:0.0014453390064756986\n",
      "train loss:0.003191497944512861\n",
      "train loss:0.0044089548289745735\n",
      "=== epoch:17, train acc:0.998, test acc:0.985 ===\n",
      "train loss:0.0027411415251126264\n",
      "train loss:0.00017628616638476577\n",
      "train loss:0.00044455074073685043\n",
      "train loss:0.005430608312478976\n",
      "train loss:0.00038450200133084456\n",
      "train loss:0.0017140898610275943\n",
      "train loss:0.0004007259473983719\n",
      "train loss:0.0012174418001164513\n",
      "train loss:0.00026785778882735053\n",
      "train loss:0.003915897716581066\n",
      "train loss:0.005751699314480333\n",
      "train loss:0.00012628841535655317\n",
      "train loss:0.0024581857769927517\n",
      "train loss:0.0008344660819749161\n",
      "train loss:0.0015783849883558643\n",
      "train loss:0.001764601144380968\n",
      "train loss:0.0009896006233299343\n",
      "train loss:0.000826545445929599\n",
      "train loss:0.0013228058538215597\n",
      "train loss:0.0019138464366400094\n",
      "train loss:0.004489170178807296\n",
      "train loss:0.0054145051294160465\n",
      "train loss:0.0015085780959891038\n",
      "train loss:0.0012314040990457752\n",
      "train loss:0.0001243077450036528\n",
      "train loss:0.021588204246639778\n",
      "train loss:0.016428017252437716\n",
      "train loss:0.0073586194288546266\n",
      "train loss:0.0011823029870662565\n",
      "train loss:0.0037979453041930965\n",
      "train loss:0.00438135189750166\n",
      "train loss:0.0009088196203643117\n",
      "train loss:0.001389737794747258\n",
      "train loss:0.003963570926337987\n",
      "train loss:0.004364850247303885\n",
      "train loss:0.004672038896765743\n",
      "train loss:0.00024371107199036205\n",
      "train loss:0.00115766832050655\n",
      "train loss:0.00015047876559715745\n",
      "train loss:0.0019360053774760619\n",
      "train loss:0.0015141133425653553\n",
      "train loss:0.001491562651995184\n",
      "train loss:0.00019125654253239054\n",
      "train loss:0.00019533684789810684\n",
      "train loss:0.0003219928610064054\n",
      "train loss:0.0012100507376157337\n",
      "train loss:0.004834808920102553\n",
      "train loss:0.0045264174465299185\n",
      "train loss:0.0007358079523535769\n",
      "train loss:0.0049022588647009415\n",
      "train loss:0.002413481884416482\n",
      "train loss:0.0010221627484966256\n",
      "train loss:0.0014939761645155038\n",
      "train loss:0.0035012210164688303\n",
      "train loss:0.009549214727294848\n",
      "train loss:0.0018293046607296324\n",
      "train loss:0.00042949343829721734\n",
      "train loss:0.0018865528373481274\n",
      "train loss:0.00316335271738945\n",
      "train loss:4.246805271748224e-05\n",
      "train loss:0.0004150382533570169\n",
      "train loss:0.0014799279655465464\n",
      "train loss:0.0010669100554775463\n",
      "train loss:0.0012627197288435726\n",
      "train loss:0.001346292972363948\n",
      "train loss:0.0031483362419347013\n",
      "train loss:0.004506808557960515\n",
      "train loss:0.0028691304818912185\n",
      "train loss:0.0007380564885068829\n",
      "train loss:0.0004624593824643561\n",
      "train loss:0.0061226138572195825\n",
      "train loss:0.0005853987082411438\n",
      "train loss:0.000705704418620417\n",
      "train loss:0.0012391404876595884\n",
      "train loss:0.0024461108347580925\n",
      "train loss:0.0008944339787922369\n",
      "train loss:0.004501096388961412\n",
      "train loss:0.0017707068703623255\n",
      "train loss:0.0031517702194389795\n",
      "train loss:0.0013658174221876287\n",
      "train loss:0.0005337278163827873\n",
      "train loss:0.0014117860766845538\n",
      "train loss:0.0001636851531256624\n",
      "train loss:0.0011849899884798286\n",
      "train loss:0.004432460870219607\n",
      "train loss:0.006675489902033795\n",
      "train loss:0.0013805510305396756\n",
      "train loss:0.00228933344920163\n",
      "train loss:0.001178352959741113\n",
      "train loss:0.0010900102141263423\n",
      "train loss:0.0007895046536290232\n",
      "train loss:0.00289105607105634\n",
      "train loss:0.0006095713109630657\n",
      "train loss:0.0020021657187525733\n",
      "train loss:0.00043939280831748243\n",
      "train loss:0.00839417914143268\n",
      "train loss:3.029675118121541e-05\n",
      "train loss:0.0027919675640383844\n",
      "train loss:0.0033047733210663376\n",
      "train loss:0.0028910820532031295\n",
      "train loss:0.001582011655310437\n",
      "train loss:0.00014545130417708218\n",
      "train loss:0.0009110359484447363\n",
      "train loss:0.00037841829474768\n",
      "train loss:0.001973390338741522\n",
      "train loss:0.007481720489530209\n",
      "train loss:0.001064756831417304\n",
      "train loss:0.00012361169153716142\n",
      "train loss:0.0017723026009851502\n",
      "train loss:0.0037919711738977485\n",
      "train loss:0.002503194003491692\n",
      "train loss:0.003191214798775899\n",
      "train loss:0.001042269494180935\n",
      "train loss:0.0010168266634922602\n",
      "train loss:0.0009176082230083357\n",
      "train loss:6.218877210962047e-05\n",
      "train loss:0.010346431322236296\n",
      "train loss:0.001759520902706279\n",
      "train loss:0.00034483539555413013\n",
      "train loss:0.0002634487275426483\n",
      "train loss:0.0020664437883446303\n",
      "train loss:6.596594800824745e-05\n",
      "train loss:0.0002290897168986847\n",
      "train loss:0.002247984052665947\n",
      "train loss:0.0059121900673916985\n",
      "train loss:0.001410647024961209\n",
      "train loss:0.0031866127381945664\n",
      "train loss:0.014267261825889577\n",
      "train loss:7.249579153229109e-05\n",
      "train loss:0.0006829655717965492\n",
      "train loss:0.002770814499245064\n",
      "train loss:0.0072942289910284015\n",
      "train loss:0.00011678970573898874\n",
      "train loss:0.0005066861316617684\n",
      "train loss:0.001935998364374798\n",
      "train loss:0.00036656430830886286\n",
      "train loss:0.00044200387873106025\n",
      "train loss:0.0024247359527882224\n",
      "train loss:0.0014034463206098373\n",
      "train loss:0.00026036712556119903\n",
      "train loss:8.278226349671649e-05\n",
      "train loss:0.0006039107363301268\n",
      "train loss:0.0036627199926752697\n",
      "train loss:0.0029879278512310948\n",
      "train loss:0.00430612112347241\n",
      "train loss:0.004627488401723129\n",
      "train loss:0.00016788357983515926\n",
      "train loss:0.0013459510884069937\n",
      "train loss:0.00011164588882780871\n",
      "train loss:0.0017221697395113909\n",
      "train loss:0.0036098289644442543\n",
      "train loss:0.0017892586613503835\n",
      "train loss:0.0003851652855462282\n",
      "train loss:0.0007146378370985227\n",
      "train loss:0.0037704827107869297\n",
      "train loss:0.0013901785843116418\n",
      "train loss:0.004242821053437881\n",
      "train loss:0.005529176065159616\n",
      "train loss:0.008772710346719096\n",
      "train loss:0.0011859008295418772\n",
      "train loss:0.0024203235929335593\n",
      "train loss:0.00030112537446006616\n",
      "train loss:0.0005660454551348835\n",
      "train loss:0.0020563615848238196\n",
      "train loss:0.0006466089405300108\n",
      "train loss:0.0012592205812722423\n",
      "train loss:0.00035648714293181976\n",
      "train loss:0.004208367563263486\n",
      "train loss:0.0026797388736462193\n",
      "train loss:0.0031161997830418185\n",
      "train loss:0.0006401457244232097\n",
      "train loss:0.0059271350538761215\n",
      "train loss:0.0029931953344334798\n",
      "train loss:0.0022932331328179693\n",
      "train loss:0.001443724971310908\n",
      "train loss:0.0003548688528881586\n",
      "train loss:0.00379167366686845\n",
      "train loss:0.0010093727598030383\n",
      "train loss:0.0016042252897084167\n",
      "train loss:0.00048676996987916284\n",
      "train loss:0.0022754889123866836\n",
      "train loss:0.0003758635933020705\n",
      "train loss:0.011799756976370703\n",
      "train loss:0.0006236300111458694\n",
      "train loss:0.0047235199824360785\n",
      "train loss:0.005860918237115712\n",
      "train loss:0.0013646187519712276\n",
      "train loss:0.001562941640415882\n",
      "train loss:0.0018339890128329709\n",
      "train loss:0.010670283824298712\n",
      "train loss:0.003745866397832628\n",
      "train loss:0.007484995947846176\n",
      "train loss:0.0018753984427410716\n",
      "train loss:0.001149417559409212\n",
      "train loss:0.00039656488647183465\n",
      "train loss:0.0038344131160332855\n",
      "train loss:0.0045009922340659295\n",
      "train loss:0.0013709332255665858\n",
      "train loss:0.00010062676482111319\n",
      "train loss:0.0008841980038205721\n",
      "train loss:0.0023326306817157976\n",
      "train loss:0.016590987294629184\n",
      "train loss:0.0008268099835092015\n",
      "train loss:0.02064613913347106\n",
      "train loss:0.001598682189265485\n",
      "train loss:0.00039882042046162497\n",
      "train loss:0.0018917408519979638\n",
      "train loss:0.001715820768657434\n",
      "train loss:0.0005647509352794356\n",
      "train loss:0.0021214424714829246\n",
      "train loss:0.005844201941356225\n",
      "train loss:0.0069807407411024\n",
      "train loss:0.00030808419230974243\n",
      "train loss:0.002005431313403931\n",
      "train loss:0.014809675487031757\n",
      "train loss:0.02175287346494921\n",
      "train loss:0.00038479891267987064\n",
      "train loss:0.0013511126757147385\n",
      "train loss:0.00042235427252580385\n",
      "train loss:0.0004501229127768985\n",
      "train loss:0.0019702935481386366\n",
      "train loss:0.0008903500773491214\n",
      "train loss:0.00017061720169175075\n",
      "train loss:0.0015763069259393375\n",
      "train loss:0.0031656712146672654\n",
      "train loss:0.0016931489650061685\n",
      "train loss:0.000968455934383218\n",
      "train loss:0.012116365917411503\n",
      "train loss:6.721554159465595e-05\n",
      "train loss:0.0024703734998832213\n",
      "train loss:0.008681922017320154\n",
      "train loss:0.0010512625600575965\n",
      "train loss:0.0006629529179559327\n",
      "train loss:0.011461666834863065\n",
      "train loss:0.0008691349725459486\n",
      "train loss:0.005553157064454246\n",
      "train loss:0.0005370376273106291\n",
      "train loss:0.031168964495680282\n",
      "train loss:0.00035055373502661637\n",
      "train loss:0.0006400853645084359\n",
      "train loss:0.004525838726426539\n",
      "train loss:0.0016321217241140418\n",
      "train loss:0.027345241496563037\n",
      "train loss:0.0008576715494785551\n",
      "train loss:0.0009322119536534234\n",
      "train loss:0.0006631934380137808\n",
      "train loss:0.0002048199853557297\n",
      "train loss:0.0008705849564482109\n",
      "train loss:3.350929025735247e-05\n",
      "train loss:0.0019144165879141047\n",
      "train loss:0.002502264298900311\n",
      "train loss:0.004124695682474494\n",
      "train loss:0.0013484419575804753\n",
      "train loss:0.0013444178328943246\n",
      "train loss:0.0029306143847472738\n",
      "train loss:4.954369189013593e-05\n",
      "train loss:0.00023107818155951494\n",
      "train loss:0.0034066551107423317\n",
      "train loss:0.0010537754655912785\n",
      "train loss:0.0019135557778502499\n",
      "train loss:0.037954856975551655\n",
      "train loss:0.0005223280857113653\n",
      "train loss:0.0012053445742946191\n",
      "train loss:0.0006245521177946474\n",
      "train loss:0.0001306292906739819\n",
      "train loss:0.0022646776629516962\n",
      "train loss:0.0016360832065416273\n",
      "train loss:0.0007836658421566608\n",
      "train loss:0.0027721786797782915\n",
      "train loss:0.0011750798796814426\n",
      "train loss:0.014944863172365708\n",
      "train loss:0.0022227019722100448\n",
      "train loss:0.0016640474134158808\n",
      "train loss:7.62556261750553e-05\n",
      "train loss:4.603492013104717e-05\n",
      "train loss:0.00017831490929545157\n",
      "train loss:0.0019835692410705677\n",
      "train loss:0.0013243567153058539\n",
      "train loss:0.0003610564890735233\n",
      "train loss:0.0013106240891078277\n",
      "train loss:0.0011654531354816336\n",
      "train loss:0.0031231202233503313\n",
      "train loss:0.0014413183506281132\n",
      "train loss:0.0004298375109624253\n",
      "train loss:0.0005097830159566005\n",
      "train loss:0.0005014107389221248\n",
      "train loss:0.0006902499014260182\n",
      "train loss:0.0004986893469987355\n",
      "train loss:4.474156008220096e-05\n",
      "train loss:9.44473915978736e-05\n",
      "train loss:0.00226754720162755\n",
      "train loss:2.376952439714697e-05\n",
      "train loss:3.0927333600598986e-05\n",
      "train loss:0.0008987719859519658\n",
      "train loss:0.0068395659473747565\n",
      "train loss:0.001055240469123381\n",
      "train loss:0.007195280779861427\n",
      "train loss:0.0025730388476436043\n",
      "train loss:0.0018703240343619228\n",
      "train loss:0.0002217966964671452\n",
      "train loss:0.0022473024541896213\n",
      "train loss:0.000424671738443439\n",
      "train loss:0.002868414454714149\n",
      "train loss:0.002022036225508627\n",
      "train loss:0.0004643482900750046\n",
      "train loss:0.0010992987831012662\n",
      "train loss:0.0008264577341895919\n",
      "train loss:0.0005556495815770924\n",
      "train loss:0.0021107040216939775\n",
      "train loss:0.003754122872841823\n",
      "train loss:0.0004899792364540942\n",
      "train loss:0.00019088886265816653\n",
      "train loss:0.008113406369901106\n",
      "train loss:0.0034155024278150615\n",
      "train loss:0.00020811279416110294\n",
      "train loss:0.000728230594131131\n",
      "train loss:0.0017151025238903875\n",
      "train loss:0.0011515314436181677\n",
      "train loss:0.0002161518956240962\n",
      "train loss:0.000562465380811112\n",
      "train loss:0.0013886494241275524\n",
      "train loss:0.001354711405370707\n",
      "train loss:0.00014370610249629794\n",
      "train loss:0.0019650946553249962\n",
      "train loss:6.905707386870045e-05\n",
      "train loss:0.00031158920869428616\n",
      "train loss:0.001962223583223828\n",
      "train loss:0.0006330735587104175\n",
      "train loss:0.0009387290117551404\n",
      "train loss:0.002626568958570807\n",
      "train loss:0.0031335926205669595\n",
      "train loss:0.0008535100721930062\n",
      "train loss:0.0035382758947207628\n",
      "train loss:0.0002674506752430472\n",
      "train loss:0.0017063049314486128\n",
      "train loss:0.004898467310981877\n",
      "train loss:0.0003426539000606764\n",
      "train loss:0.0015400218117108747\n",
      "train loss:0.0007548034450876079\n",
      "train loss:0.00058236353596225\n",
      "train loss:0.0015996114739666263\n",
      "train loss:0.00041476694619186505\n",
      "train loss:0.002831502223026934\n",
      "train loss:0.0022923599140212635\n",
      "train loss:0.0006703629587538594\n",
      "train loss:0.00045698455041754055\n",
      "train loss:0.0015106183857980645\n",
      "train loss:0.0033585220657043877\n",
      "train loss:4.0376685052079375e-05\n",
      "train loss:0.000585507558244472\n",
      "train loss:0.0024634023566209324\n",
      "train loss:0.0012207717682764167\n",
      "train loss:0.002629988401196784\n",
      "train loss:0.002480380175714653\n",
      "train loss:0.0017855340085419704\n",
      "train loss:0.0003755795899507381\n",
      "train loss:0.0028525310697414424\n",
      "train loss:0.0061542654995835845\n",
      "train loss:0.0023016502290984643\n",
      "train loss:0.010059840873471185\n",
      "train loss:0.0009497577921148869\n",
      "train loss:0.0035682318410887757\n",
      "train loss:0.0009587815916271955\n",
      "train loss:0.003818455674407824\n",
      "train loss:0.001459204950203962\n",
      "train loss:0.00021781294909830134\n",
      "train loss:0.000737360704254932\n",
      "train loss:0.004886603645282723\n",
      "train loss:0.053560862307598794\n",
      "train loss:0.00015636668997793892\n",
      "train loss:0.013463216319842541\n",
      "train loss:0.0005580028614419821\n",
      "train loss:0.0007285518208766949\n",
      "train loss:0.0020588910950843082\n",
      "train loss:0.0004988141195933139\n",
      "train loss:0.0023499810311185727\n",
      "train loss:0.0021313654666239535\n",
      "train loss:0.0018625501428279564\n",
      "train loss:0.0009125010994868253\n",
      "train loss:0.00013875758733081645\n",
      "train loss:0.000355829455017313\n",
      "train loss:9.578981434961931e-05\n",
      "train loss:0.0010339353684880308\n",
      "train loss:0.00023190090526112913\n",
      "train loss:0.0007922812340248529\n",
      "train loss:0.0015147149290016405\n",
      "train loss:0.0076798109329842025\n",
      "train loss:0.009677326354742609\n",
      "train loss:0.0007979208251475727\n",
      "train loss:0.010628587148854365\n",
      "train loss:0.0017083364397899687\n",
      "train loss:0.0024860133003157393\n",
      "train loss:0.001837383775350543\n",
      "train loss:0.0059080417716997746\n",
      "train loss:0.004209111085265375\n",
      "train loss:0.002096472164816651\n",
      "train loss:0.017811301028345702\n",
      "train loss:0.00011866099553071951\n",
      "train loss:0.00038955804983243795\n",
      "train loss:0.0005436201024969102\n",
      "train loss:0.0022788208792571918\n",
      "train loss:0.014676419967506005\n",
      "train loss:0.0009002380785023921\n",
      "train loss:0.010285386116780539\n",
      "train loss:0.0027809658018122796\n",
      "train loss:0.0015470537956997358\n",
      "train loss:0.00028514012760866986\n",
      "train loss:0.002719020070670113\n",
      "train loss:0.0008256407411084478\n",
      "train loss:0.0009790094466382415\n",
      "train loss:0.00012364831958766316\n",
      "train loss:0.0014860899834575941\n",
      "train loss:0.0012554700424543997\n",
      "train loss:0.0003657573197307317\n",
      "train loss:0.0050373333691738865\n",
      "train loss:0.0030064585772408992\n",
      "train loss:0.008882215384427357\n",
      "train loss:0.002135901255842267\n",
      "train loss:0.0007307109933990704\n",
      "train loss:0.0022591249063841604\n",
      "train loss:0.000306062322777135\n",
      "train loss:0.006595608583272511\n",
      "train loss:0.001616075063087381\n",
      "train loss:0.0006897668956831297\n",
      "train loss:0.0011795260494071773\n",
      "train loss:0.042285598513909395\n",
      "train loss:0.00019264850438131516\n",
      "train loss:0.009956611790827564\n",
      "train loss:0.005287189609995961\n",
      "train loss:0.0029801079103692974\n",
      "train loss:0.004205991213289378\n",
      "train loss:0.0007307033699570921\n",
      "train loss:0.0021038241638997343\n",
      "train loss:7.641450071752651e-05\n",
      "train loss:0.00012164739288362492\n",
      "train loss:0.00853103263807976\n",
      "train loss:0.0031525301446595167\n",
      "train loss:0.0003267733803556103\n",
      "train loss:0.0001175689336250868\n",
      "train loss:0.0009364061215516044\n",
      "train loss:0.0022900807990239593\n",
      "train loss:0.0026470115908405873\n",
      "train loss:0.011934580915104354\n",
      "train loss:0.000404125146552109\n",
      "train loss:0.0029341033671739414\n",
      "train loss:0.0004250813172780303\n",
      "train loss:0.0008382136371653743\n",
      "train loss:0.0008815026496426912\n",
      "train loss:0.018824035976562455\n",
      "train loss:0.0007410437968310749\n",
      "train loss:0.007997927183889702\n",
      "train loss:0.009143972774180298\n",
      "train loss:0.008916181240232818\n",
      "train loss:0.005115590521179556\n",
      "train loss:0.007632168108722764\n",
      "train loss:0.0032544224933684666\n",
      "train loss:0.0033780651820575517\n",
      "train loss:0.005778777140992418\n",
      "train loss:0.0022241456126725514\n",
      "train loss:0.016249558756206112\n",
      "train loss:0.0008562048933159288\n",
      "train loss:0.0057967231285463786\n",
      "train loss:0.0001868731280832127\n",
      "train loss:2.2130385526923377e-05\n",
      "train loss:0.0008548407338873127\n",
      "train loss:0.01236491816173214\n",
      "train loss:0.0008730595005880252\n",
      "train loss:0.00012201849635638656\n",
      "train loss:0.0017481313284330503\n",
      "train loss:0.011652109031941783\n",
      "train loss:0.0013293994682212363\n",
      "train loss:0.0029439601655284553\n",
      "train loss:0.0010831000251430314\n",
      "train loss:0.005057343358784208\n",
      "train loss:0.0016032232137121658\n",
      "train loss:0.02217250189948665\n",
      "train loss:0.000669520764005912\n",
      "train loss:0.0011426378500773435\n",
      "train loss:0.008122866473525982\n",
      "train loss:0.002125736278240678\n",
      "train loss:0.0033533637111258048\n",
      "train loss:0.001204828720163872\n",
      "train loss:0.003660910467617503\n",
      "train loss:0.00180983790281779\n",
      "train loss:0.0010320812388441205\n",
      "train loss:0.0020871138027866933\n",
      "train loss:0.0028357059369162304\n",
      "train loss:0.0014868471783687023\n",
      "train loss:0.003437559330061789\n",
      "train loss:0.0018905927385566223\n",
      "train loss:0.0016229602106919547\n",
      "train loss:0.009462399284814953\n",
      "train loss:0.005414674807889233\n",
      "train loss:0.02907233088915226\n",
      "train loss:0.0017605859795163656\n",
      "train loss:0.0013621315762079988\n",
      "train loss:0.00028149720872799584\n",
      "train loss:0.0015999447502565611\n",
      "train loss:0.0023146959324789307\n",
      "train loss:0.013783517171228433\n",
      "train loss:0.0014829862640023028\n",
      "train loss:0.0014122576431669699\n",
      "train loss:0.0012355770991069037\n",
      "train loss:0.0011243523673890058\n",
      "train loss:0.0006177475148148252\n",
      "train loss:0.0058912281707398165\n",
      "train loss:0.002110893288131382\n",
      "train loss:0.0007402922827696383\n",
      "train loss:0.0002294876764631332\n",
      "train loss:0.0002614280430807255\n",
      "train loss:0.0023637858894111252\n",
      "train loss:0.003086292426034776\n",
      "train loss:0.0031218145929269004\n",
      "train loss:0.053185321214922116\n",
      "train loss:0.00024237427748106545\n",
      "train loss:0.002607319822702595\n",
      "train loss:0.0025682350925653667\n",
      "train loss:0.006131983899259584\n",
      "train loss:0.006200845120930349\n",
      "train loss:0.0009077347909691495\n",
      "train loss:0.0024284207014346653\n",
      "train loss:0.0006173576005574323\n",
      "train loss:0.003729274295149241\n",
      "train loss:0.002522062687764831\n",
      "train loss:0.007077818420334738\n",
      "train loss:0.0007366873486495613\n",
      "train loss:0.0018640762723296266\n",
      "train loss:0.006893234712856723\n",
      "train loss:0.0011558298530424144\n",
      "train loss:0.0017258939190902744\n",
      "train loss:0.008790664669974349\n",
      "train loss:0.004082206511683011\n",
      "train loss:0.0035263564223903953\n",
      "train loss:0.0036110059568485327\n",
      "train loss:0.0057074845795371965\n",
      "train loss:0.008120347831432374\n",
      "train loss:0.0012998131980439737\n",
      "train loss:0.001993186973649475\n",
      "train loss:0.000575988169355593\n",
      "train loss:0.001776184101736567\n",
      "train loss:0.002283805747316801\n",
      "train loss:0.003321042955610704\n",
      "train loss:0.0020976180785871905\n",
      "train loss:0.00011824930247095441\n",
      "train loss:7.659924618439376e-05\n",
      "train loss:0.0009881652142403872\n",
      "train loss:3.995860685024234e-05\n",
      "train loss:0.00034195435567510916\n",
      "train loss:0.0016702546123711416\n",
      "train loss:0.001304250581126276\n",
      "train loss:0.004429473430357928\n",
      "train loss:0.0014449166352234434\n",
      "train loss:0.012307320089377256\n",
      "train loss:0.0004087694894139489\n",
      "train loss:0.0017079087365422666\n",
      "train loss:0.01601317153727913\n",
      "train loss:0.0011287633558396861\n",
      "train loss:0.004727961440311618\n",
      "train loss:0.00019492834278026826\n",
      "train loss:0.0013579073609847902\n",
      "train loss:0.0001253731468277815\n",
      "train loss:0.001164453058191302\n",
      "train loss:0.006921766820386831\n",
      "train loss:0.001282745343422915\n",
      "train loss:6.10684810485981e-05\n",
      "train loss:0.001305603896306933\n",
      "train loss:0.0024356574924105892\n",
      "train loss:0.0005877751918428431\n",
      "train loss:0.0014446225073855088\n",
      "train loss:0.00022500165230321232\n",
      "train loss:0.0003411387730416373\n",
      "train loss:0.00011871761892925303\n",
      "train loss:0.0055724864241650796\n",
      "train loss:0.0012784640512913373\n",
      "train loss:0.0017112260380337308\n",
      "train loss:0.0012003024820428922\n",
      "train loss:0.00014317974892899885\n",
      "train loss:0.005652967133419043\n",
      "train loss:0.003727110903697402\n",
      "train loss:0.0009825808727787723\n",
      "train loss:0.0023839505861481514\n",
      "train loss:0.0007338187728320399\n",
      "train loss:0.0002170247116475641\n",
      "train loss:0.00011646604381551385\n",
      "train loss:0.004094459498992256\n",
      "train loss:0.0004223815680318891\n",
      "train loss:0.00014963469093522643\n",
      "train loss:0.0033755216805034243\n",
      "train loss:0.000344327022683435\n",
      "train loss:0.0005795124784922847\n",
      "train loss:0.0010684909084299483\n",
      "train loss:0.0047537286923149446\n",
      "train loss:0.003079870461043157\n",
      "train loss:0.0011266824552548\n",
      "train loss:0.0021559295522966997\n",
      "train loss:0.00206530278358501\n",
      "train loss:0.0008451737360971927\n",
      "train loss:0.0011182430217775404\n",
      "train loss:0.006301260447515037\n",
      "train loss:0.00023768998879259567\n",
      "=== epoch:18, train acc:0.998, test acc:0.988 ===\n",
      "train loss:0.004943437741787787\n",
      "train loss:2.1008910803051377e-05\n",
      "train loss:0.0010159270323129757\n",
      "train loss:0.0010588737765349573\n",
      "train loss:0.0034184566488921642\n",
      "train loss:0.0020499384114737525\n",
      "train loss:0.0025572799399303098\n",
      "train loss:0.004544063824361396\n",
      "train loss:0.004672414473531835\n",
      "train loss:0.001114434752343629\n",
      "train loss:0.00019693910277112785\n",
      "train loss:0.002423429533804379\n",
      "train loss:0.0014271084211110515\n",
      "train loss:0.0009541739926824489\n",
      "train loss:0.0014562271059004805\n",
      "train loss:0.0002457091836756581\n",
      "train loss:0.0009692591409744044\n",
      "train loss:0.011701207435781902\n",
      "train loss:0.0009826301104095794\n",
      "train loss:0.0002435373402070856\n",
      "train loss:0.00037679828461004817\n",
      "train loss:0.0027097441633408266\n",
      "train loss:0.0013931818179749198\n",
      "train loss:0.0009723683722121214\n",
      "train loss:0.0021432002893877365\n",
      "train loss:0.003620700817811599\n",
      "train loss:0.008819092253317532\n",
      "train loss:0.0008253225403315131\n",
      "train loss:0.007295102731277604\n",
      "train loss:0.00023729445938360094\n",
      "train loss:7.993200845003723e-05\n",
      "train loss:0.003938740603785124\n",
      "train loss:0.000959473611589926\n",
      "train loss:0.0003648501521727399\n",
      "train loss:0.004370356016429169\n",
      "train loss:0.0008644008616593715\n",
      "train loss:0.00014513059759324666\n",
      "train loss:0.006133992100547674\n",
      "train loss:0.001002364103519321\n",
      "train loss:0.0005223368621244393\n",
      "train loss:0.0060415755486079425\n",
      "train loss:0.003258685716515575\n",
      "train loss:0.0014375136325457997\n",
      "train loss:0.03015846833048107\n",
      "train loss:0.0017979864917382785\n",
      "train loss:0.0010898644590566545\n",
      "train loss:0.00010262777596437276\n",
      "train loss:0.0017836181016662707\n",
      "train loss:0.0028607180347975316\n",
      "train loss:0.0013295888776532633\n",
      "train loss:6.541377448538353e-05\n",
      "train loss:0.003969016258371135\n",
      "train loss:0.0001036458935192452\n",
      "train loss:0.0019498122457836488\n",
      "train loss:0.0015518971656601022\n",
      "train loss:0.0018296849636806475\n",
      "train loss:0.003373827325996888\n",
      "train loss:0.0001872108112138643\n",
      "train loss:0.0011872932902546277\n",
      "train loss:0.002446874044094868\n",
      "train loss:0.0015706538863165128\n",
      "train loss:0.005956943407956491\n",
      "train loss:0.0007247743379931429\n",
      "train loss:0.0015678956587796536\n",
      "train loss:0.005209479179480924\n",
      "train loss:0.026688302513328533\n",
      "train loss:0.0013740104495926749\n",
      "train loss:0.00102828295019343\n",
      "train loss:0.00299597229804598\n",
      "train loss:0.0003231709881238582\n",
      "train loss:0.001072629943842431\n",
      "train loss:0.004196594159060845\n",
      "train loss:0.00024025900500142315\n",
      "train loss:0.003316573650384628\n",
      "train loss:3.6625390774398215e-05\n",
      "train loss:0.0010949557277102873\n",
      "train loss:0.003226848943464958\n",
      "train loss:0.005565030430557454\n",
      "train loss:0.0009699989711199016\n",
      "train loss:0.0022004579393573006\n",
      "train loss:0.005614190620289414\n",
      "train loss:0.002274008519208471\n",
      "train loss:0.0006342180529186497\n",
      "train loss:0.00010124154087160431\n",
      "train loss:0.001702291582139502\n",
      "train loss:0.00035404257497217046\n",
      "train loss:3.4337271580081205e-05\n",
      "train loss:0.0001593243756422015\n",
      "train loss:0.0009421651002241148\n",
      "train loss:0.003930415895758341\n",
      "train loss:0.0021555649142610466\n",
      "train loss:0.0032519144940414296\n",
      "train loss:0.0013997572843611958\n",
      "train loss:0.0011272356958767335\n",
      "train loss:0.000761319131664234\n",
      "train loss:0.002578195977687985\n",
      "train loss:0.00047871592234221215\n",
      "train loss:0.00560223625113498\n",
      "train loss:0.005273490741559846\n",
      "train loss:0.001193198885202856\n",
      "train loss:0.005736790577246576\n",
      "train loss:0.0007890404912154256\n",
      "train loss:0.0001657302263878494\n",
      "train loss:0.0001667796785417756\n",
      "train loss:0.00046203430713199356\n",
      "train loss:0.0029388309226112967\n",
      "train loss:0.00234139901559008\n",
      "train loss:0.0020128142537367863\n",
      "train loss:0.0008366980700091688\n",
      "train loss:0.0016932781044958585\n",
      "train loss:0.008914209792487108\n",
      "train loss:0.003035615925421348\n",
      "train loss:0.0037876377151551295\n",
      "train loss:0.0011985130551524894\n",
      "train loss:0.0004859662128457186\n",
      "train loss:0.00032159662209378296\n",
      "train loss:0.004088625897036074\n",
      "train loss:0.0026583249054705853\n",
      "train loss:0.00039011344147478065\n",
      "train loss:0.0013204437797847304\n",
      "train loss:0.0019178371515305632\n",
      "train loss:0.001488071807244356\n",
      "train loss:0.004779878026761074\n",
      "train loss:0.0028332232055843115\n",
      "train loss:0.001116074654073098\n",
      "train loss:0.0010393295512253057\n",
      "train loss:0.00923422383072885\n",
      "train loss:0.00028993148229034476\n",
      "train loss:0.013041405815431575\n",
      "train loss:0.002099028892776143\n",
      "train loss:0.002009828729529669\n",
      "train loss:0.0002402810940228119\n",
      "train loss:0.0005839701111266579\n",
      "train loss:0.00025922204958109653\n",
      "train loss:0.0014207088461671577\n",
      "train loss:0.0006444741877570674\n",
      "train loss:0.00021471052141393168\n",
      "train loss:0.0007204935860931543\n",
      "train loss:0.0004649822629107976\n",
      "train loss:0.0001934954442559635\n",
      "train loss:0.0028719665211898275\n",
      "train loss:0.007612731086681466\n",
      "train loss:0.0002804705896057346\n",
      "train loss:0.002628245238148308\n",
      "train loss:0.0012548054928360247\n",
      "train loss:0.0005857304483382864\n",
      "train loss:0.000889430406725106\n",
      "train loss:0.00039024627909772596\n",
      "train loss:0.00048189101399712597\n",
      "train loss:5.6902335686066975e-05\n",
      "train loss:0.0011867571860934342\n",
      "train loss:7.076941807039823e-05\n",
      "train loss:0.0024471169478046196\n",
      "train loss:0.00040291036775869224\n",
      "train loss:0.0006913522339091298\n",
      "train loss:0.007196655906548103\n",
      "train loss:0.0007055612891383256\n",
      "train loss:0.0005566398752008821\n",
      "train loss:0.0023904237444268162\n",
      "train loss:0.000857518864641269\n",
      "train loss:0.00041171656922064497\n",
      "train loss:9.97775294093361e-05\n",
      "train loss:0.0018409203144848505\n",
      "train loss:0.0013120222378255229\n",
      "train loss:0.007614499503791821\n",
      "train loss:0.002102621548699287\n",
      "train loss:0.0011573044203654207\n",
      "train loss:0.0010603718287004744\n",
      "train loss:0.00018178375341584745\n",
      "train loss:0.0007381066603973158\n",
      "train loss:0.0003737747583533497\n",
      "train loss:0.0008269714039982249\n",
      "train loss:0.0009404846129044764\n",
      "train loss:0.0013200979087086375\n",
      "train loss:0.0008412463780872768\n",
      "train loss:0.0002951650197966263\n",
      "train loss:0.001432009234469416\n",
      "train loss:0.00029817457693603113\n",
      "train loss:0.0004483857351930036\n",
      "train loss:0.0025094503608462187\n",
      "train loss:0.000465278028591403\n",
      "train loss:0.00097971562281743\n",
      "train loss:0.0027334171454608115\n",
      "train loss:0.00021093313254265226\n",
      "train loss:0.0014315936064021335\n",
      "train loss:0.00019161465907938476\n",
      "train loss:0.0040823190013635526\n",
      "train loss:0.002711174178767575\n",
      "train loss:0.0018319446700149295\n",
      "train loss:0.0017207156571241431\n",
      "train loss:0.0037131508127218617\n",
      "train loss:0.0004507510554202916\n",
      "train loss:0.0023514600980434554\n",
      "train loss:0.0002655300116802864\n",
      "train loss:0.0005252118145820516\n",
      "train loss:0.004605805011699131\n",
      "train loss:0.005167670019216328\n",
      "train loss:0.0008327259674874523\n",
      "train loss:0.0001296954590616425\n",
      "train loss:0.0002399682502123505\n",
      "train loss:0.0009476511491835634\n",
      "train loss:0.0009400810774813029\n",
      "train loss:9.280766937231389e-05\n",
      "train loss:0.002816920451411538\n",
      "train loss:0.0015682953819198208\n",
      "train loss:0.006088528500417437\n",
      "train loss:0.006353474647485129\n",
      "train loss:0.001036266961685504\n",
      "train loss:0.0023124749164713837\n",
      "train loss:0.00021070301057799594\n",
      "train loss:0.004514466758482374\n",
      "train loss:0.008386331292615378\n",
      "train loss:0.00535074741324518\n",
      "train loss:3.963679663732452e-05\n",
      "train loss:0.0014170949205358344\n",
      "train loss:0.0004351387806995891\n",
      "train loss:0.0006418060625090493\n",
      "train loss:0.002475911319034598\n",
      "train loss:0.0006212585480577375\n",
      "train loss:0.0020531162595463994\n",
      "train loss:3.0330737123897514e-05\n",
      "train loss:0.00013102306123778863\n",
      "train loss:0.00013532133996539022\n",
      "train loss:0.0009882888061434542\n",
      "train loss:0.00260533608430287\n",
      "train loss:0.0011502787894697442\n",
      "train loss:0.00013268883700652635\n",
      "train loss:0.003119354921621468\n",
      "train loss:4.4671440038363454e-05\n",
      "train loss:0.0009686505310661532\n",
      "train loss:0.0025295708948420096\n",
      "train loss:0.0011620092264524305\n",
      "train loss:0.0008086066062265626\n",
      "train loss:0.007781195449015074\n",
      "train loss:0.002004215584712905\n",
      "train loss:0.0025205544138891807\n",
      "train loss:0.001190651135113402\n",
      "train loss:0.002970377157618784\n",
      "train loss:0.0006108306675257899\n",
      "train loss:0.0001748603852397823\n",
      "train loss:6.543439557661706e-05\n",
      "train loss:0.0002089042202909686\n",
      "train loss:0.0022465714614537235\n",
      "train loss:0.0007183184458778137\n",
      "train loss:0.00023879088402170107\n",
      "train loss:0.0003212924679359818\n",
      "train loss:0.00038973711714978084\n",
      "train loss:0.0003506325096168253\n",
      "train loss:0.0014466858409635877\n",
      "train loss:0.00018668425399434515\n",
      "train loss:0.011529999944917857\n",
      "train loss:0.0014709948247673124\n",
      "train loss:0.001938452885416636\n",
      "train loss:0.0001907222000230944\n",
      "train loss:0.008880543015344576\n",
      "train loss:0.0018889319381077648\n",
      "train loss:0.0006519991913814208\n",
      "train loss:0.00018053885572101707\n",
      "train loss:0.006249808187290698\n",
      "train loss:0.00043442485085381984\n",
      "train loss:0.000261801800400382\n",
      "train loss:0.0025461697878752243\n",
      "train loss:9.331660841451626e-05\n",
      "train loss:0.011410529907295424\n",
      "train loss:0.0009090367910041274\n",
      "train loss:0.002954716847862428\n",
      "train loss:0.0014907514247107644\n",
      "train loss:0.003462363024870837\n",
      "train loss:0.0017854879197074422\n",
      "train loss:0.004942477212447681\n",
      "train loss:0.0016800798762817131\n",
      "train loss:0.0038862965580776032\n",
      "train loss:0.00017430615398344445\n",
      "train loss:0.0026638540350158433\n",
      "train loss:0.003391077887048723\n",
      "train loss:0.0006153838049636883\n",
      "train loss:0.00011465825909453955\n",
      "train loss:0.0012284903675078293\n",
      "train loss:0.0004978734350824521\n",
      "train loss:0.01973556921611727\n",
      "train loss:0.00035357625455298967\n",
      "train loss:0.0020458574996067426\n",
      "train loss:0.0038004344257546903\n",
      "train loss:0.004130653892891895\n",
      "train loss:0.0016421493925635419\n",
      "train loss:0.007877259706070871\n",
      "train loss:0.0007252079708466148\n",
      "train loss:0.002592592991211102\n",
      "train loss:0.0020982822207809473\n",
      "train loss:0.0009830338903814393\n",
      "train loss:0.0007719751333532718\n",
      "train loss:0.00279359300532836\n",
      "train loss:0.009222566343833878\n",
      "train loss:0.0007155868576036885\n",
      "train loss:0.00040232459473099543\n",
      "train loss:0.0001320454743709763\n",
      "train loss:0.0005144463031808054\n",
      "train loss:0.002488374082522953\n",
      "train loss:0.0038029930437503655\n",
      "train loss:0.008041787976197699\n",
      "train loss:0.000505258609224986\n",
      "train loss:0.00042332034363312345\n",
      "train loss:0.0026497326991391816\n",
      "train loss:0.00022341295378793493\n",
      "train loss:0.022960258582627367\n",
      "train loss:0.008514978573562652\n",
      "train loss:0.001700356998379059\n",
      "train loss:0.00026312013054030094\n",
      "train loss:0.004510420923528667\n",
      "train loss:0.0005546795639719942\n",
      "train loss:0.003655853995006104\n",
      "train loss:0.0004697473066696553\n",
      "train loss:0.006764404929882423\n",
      "train loss:0.002424205983643046\n",
      "train loss:2.056226736699552e-05\n",
      "train loss:0.00016149903641837196\n",
      "train loss:0.0002979037299182835\n",
      "train loss:0.0225258277602851\n",
      "train loss:0.003442217136275238\n",
      "train loss:0.0022633444887059733\n",
      "train loss:0.0012786803093663966\n",
      "train loss:0.004871688594225234\n",
      "train loss:0.0011302082455648791\n",
      "train loss:0.007031060681752652\n",
      "train loss:0.002735662786630531\n",
      "train loss:0.004235467204502404\n",
      "train loss:0.001119011867128848\n",
      "train loss:0.000794171488996137\n",
      "train loss:0.0002032909070021047\n",
      "train loss:2.8285554219872372e-05\n",
      "train loss:0.0003684293456796034\n",
      "train loss:0.0001400381143039718\n",
      "train loss:0.000655903158528002\n",
      "train loss:0.0012488176753566223\n",
      "train loss:0.00013105362150335923\n",
      "train loss:0.0021834952131703444\n",
      "train loss:0.000780293547444665\n",
      "train loss:0.0004471288986192261\n",
      "train loss:0.00010481214139652422\n",
      "train loss:0.0002859008788252034\n",
      "train loss:0.00046824390769832733\n",
      "train loss:4.366561024435336e-05\n",
      "train loss:0.0013946891027861589\n",
      "train loss:0.00030855625642741113\n",
      "train loss:0.002240135300680981\n",
      "train loss:0.005591976903324588\n",
      "train loss:0.00011544650340215825\n",
      "train loss:0.00022948425974458653\n",
      "train loss:0.00023854917217895947\n",
      "train loss:0.0006048060608914876\n",
      "train loss:0.0011790016115752562\n",
      "train loss:0.0004689362073425622\n",
      "train loss:0.000461271523928445\n",
      "train loss:0.0007525148932998004\n",
      "train loss:0.0004998760469152743\n",
      "train loss:0.001144755224561123\n",
      "train loss:4.4603792090007814e-05\n",
      "train loss:8.232259830942924e-05\n",
      "train loss:0.00046367893002591205\n",
      "train loss:0.000844308885031374\n",
      "train loss:0.0005498395011970474\n",
      "train loss:0.0008029511071879219\n",
      "train loss:0.001265473320262099\n",
      "train loss:0.0006143279801824196\n",
      "train loss:0.00010669914843303209\n",
      "train loss:0.0034102981677970024\n",
      "train loss:0.0011440121034010135\n",
      "train loss:0.0038663699778080183\n",
      "train loss:0.0015595748523750742\n",
      "train loss:0.0008266387471793438\n",
      "train loss:0.00012607812705158356\n",
      "train loss:0.0007534027554745925\n",
      "train loss:0.004616034530811486\n",
      "train loss:0.002882968424295755\n",
      "train loss:0.003654086930316514\n",
      "train loss:0.0003842427086039899\n",
      "train loss:0.00018733200709770338\n",
      "train loss:0.0032638373837863793\n",
      "train loss:0.002146042796479099\n",
      "train loss:0.00023597295578355916\n",
      "train loss:0.0010051010656326272\n",
      "train loss:0.0005081223191116404\n",
      "train loss:0.0010472548870881025\n",
      "train loss:0.00013651777723697891\n",
      "train loss:0.0008957059762760409\n",
      "train loss:0.0011313955893461174\n",
      "train loss:3.148151602978314e-05\n",
      "train loss:0.0005355125145388273\n",
      "train loss:0.0004242318832569394\n",
      "train loss:0.0034465979733575673\n",
      "train loss:0.0011023031805594912\n",
      "train loss:0.0007879619512139084\n",
      "train loss:0.007592551281823779\n",
      "train loss:0.0002563403999698478\n",
      "train loss:0.0003076946085580159\n",
      "train loss:0.0007071144146038044\n",
      "train loss:0.0025535843286565983\n",
      "train loss:0.0011188624975735978\n",
      "train loss:0.003998923982520427\n",
      "train loss:0.0012862102680104859\n",
      "train loss:0.002280256861954892\n",
      "train loss:0.00025304818276249337\n",
      "train loss:0.0018006719194855224\n",
      "train loss:0.00024725788413773375\n",
      "train loss:0.0006278782868327562\n",
      "train loss:0.00042804705786919373\n",
      "train loss:2.5385393594882084e-05\n",
      "train loss:0.0002711583814085607\n",
      "train loss:0.0002696537934539104\n",
      "train loss:0.007323269683889489\n",
      "train loss:0.00019060264686912215\n",
      "train loss:0.002131552423955461\n",
      "train loss:0.0004483273163623146\n",
      "train loss:0.0002669830858237268\n",
      "train loss:0.0005074607271718576\n",
      "train loss:0.0005047669160366398\n",
      "train loss:0.0035282399603831695\n",
      "train loss:0.0007420240909691131\n",
      "train loss:0.0002763990024228675\n",
      "train loss:0.0009829160297470949\n",
      "train loss:0.0001240916091376722\n",
      "train loss:0.003323009397348307\n",
      "train loss:0.0008950736147125443\n",
      "train loss:0.002931760048597421\n",
      "train loss:0.006412638879819843\n",
      "train loss:0.020801675233224976\n",
      "train loss:0.004141574967229237\n",
      "train loss:0.0008826632091148586\n",
      "train loss:0.0009841394279761352\n",
      "train loss:0.0003729788998326114\n",
      "train loss:0.0007380065747330627\n",
      "train loss:0.00028291265373107504\n",
      "train loss:0.001331058206897493\n",
      "train loss:0.0008688673536609918\n",
      "train loss:0.027714115624338877\n",
      "train loss:0.002341276643238742\n",
      "train loss:0.0005301420225296441\n",
      "train loss:0.0006157756043404222\n",
      "train loss:0.001435257719954878\n",
      "train loss:0.008210950370535769\n",
      "train loss:0.010771539260272345\n",
      "train loss:0.0006850103132531603\n",
      "train loss:0.0003165163959756353\n",
      "train loss:0.00016275437106588088\n",
      "train loss:0.00014131008358737602\n",
      "train loss:0.0004920806710778684\n",
      "train loss:0.0012129913131531962\n",
      "train loss:0.0007936725411319788\n",
      "train loss:0.0031574554792733562\n",
      "train loss:0.0013393065071160449\n",
      "train loss:0.0006788434190493809\n",
      "train loss:0.0054718741075052675\n",
      "train loss:0.00015556218108068003\n",
      "train loss:0.010064176206963003\n",
      "train loss:0.0028069450563584326\n",
      "train loss:0.0056396591123798944\n",
      "train loss:0.0033264677131577157\n",
      "train loss:0.005270559086448298\n",
      "train loss:0.0013087950803662637\n",
      "train loss:0.0007596703560251931\n",
      "train loss:0.0002033645167676491\n",
      "train loss:0.0005980357274320904\n",
      "train loss:0.0002765291426505046\n",
      "train loss:0.011417356388247788\n",
      "train loss:0.003102075196001292\n",
      "train loss:0.0012866558975382504\n",
      "train loss:0.00025731491599080303\n",
      "train loss:0.00030859438600771145\n",
      "train loss:0.0013705244276234012\n",
      "train loss:0.00029221091820363785\n",
      "train loss:0.0002486266299893848\n",
      "train loss:0.0008334685573249994\n",
      "train loss:0.0004422015559547273\n",
      "train loss:0.0003091559020425785\n",
      "train loss:0.004890152742335198\n",
      "train loss:0.00016364808864353174\n",
      "train loss:0.0016625186661031\n",
      "train loss:0.012843522004726122\n",
      "train loss:0.0004973374177280363\n",
      "train loss:0.002303952360299595\n",
      "train loss:0.0020058016006597314\n",
      "train loss:0.0016996192405309696\n",
      "train loss:0.00925871600411083\n",
      "train loss:0.003411504217179684\n",
      "train loss:0.0003844176178322092\n",
      "train loss:0.0008292475205208037\n",
      "train loss:0.0021076780969721317\n",
      "train loss:0.00021427665823716072\n",
      "train loss:0.00024701698485914847\n",
      "train loss:0.0016015080781657627\n",
      "train loss:0.0012667458413974466\n",
      "train loss:0.0026395893926508935\n",
      "train loss:0.0026718542643903564\n",
      "train loss:0.001995230297322047\n",
      "train loss:0.025241126216037354\n",
      "train loss:0.0002847642448763187\n",
      "train loss:0.0006805819685240967\n",
      "train loss:6.679220913848675e-05\n",
      "train loss:0.00010775833220418202\n",
      "train loss:0.0037938383592873875\n",
      "train loss:0.004118242107988056\n",
      "train loss:0.000319899811263278\n",
      "train loss:0.003594244296737567\n",
      "train loss:0.0003110920488119759\n",
      "train loss:0.005191424911522894\n",
      "train loss:0.0031811991672161016\n",
      "train loss:5.929930540741598e-05\n",
      "train loss:0.0006697579853995149\n",
      "train loss:0.0011023451426263263\n",
      "train loss:0.0013738034437064364\n",
      "train loss:0.0010768021073803086\n",
      "train loss:0.0024789842134684235\n",
      "train loss:0.0007334535383285393\n",
      "train loss:0.0006500526388107242\n",
      "train loss:0.0011059699671835599\n",
      "train loss:0.002904490104759031\n",
      "train loss:0.0014359469170109882\n",
      "train loss:0.00011541512892803527\n",
      "train loss:2.176720694654017e-05\n",
      "train loss:0.0010937814829617147\n",
      "train loss:0.0012812079449491113\n",
      "train loss:0.00019555808685110587\n",
      "train loss:0.008962569129840243\n",
      "train loss:0.0034215683058453337\n",
      "train loss:0.0001942709455030318\n",
      "train loss:0.0003713252827868923\n",
      "train loss:0.0003944734169218033\n",
      "train loss:0.009633599580645835\n",
      "train loss:6.85744920360834e-05\n",
      "train loss:0.003951210803137144\n",
      "train loss:0.004065049570050865\n",
      "train loss:0.005342113552576573\n",
      "train loss:0.0006688466051966374\n",
      "train loss:0.0001810501900589915\n",
      "train loss:0.0007323278378580369\n",
      "train loss:0.002744423398450393\n",
      "train loss:0.0016171453112467959\n",
      "train loss:0.0008779924019118738\n",
      "train loss:0.00012356411944591057\n",
      "train loss:0.0008028995182226943\n",
      "train loss:0.0018226342681770113\n",
      "train loss:0.00653263163438837\n",
      "train loss:0.0007160995272068845\n",
      "train loss:0.0010099894437754344\n",
      "train loss:0.00197942283462341\n",
      "train loss:0.0017940156131169185\n",
      "train loss:0.0012470833718634421\n",
      "train loss:0.0006552246841363307\n",
      "train loss:0.0010140505902302365\n",
      "train loss:0.00412400796311917\n",
      "train loss:0.002886561663205477\n",
      "train loss:0.008611677251525339\n",
      "train loss:0.0014063168358269857\n",
      "train loss:0.0009253470916360123\n",
      "train loss:0.002524406703806276\n",
      "train loss:0.006649375803228711\n",
      "train loss:0.00017583574663377586\n",
      "train loss:0.0018779276345245691\n",
      "train loss:0.0007609123997115628\n",
      "train loss:0.0033099639272063308\n",
      "train loss:6.794489967502736e-05\n",
      "train loss:0.00366662989509123\n",
      "train loss:0.004115547060763875\n",
      "train loss:0.0003831971451812648\n",
      "train loss:0.0011920762630822695\n",
      "train loss:0.0005585328276016307\n",
      "train loss:0.0015223496923110601\n",
      "train loss:0.010442386245586568\n",
      "train loss:0.00012950671155754305\n",
      "train loss:0.0011332191470868431\n",
      "train loss:0.0008928199040838355\n",
      "train loss:0.00010365268465653683\n",
      "train loss:0.013191374157971857\n",
      "train loss:0.0008446563857716634\n",
      "train loss:0.0035052408939545542\n",
      "train loss:0.013350642082139931\n",
      "train loss:2.0980787872422504e-05\n",
      "train loss:0.005956137313162102\n",
      "train loss:0.004295396209005183\n",
      "train loss:0.004019885534177219\n",
      "train loss:0.0006717261227907642\n",
      "train loss:0.0012063258842405294\n",
      "train loss:4.735492735387986e-05\n",
      "train loss:0.005446811604911941\n",
      "train loss:0.001452304793216716\n",
      "train loss:0.000653771080878756\n",
      "train loss:9.99743154722129e-05\n",
      "train loss:0.0011732293667957119\n",
      "train loss:0.0060827841753552415\n",
      "train loss:0.00010697750365221235\n",
      "train loss:0.0011660130143626196\n",
      "train loss:0.0001896811169491065\n",
      "train loss:0.001548845493719611\n",
      "train loss:0.001531306789877111\n",
      "train loss:0.0002516383905784866\n",
      "train loss:0.03703053270037548\n",
      "train loss:0.0014371242971685607\n",
      "train loss:0.00030615772188390876\n",
      "train loss:0.0010204787788113106\n",
      "train loss:0.0007806748107062815\n",
      "=== epoch:19, train acc:0.996, test acc:0.99 ===\n",
      "train loss:9.506167895920662e-05\n",
      "train loss:0.0006098553493566949\n",
      "train loss:0.0034013221452838505\n",
      "train loss:0.0012105286787191015\n",
      "train loss:0.002277274520549206\n",
      "train loss:0.003210592287273075\n",
      "train loss:0.0037025916770542016\n",
      "train loss:0.003640478687882482\n",
      "train loss:0.000518079585303894\n",
      "train loss:0.0005507098718641804\n",
      "train loss:0.0035257565534910123\n",
      "train loss:0.000226989707260061\n",
      "train loss:0.00045874126848270686\n",
      "train loss:0.0007713516615376828\n",
      "train loss:0.0015486017918779381\n",
      "train loss:0.0016196160508400604\n",
      "train loss:0.0019608053589224637\n",
      "train loss:0.0022982619904651867\n",
      "train loss:0.0010372609480419053\n",
      "train loss:0.004256734920428112\n",
      "train loss:0.0019906917941739845\n",
      "train loss:0.0009992013227202307\n",
      "train loss:0.0016434972253190777\n",
      "train loss:0.00036880634617456976\n",
      "train loss:0.0003935372568969346\n",
      "train loss:0.0008307851463282548\n",
      "train loss:0.029968625118337703\n",
      "train loss:0.00034782206039701987\n",
      "train loss:0.002817033495209493\n",
      "train loss:0.013285752023712712\n",
      "train loss:0.00032821783885316326\n",
      "train loss:0.0054577086259237325\n",
      "train loss:0.0006599514346782704\n",
      "train loss:0.0026856793926135995\n",
      "train loss:2.714009804319475e-05\n",
      "train loss:0.00034079618847843954\n",
      "train loss:0.00025052973584546706\n",
      "train loss:0.0036882172499007756\n",
      "train loss:0.00016133382018351393\n",
      "train loss:0.0027296499922938307\n",
      "train loss:0.0032535004329333765\n",
      "train loss:0.0022431474462910562\n",
      "train loss:0.0019412580750424173\n",
      "train loss:0.0012993910274513487\n",
      "train loss:0.0003926596477512791\n",
      "train loss:0.0004619921320577143\n",
      "train loss:0.0006575735100846502\n",
      "train loss:0.0017938763802814834\n",
      "train loss:0.0009466277247128035\n",
      "train loss:0.0020937060459124707\n",
      "train loss:0.002090773247609137\n",
      "train loss:8.465994994938161e-05\n",
      "train loss:0.0001955405447664554\n",
      "train loss:0.001147150846879545\n",
      "train loss:0.001019931810562519\n",
      "train loss:0.03091249761800836\n",
      "train loss:4.713878276069163e-05\n",
      "train loss:0.0025798579555457906\n",
      "train loss:0.00039141200688776884\n",
      "train loss:0.0013601008064098642\n",
      "train loss:0.00019002964127480106\n",
      "train loss:0.00015247666680500327\n",
      "train loss:0.00025064470892600233\n",
      "train loss:0.00037814341388814045\n",
      "train loss:8.98233706823205e-05\n",
      "train loss:0.0006609113597910693\n",
      "train loss:0.006795321608768784\n",
      "train loss:0.007233683387003523\n",
      "train loss:0.0003685644911853747\n",
      "train loss:0.0025670622302604133\n",
      "train loss:0.002227661728102614\n",
      "train loss:3.518420723284778e-05\n",
      "train loss:0.00042305549497288986\n",
      "train loss:0.002315869944484217\n",
      "train loss:0.0005287640497203711\n",
      "train loss:0.01103204750968633\n",
      "train loss:0.001488423777184303\n",
      "train loss:0.00011175850285902847\n",
      "train loss:0.0006991309402356461\n",
      "train loss:0.0010693944801679525\n",
      "train loss:0.001108993051303831\n",
      "train loss:0.0005208328576974529\n",
      "train loss:0.0025657557577479697\n",
      "train loss:0.000530523429646109\n",
      "train loss:0.0011664700835682233\n",
      "train loss:0.000154858453789769\n",
      "train loss:0.011017636369934709\n",
      "train loss:0.00018938369850545156\n",
      "train loss:0.00042694476282361277\n",
      "train loss:0.001040270370551767\n",
      "train loss:0.0014951022365134747\n",
      "train loss:0.0010372984769738648\n",
      "train loss:9.356597185923868e-05\n",
      "train loss:0.00014020293689744536\n",
      "train loss:0.005104470716203894\n",
      "train loss:0.00039494505906759745\n",
      "train loss:0.0008071969263913363\n",
      "train loss:0.007806564577743999\n",
      "train loss:0.00021186209945995484\n",
      "train loss:0.0012364670647832777\n",
      "train loss:0.0018184475578470524\n",
      "train loss:4.348510301229414e-05\n",
      "train loss:0.00047777494557793966\n",
      "train loss:0.00024178817187576394\n",
      "train loss:0.0021968219894450197\n",
      "train loss:0.0006555238762161116\n",
      "train loss:0.0007512077900157352\n",
      "train loss:0.00015253046614091358\n",
      "train loss:0.00031837509479017053\n",
      "train loss:0.001585760519516562\n",
      "train loss:0.0014513648107131885\n",
      "train loss:0.0008933416636689297\n",
      "train loss:0.00010035453694921176\n",
      "train loss:0.00034657933171433077\n",
      "train loss:0.0011548436616333738\n",
      "train loss:0.0006067385369074319\n",
      "train loss:0.010789209721903248\n",
      "train loss:0.0005406151244138852\n",
      "train loss:0.0016470841538773358\n",
      "train loss:0.0007444182203182558\n",
      "train loss:0.0018764074606301623\n",
      "train loss:0.004358547998480996\n",
      "train loss:0.0003153212659626505\n",
      "train loss:0.00036097401156834634\n",
      "train loss:0.00015395844959991038\n",
      "train loss:0.0008184393687630975\n",
      "train loss:9.517931803246697e-05\n",
      "train loss:0.0023925404740307503\n",
      "train loss:0.0006750940305630176\n",
      "train loss:0.0007972781155698631\n",
      "train loss:0.002778495055868787\n",
      "train loss:0.0007685793623884545\n",
      "train loss:0.000975289484067721\n",
      "train loss:0.0002707114220543599\n",
      "train loss:0.0003381904328026618\n",
      "train loss:0.002429527453480641\n",
      "train loss:0.00035983836258337567\n",
      "train loss:0.001120143381224213\n",
      "train loss:8.81361034431667e-05\n",
      "train loss:0.0003275298004724671\n",
      "train loss:0.0018124598176827045\n",
      "train loss:0.00018250796264017481\n",
      "train loss:0.00016943085013208719\n",
      "train loss:0.002330175538892543\n",
      "train loss:0.0005573719959977744\n",
      "train loss:3.7120061491654525e-05\n",
      "train loss:0.00011823509344555493\n",
      "train loss:0.002074035249877905\n",
      "train loss:0.0029095663980595434\n",
      "train loss:9.095950081387753e-05\n",
      "train loss:0.00018530350621552316\n",
      "train loss:0.0001384889224257137\n",
      "train loss:0.00014366578368741202\n",
      "train loss:0.0002340775731270733\n",
      "train loss:0.00011083527661748268\n",
      "train loss:0.00017807353098388853\n",
      "train loss:0.00019758549250240205\n",
      "train loss:0.002890420014083449\n",
      "train loss:0.0004935235469584919\n",
      "train loss:0.0015529858680809875\n",
      "train loss:5.707206073402296e-05\n",
      "train loss:5.487061257796922e-05\n",
      "train loss:0.0006498802846415272\n",
      "train loss:0.001264245497828796\n",
      "train loss:0.0007905186242768022\n",
      "train loss:0.0023401958411963563\n",
      "train loss:0.0002460147844329113\n",
      "train loss:0.005103174577574057\n",
      "train loss:0.0016663834185858151\n",
      "train loss:0.0004940375841764552\n",
      "train loss:7.235282619847511e-05\n",
      "train loss:4.70924114336131e-05\n",
      "train loss:0.0035999228754565395\n",
      "train loss:7.542763970037355e-05\n",
      "train loss:0.0020380187339656955\n",
      "train loss:8.907958191934076e-05\n",
      "train loss:0.000526935339503222\n",
      "train loss:0.0016980926561012473\n",
      "train loss:0.00010499674490647963\n",
      "train loss:0.0003673714871620671\n",
      "train loss:0.0010720850252316934\n",
      "train loss:0.00420609938050122\n",
      "train loss:0.007534931469747193\n",
      "train loss:0.0008696425908466809\n",
      "train loss:9.84146018094348e-05\n",
      "train loss:0.00047141747769266355\n",
      "train loss:0.026133384212853515\n",
      "train loss:0.002451716489415072\n",
      "train loss:0.0006768490340382448\n",
      "train loss:0.00023199910090594266\n",
      "train loss:0.005513231615731549\n",
      "train loss:0.0009543813244360184\n",
      "train loss:0.00031835125450887597\n",
      "train loss:0.0023733079236398368\n",
      "train loss:0.0006102765094709746\n",
      "train loss:0.008357524589230867\n",
      "train loss:0.0014053180141789566\n",
      "train loss:5.546739878313361e-05\n",
      "train loss:0.001989873071674686\n",
      "train loss:0.000867221140683025\n",
      "train loss:0.0006794626467410783\n",
      "train loss:0.005063808771526367\n",
      "train loss:0.0008009088191516489\n",
      "train loss:0.0028702439051591167\n",
      "train loss:0.004816072094132814\n",
      "train loss:0.0015459973040635924\n",
      "train loss:0.0002576811603856364\n",
      "train loss:0.0003461898407092529\n",
      "train loss:0.00294564295502813\n",
      "train loss:0.0001045594233994353\n",
      "train loss:0.0007872542727779089\n",
      "train loss:0.0046441345713984505\n",
      "train loss:0.0001480840684468591\n",
      "train loss:0.0012207043140998633\n",
      "train loss:0.0023726126353185565\n",
      "train loss:0.002887882375155663\n",
      "train loss:0.0016314841324069765\n",
      "train loss:0.00024091968615094883\n",
      "train loss:0.00014058983330693975\n",
      "train loss:7.648684558468811e-05\n",
      "train loss:0.0001541367921895656\n",
      "train loss:0.00016477825409737059\n",
      "train loss:0.001075801639698402\n",
      "train loss:0.0004148655263979619\n",
      "train loss:2.831621875761697e-05\n",
      "train loss:0.0043240690133008785\n",
      "train loss:0.0006298590554074385\n",
      "train loss:0.00013043241101713763\n",
      "train loss:0.0018716658909097208\n",
      "train loss:0.0005916077040044921\n",
      "train loss:0.0003431855115455344\n",
      "train loss:0.00012500065242671883\n",
      "train loss:0.00020949735965263667\n",
      "train loss:0.0005535982312364901\n",
      "train loss:0.0012327589662317164\n",
      "train loss:0.00024015341031346862\n",
      "train loss:0.0010660172315171052\n",
      "train loss:0.0006818452723270517\n",
      "train loss:0.001483802045955214\n",
      "train loss:0.0004932351177247059\n",
      "train loss:6.258035197201206e-05\n",
      "train loss:0.0028095887365293826\n",
      "train loss:0.00013076942772791245\n",
      "train loss:0.0011883613101112119\n",
      "train loss:0.0017378610180918675\n",
      "train loss:0.00022495497967646268\n",
      "train loss:4.0416495933558726e-05\n",
      "train loss:0.00022234820365459298\n",
      "train loss:0.007476945286129609\n",
      "train loss:0.0017044107932584602\n",
      "train loss:0.001902160730897906\n",
      "train loss:0.003994624395490748\n",
      "train loss:0.00018532485484320182\n",
      "train loss:0.0012579101347086471\n",
      "train loss:0.0006217002805074435\n",
      "train loss:0.0008140543311829295\n",
      "train loss:0.0018329517082301323\n",
      "train loss:0.000338767489502456\n",
      "train loss:0.0015616713840877435\n",
      "train loss:0.00036962232225366647\n",
      "train loss:9.925065503338985e-05\n",
      "train loss:0.00029499401259637157\n",
      "train loss:0.002313600565738649\n",
      "train loss:0.000418694888463554\n",
      "train loss:0.00030836290909644955\n",
      "train loss:0.0003906952183568062\n",
      "train loss:8.81489397942571e-05\n",
      "train loss:0.006421545632471329\n",
      "train loss:0.00011874397469102936\n",
      "train loss:0.0017083579410832766\n",
      "train loss:0.0020616608344025803\n",
      "train loss:0.0006597445588646359\n",
      "train loss:0.00016266896915379875\n",
      "train loss:9.23756167118308e-05\n",
      "train loss:0.00033408328704146584\n",
      "train loss:0.002162460883020643\n",
      "train loss:0.0012204952244112008\n",
      "train loss:0.0043853192205282\n",
      "train loss:0.0005088950348586857\n",
      "train loss:0.0041149731695792925\n",
      "train loss:0.0022285428243990334\n",
      "train loss:0.00018373690476310278\n",
      "train loss:0.0034257580117449645\n",
      "train loss:0.0007067227520426828\n",
      "train loss:0.00031746142536033257\n",
      "train loss:0.00010520484281588721\n",
      "train loss:0.00021942256995644477\n",
      "train loss:0.0007931314623065336\n",
      "train loss:4.638185591989558e-05\n",
      "train loss:5.578029010130474e-05\n",
      "train loss:0.0002661803138765941\n",
      "train loss:0.0013006157922930885\n",
      "train loss:0.002204887696801993\n",
      "train loss:0.0018039926361001133\n",
      "train loss:0.0013574854111083323\n",
      "train loss:2.024593628973046e-05\n",
      "train loss:0.00010015809601337923\n",
      "train loss:0.0019144800883038498\n",
      "train loss:0.002317334696000499\n",
      "train loss:0.00034082302347424406\n",
      "train loss:0.0012697760824553794\n",
      "train loss:0.009309655723126121\n",
      "train loss:0.0013747984466777174\n",
      "train loss:0.002418781563512593\n",
      "train loss:0.0032740347369448163\n",
      "train loss:0.000984538744880327\n",
      "train loss:0.00041435527139332853\n",
      "train loss:0.00024482387418623785\n",
      "train loss:0.002068479058280073\n",
      "train loss:0.0007818272593532395\n",
      "train loss:0.0004128018364282472\n",
      "train loss:0.0028343309483030493\n",
      "train loss:0.0009292454216435436\n",
      "train loss:0.0009264966217331877\n",
      "train loss:0.0004690895528382838\n",
      "train loss:0.004142556501157234\n",
      "train loss:0.0025943079604773757\n",
      "train loss:0.0004522654930779833\n",
      "train loss:0.0002559523094803208\n",
      "train loss:9.390904839977981e-05\n",
      "train loss:0.0005930124028516128\n",
      "train loss:0.003924237493574089\n",
      "train loss:0.0001741950203011549\n",
      "train loss:0.0003181640863235746\n",
      "train loss:0.0002737618096492039\n",
      "train loss:0.0007670434620775616\n",
      "train loss:0.001165417548888451\n",
      "train loss:0.0005477673591882167\n",
      "train loss:0.0025256316142310943\n",
      "train loss:0.0003767795140453912\n",
      "train loss:0.006343184378620446\n",
      "train loss:0.000620969570191307\n",
      "train loss:6.140111550915644e-05\n",
      "train loss:0.0006476025664023472\n",
      "train loss:0.006974962590504774\n",
      "train loss:0.0005568358012516385\n",
      "train loss:0.000833964448791228\n",
      "train loss:0.0003441592979691028\n",
      "train loss:5.022256404740631e-05\n",
      "train loss:0.0019267506089994378\n",
      "train loss:3.725870438287273e-05\n",
      "train loss:0.0027866871675107387\n",
      "train loss:0.0015951484631020433\n",
      "train loss:0.0012014819811368917\n",
      "train loss:0.0005646070844105776\n",
      "train loss:0.0018396010368605994\n",
      "train loss:0.0017431960773321353\n",
      "train loss:0.0033693158929821616\n",
      "train loss:0.0006164567187575272\n",
      "train loss:0.003122746170269223\n",
      "train loss:0.0018157477738742645\n",
      "train loss:0.0012337816334733844\n",
      "train loss:0.0031773620007400556\n",
      "train loss:7.07525847477403e-05\n",
      "train loss:0.0010585641708719202\n",
      "train loss:4.456081872432625e-05\n",
      "train loss:0.0020671740709415952\n",
      "train loss:0.0013584603617794347\n",
      "train loss:0.005176284796621714\n",
      "train loss:0.0013430725941177713\n",
      "train loss:0.00024259294117213531\n",
      "train loss:0.0001363272266453781\n",
      "train loss:0.00018001074264511766\n",
      "train loss:0.0006951259708830775\n",
      "train loss:0.0005361389563907527\n",
      "train loss:0.004133749234059903\n",
      "train loss:0.0005391951465921216\n",
      "train loss:0.000911072734285236\n",
      "train loss:1.2260670329804876e-05\n",
      "train loss:0.001975551350794374\n",
      "train loss:0.0007793613164766218\n",
      "train loss:0.0003923832852756834\n",
      "train loss:0.0001304471960380839\n",
      "train loss:0.0010769048602844939\n",
      "train loss:0.0007646417454378775\n",
      "train loss:0.001630291255459712\n",
      "train loss:0.0006006155776477632\n",
      "train loss:0.012659630005906235\n",
      "train loss:5.555151758120205e-05\n",
      "train loss:0.0005394205726972926\n",
      "train loss:0.0016151017870761528\n",
      "train loss:0.00010496435831693832\n",
      "train loss:0.0060915616725680955\n",
      "train loss:0.0006279429451089266\n",
      "train loss:3.363173488225023e-05\n",
      "train loss:0.0011199099836023715\n",
      "train loss:0.00012803103360029564\n",
      "train loss:0.00010677153671179716\n",
      "train loss:0.0004579554208468571\n",
      "train loss:0.000219979063935851\n",
      "train loss:1.3170107432588229e-05\n",
      "train loss:0.00011301997422119014\n",
      "train loss:7.35633767975649e-05\n",
      "train loss:0.0003396953042826794\n",
      "train loss:0.0002639800077232687\n",
      "train loss:0.000577974318653036\n",
      "train loss:2.920218548788486e-05\n",
      "train loss:0.002620729831791552\n",
      "train loss:0.001968462594497633\n",
      "train loss:0.0012468498309360346\n",
      "train loss:8.981818880265381e-05\n",
      "train loss:0.0002882633393359878\n",
      "train loss:0.00045002629355690764\n",
      "train loss:0.0007808981349648291\n",
      "train loss:0.0002915885884379886\n",
      "train loss:0.0011317449758668147\n",
      "train loss:0.0005005478299228709\n",
      "train loss:3.297817700361184e-05\n",
      "train loss:0.0005440275468356593\n",
      "train loss:0.002744893447005001\n",
      "train loss:0.004685578112388345\n",
      "train loss:0.003157399964586483\n",
      "train loss:0.0005596966037137371\n",
      "train loss:0.0007571580845756247\n",
      "train loss:0.002901671609410647\n",
      "train loss:0.0007842798635696887\n",
      "train loss:0.00023766122862960883\n",
      "train loss:0.0010313332015466554\n",
      "train loss:0.00021267794128433697\n",
      "train loss:8.090061108937302e-05\n",
      "train loss:0.0010362563439834645\n",
      "train loss:0.0013244482234658183\n",
      "train loss:0.0006623454792387972\n",
      "train loss:0.0012872549039175205\n",
      "train loss:3.5750857310325996e-05\n",
      "train loss:0.0005685063078220399\n",
      "train loss:5.94200737642753e-05\n",
      "train loss:0.0026964307098017036\n",
      "train loss:0.00031206679598045397\n",
      "train loss:0.0038356510684678185\n",
      "train loss:0.0022754747503743143\n",
      "train loss:7.89025643624415e-05\n",
      "train loss:9.184829076759145e-05\n",
      "train loss:0.0013351206405829005\n",
      "train loss:0.0007384657508884783\n",
      "train loss:0.0012750931840251176\n",
      "train loss:4.771603386142942e-05\n",
      "train loss:0.000599801274949378\n",
      "train loss:0.000872047133727097\n",
      "train loss:0.00662426261210345\n",
      "train loss:0.0009624953244451603\n",
      "train loss:0.0007209205757389761\n",
      "train loss:0.000513776314478883\n",
      "train loss:0.006971937640780506\n",
      "train loss:0.0007937379187339963\n",
      "train loss:3.817199749861162e-05\n",
      "train loss:0.0001261193248327206\n",
      "train loss:0.0010016546068530973\n",
      "train loss:0.0017118706865704755\n",
      "train loss:0.00013676751787699708\n",
      "train loss:0.0001892667128980939\n",
      "train loss:0.00436371719150738\n",
      "train loss:8.956406681272712e-05\n",
      "train loss:0.0007013374094574856\n",
      "train loss:0.001984141975045536\n",
      "train loss:0.0011135332303328239\n",
      "train loss:0.00010395216642435773\n",
      "train loss:0.0007742190828032625\n",
      "train loss:0.0005761371466841825\n",
      "train loss:0.001735196735161493\n",
      "train loss:0.0005196465173092989\n",
      "train loss:0.0011640903182819104\n",
      "train loss:9.060530144425399e-05\n",
      "train loss:0.0004806273404030121\n",
      "train loss:0.0003875660912190307\n",
      "train loss:0.0007924653974392132\n",
      "train loss:0.00022218277226148232\n",
      "train loss:0.007841937539532705\n",
      "train loss:4.717436587312912e-05\n",
      "train loss:0.001112873191217517\n",
      "train loss:0.00020517250084910185\n",
      "train loss:0.004329868091643046\n",
      "train loss:0.004948714623594747\n",
      "train loss:0.0027817566634616487\n",
      "train loss:0.0022088370113545457\n",
      "train loss:0.0001904681711601822\n",
      "train loss:0.0001326099777413135\n",
      "train loss:7.48388880048475e-05\n",
      "train loss:0.0024865156381196143\n",
      "train loss:0.0009861224212813445\n",
      "train loss:0.002527830470849354\n",
      "train loss:0.00557485797124545\n",
      "train loss:0.0015967894116748545\n",
      "train loss:0.0003315629987455025\n",
      "train loss:0.0023589653088842\n",
      "train loss:0.0014355244979702899\n",
      "train loss:0.00015600154966453376\n",
      "train loss:0.0007944081977570222\n",
      "train loss:0.000796552149017541\n",
      "train loss:0.001965821015121531\n",
      "train loss:0.0004056258180463442\n",
      "train loss:0.003747092163838888\n",
      "train loss:0.0018574799721451506\n",
      "train loss:8.668947921531528e-05\n",
      "train loss:0.000471443020648526\n",
      "train loss:0.00014179546625398804\n",
      "train loss:0.0002582961692203941\n",
      "train loss:0.0009116914964025999\n",
      "train loss:0.0010305941737371728\n",
      "train loss:0.00016633295321915977\n",
      "train loss:0.00012782364173674995\n",
      "train loss:0.0006980504234594062\n",
      "train loss:0.00015094648546110383\n",
      "train loss:0.0001590918195620323\n",
      "train loss:0.001562987623544182\n",
      "train loss:0.0005417400429168929\n",
      "train loss:2.0807524500868277e-05\n",
      "train loss:0.00271563653090975\n",
      "train loss:9.011713318171149e-05\n",
      "train loss:0.002243776619702615\n",
      "train loss:0.0008185334583412586\n",
      "train loss:0.0002884510250213419\n",
      "train loss:0.0004492335213295704\n",
      "train loss:0.0002458817081489743\n",
      "train loss:0.006755385989012952\n",
      "train loss:0.0030868729233577037\n",
      "train loss:0.0008206219066620238\n",
      "train loss:0.0025502787535325333\n",
      "train loss:0.0007064101526465952\n",
      "train loss:0.00011975189809040818\n",
      "train loss:0.00013647618879583258\n",
      "train loss:0.0031258034798580265\n",
      "train loss:0.0014249502975456354\n",
      "train loss:0.00014040453885945175\n",
      "train loss:0.0006902716688738475\n",
      "train loss:0.0017208378771340707\n",
      "train loss:0.0004031657775463078\n",
      "train loss:0.00015424124677638232\n",
      "train loss:0.00037088649407855017\n",
      "train loss:0.0015305147456929596\n",
      "train loss:7.885971505718757e-06\n",
      "train loss:0.0004442369813979493\n",
      "train loss:0.023786229923721557\n",
      "train loss:0.0013734835815116826\n",
      "train loss:0.0002053434345949726\n",
      "train loss:9.322649956230002e-05\n",
      "train loss:0.001535010239994138\n",
      "train loss:0.00048635071954243603\n",
      "train loss:0.004179361954300561\n",
      "train loss:0.001192914837971823\n",
      "train loss:0.0018556733406106755\n",
      "train loss:0.0017226269021135894\n",
      "train loss:0.000967664637647839\n",
      "train loss:0.00396963026133556\n",
      "train loss:0.0017222283482937822\n",
      "train loss:0.00014646072352068632\n",
      "train loss:0.00013379606515325526\n",
      "train loss:0.0001251529152311301\n",
      "train loss:0.0028751940951069377\n",
      "train loss:0.006344420266329488\n",
      "train loss:0.0014915089990339809\n",
      "train loss:0.001132697648890065\n",
      "train loss:0.005103215761072873\n",
      "train loss:0.00010886000595698874\n",
      "train loss:0.00016008234538552503\n",
      "train loss:0.0006523300527290827\n",
      "train loss:0.00039079437019714147\n",
      "train loss:6.10056704699557e-05\n",
      "train loss:0.0019867621097791853\n",
      "train loss:0.002664497360952463\n",
      "train loss:0.0001396999715997849\n",
      "train loss:5.270729453847996e-05\n",
      "train loss:0.0008868832842955037\n",
      "train loss:0.00037777737464116725\n",
      "train loss:0.0007433885018428733\n",
      "train loss:0.0016834950208323184\n",
      "train loss:0.0006251511363171137\n",
      "train loss:0.0009059182224960205\n",
      "train loss:0.0007230756690956249\n",
      "train loss:0.002269892481592911\n",
      "train loss:0.001264124278058919\n",
      "train loss:0.0019073014419714648\n",
      "train loss:0.0032359785181621183\n",
      "train loss:0.00034359332430165183\n",
      "train loss:2.5322427417285002e-05\n",
      "train loss:0.0010821516843937684\n",
      "train loss:5.278291641711346e-05\n",
      "train loss:0.0010174682748784923\n",
      "train loss:0.0015858805786230857\n",
      "train loss:0.00625590944561999\n",
      "train loss:0.00045994310512270523\n",
      "train loss:0.00025171416578599105\n",
      "train loss:0.0010123836976105175\n",
      "train loss:0.0003007386707363124\n",
      "train loss:0.0001389189259973987\n",
      "train loss:5.574600076848662e-05\n",
      "train loss:0.0023289594784455174\n",
      "train loss:0.004114668064909569\n",
      "train loss:2.186409674444151e-05\n",
      "train loss:0.00015938974998190442\n",
      "train loss:0.0001093529323567607\n",
      "train loss:0.0013354306053255261\n",
      "train loss:5.0343801283875544e-05\n",
      "train loss:0.0014660648948127927\n",
      "train loss:0.0030033884487622124\n",
      "train loss:0.0013923450288316444\n",
      "train loss:0.0028225738108550048\n",
      "train loss:0.0007127057498479873\n",
      "train loss:9.650767007534637e-05\n",
      "train loss:0.00027961120476973207\n",
      "=== epoch:20, train acc:0.998, test acc:0.988 ===\n",
      "train loss:0.0017346721842952416\n",
      "train loss:0.004491920095900232\n",
      "train loss:0.0002816831976779804\n",
      "train loss:0.0004208205867636682\n",
      "train loss:0.0009371053511084929\n",
      "train loss:5.872132271683715e-05\n",
      "train loss:0.0036961635516544263\n",
      "train loss:0.0005374309548930983\n",
      "train loss:0.001061621131520466\n",
      "train loss:0.00034398626302954385\n",
      "train loss:0.001065235133115567\n",
      "train loss:0.0009976638431239255\n",
      "train loss:0.00019414003622435195\n",
      "train loss:0.0009589079112779797\n",
      "train loss:5.7500004580526884e-05\n",
      "train loss:0.00019298821904291882\n",
      "train loss:0.013595049063552007\n",
      "train loss:0.0030522779916979594\n",
      "train loss:0.0005640016915840342\n",
      "train loss:0.00037768725121831674\n",
      "train loss:0.00014598460715172364\n",
      "train loss:0.0010591345637552985\n",
      "train loss:0.0005144924346430243\n",
      "train loss:0.0008876043575626175\n",
      "train loss:0.0006295829907603921\n",
      "train loss:0.0030224329007709685\n",
      "train loss:0.0002637236261465458\n",
      "train loss:0.0007601266468099091\n",
      "train loss:0.0005683783663788613\n",
      "train loss:0.0028498787315576896\n",
      "train loss:0.0005720621379888357\n",
      "train loss:0.0008597152828813375\n",
      "train loss:0.0008231082410944515\n",
      "train loss:0.0009132818782346349\n",
      "train loss:0.0009115605376328543\n",
      "train loss:0.0010996190539328615\n",
      "train loss:0.004833281062830124\n",
      "train loss:0.0007763813755581239\n",
      "train loss:0.0029189171294158713\n",
      "train loss:0.0018503499044822652\n",
      "train loss:0.000745270123587273\n",
      "train loss:0.0018439195729198015\n",
      "train loss:0.000832106447191991\n",
      "train loss:0.006803922647710795\n",
      "train loss:0.00044902762618740933\n",
      "train loss:0.0015179760796167699\n",
      "train loss:0.00207992100700983\n",
      "train loss:0.0019241953577934846\n",
      "train loss:0.0015754378459017324\n",
      "train loss:0.000587338694377268\n",
      "train loss:0.00017145944843399716\n",
      "train loss:0.0002274296716492922\n",
      "train loss:7.034763623663611e-05\n",
      "train loss:0.0007962615697347481\n",
      "train loss:0.0009117005982717296\n",
      "train loss:0.0004166592193387242\n",
      "train loss:0.0005796748519369396\n",
      "train loss:2.9576251692441973e-05\n",
      "train loss:7.910593925623436e-05\n",
      "train loss:0.0005116337746628272\n",
      "train loss:0.002483205664569352\n",
      "train loss:0.0022310339925310533\n",
      "train loss:0.007088206337890959\n",
      "train loss:9.405456942313212e-05\n",
      "train loss:0.00045983252324359306\n",
      "train loss:0.00029347429701723725\n",
      "train loss:0.0015301012910957734\n",
      "train loss:0.003842589655420973\n",
      "train loss:0.0014189336529972824\n",
      "train loss:0.0038271844410078843\n",
      "train loss:0.00608496325664143\n",
      "train loss:0.00013280601292070147\n",
      "train loss:4.8452386194075644e-05\n",
      "train loss:0.0009713152045578352\n",
      "train loss:0.002509596455001529\n",
      "train loss:0.0026671310750450783\n",
      "train loss:0.0010230187238165558\n",
      "train loss:0.004475067597640059\n",
      "train loss:0.0034124236180445304\n",
      "train loss:0.007312532295235117\n",
      "train loss:0.002931921845823761\n",
      "train loss:0.0027773485200461943\n",
      "train loss:0.0022884893155323757\n",
      "train loss:0.0001521859770202891\n",
      "train loss:0.0032692187602476586\n",
      "train loss:0.0011003532054236135\n",
      "train loss:0.0005067461940542568\n",
      "train loss:0.0009556154206392816\n",
      "train loss:9.356458014902753e-06\n",
      "train loss:3.5456158851199265e-05\n",
      "train loss:0.00046147280111292875\n",
      "train loss:0.0005391295406651077\n",
      "train loss:0.00449371674124879\n",
      "train loss:0.010905443284129844\n",
      "train loss:0.00033071540447491274\n",
      "train loss:0.0019123609946767534\n",
      "train loss:0.0002877443808342678\n",
      "train loss:0.0008366039109298986\n",
      "train loss:0.00012354591421257863\n",
      "train loss:0.0010015939295695971\n",
      "train loss:0.0002130024872518613\n",
      "train loss:0.00023483348236132256\n",
      "train loss:0.0008790936448113099\n",
      "train loss:0.002038110592116614\n",
      "train loss:0.003635608006500953\n",
      "train loss:0.0007755863632084423\n",
      "train loss:0.00020580248086125724\n",
      "train loss:0.0013525917768441695\n",
      "train loss:0.00041666340570096594\n",
      "train loss:0.0005319135384865911\n",
      "train loss:0.0031451437249573853\n",
      "train loss:0.00011187809343882988\n",
      "train loss:0.0016784081845477034\n",
      "train loss:0.00213468188430662\n",
      "train loss:0.004436241062948977\n",
      "train loss:0.0010174259636872936\n",
      "train loss:0.001534907656525001\n",
      "train loss:0.0003846072943537547\n",
      "train loss:0.0009713617092843257\n",
      "train loss:0.0002800663888175845\n",
      "train loss:0.0005367691384477326\n",
      "train loss:0.000799568131703915\n",
      "train loss:0.0005471125602389103\n",
      "train loss:0.0029137975822473576\n",
      "train loss:0.047418320035584306\n",
      "train loss:0.0001351528713433238\n",
      "train loss:0.0012708757215783362\n",
      "train loss:0.0007488681610956583\n",
      "train loss:0.0001728271671436697\n",
      "train loss:0.00013091026573178096\n",
      "train loss:0.0003385095125016157\n",
      "train loss:0.00036465108913570193\n",
      "train loss:0.000843426163230786\n",
      "train loss:0.0008366233527591381\n",
      "train loss:0.001467165326615423\n",
      "train loss:0.0003693657825904014\n",
      "train loss:0.00021919091562661155\n",
      "train loss:0.0004624935708254043\n",
      "train loss:0.0006991599868202722\n",
      "train loss:0.000758560963401919\n",
      "train loss:0.000957113358123046\n",
      "train loss:0.00028054442055208765\n",
      "train loss:0.0024229800305310386\n",
      "train loss:0.00044698651303497477\n",
      "train loss:0.00013902856338602492\n",
      "train loss:0.00889150261295003\n",
      "train loss:0.00043710849430476787\n",
      "train loss:0.0005827984938041072\n",
      "train loss:0.0005170717902672909\n",
      "train loss:0.0004640304435336537\n",
      "train loss:0.0006321772912968076\n",
      "train loss:0.0004052359673905064\n",
      "train loss:0.001151150605311789\n",
      "train loss:0.0025933358995216043\n",
      "train loss:0.00020504744802992675\n",
      "train loss:0.0016084450720099187\n",
      "train loss:0.0030095642636063986\n",
      "train loss:0.005253215342860979\n",
      "train loss:0.0002514602790757329\n",
      "train loss:0.00032196178851820093\n",
      "train loss:0.00010542871345549189\n",
      "train loss:0.00019501834289619157\n",
      "train loss:0.004667841049195948\n",
      "train loss:0.0003907865813690394\n",
      "train loss:0.0036614963051923057\n",
      "train loss:0.00018653883366486827\n",
      "train loss:0.00012826150869052575\n",
      "train loss:0.0012331414798111982\n",
      "train loss:0.0019094419244690723\n",
      "train loss:0.0002354808448889071\n",
      "train loss:0.0013517564756597663\n",
      "train loss:0.0070196567285171416\n",
      "train loss:0.0029397517298041477\n",
      "train loss:0.003041696339612266\n",
      "train loss:0.0021348596514580115\n",
      "train loss:0.0033622505931182978\n",
      "train loss:0.003722190130003772\n",
      "train loss:0.0005743503291232404\n",
      "train loss:0.0008647346875572748\n",
      "train loss:0.00044371862472854457\n",
      "train loss:0.00013929673387481114\n",
      "train loss:0.000138027380704394\n",
      "train loss:0.006009693480546977\n",
      "train loss:0.001462208768892569\n",
      "train loss:0.00011855310537169707\n",
      "train loss:5.223847019914376e-05\n",
      "train loss:0.00019701837539736668\n",
      "train loss:0.0003015672798059943\n",
      "train loss:2.8007281053761076e-05\n",
      "train loss:0.0023647486745377987\n",
      "train loss:0.0004409337989957688\n",
      "train loss:0.0011352206027975917\n",
      "train loss:0.0003088004543501191\n",
      "train loss:0.0005591009807531307\n",
      "train loss:0.0056076773447395565\n",
      "train loss:0.00728518725067762\n",
      "train loss:8.089172052869236e-05\n",
      "train loss:0.00016867828137056488\n",
      "train loss:0.0006575069394679185\n",
      "train loss:0.00012823761229435347\n",
      "train loss:0.00046862808787410774\n",
      "train loss:0.002945477302105366\n",
      "train loss:0.0012164417699206736\n",
      "train loss:0.0005192924397131138\n",
      "train loss:0.002004679990520234\n",
      "train loss:0.0006384834094075994\n",
      "train loss:0.00032826164661088045\n",
      "train loss:0.0010825826757691406\n",
      "train loss:0.00010620094551473262\n",
      "train loss:0.0005968788864890895\n",
      "train loss:0.0012130765988116168\n",
      "train loss:0.002259892020494361\n",
      "train loss:0.0019467634320560084\n",
      "train loss:0.001696635350878741\n",
      "train loss:0.0009539018480545256\n",
      "train loss:0.0014241259581597575\n",
      "train loss:0.0002669456825603421\n",
      "train loss:0.00039157096661986807\n",
      "train loss:0.002437089818765211\n",
      "train loss:0.0001891019732456378\n",
      "train loss:0.0005803280381349009\n",
      "train loss:0.00025218973230519564\n",
      "train loss:0.0007933166197955232\n",
      "train loss:0.0026375298763480475\n",
      "train loss:0.0001127127070531684\n",
      "train loss:0.00027634292206432843\n",
      "train loss:9.130467763154862e-05\n",
      "train loss:2.4790145541825023e-05\n",
      "train loss:0.0003729357381887996\n",
      "train loss:8.119842960259139e-05\n",
      "train loss:0.000783932444609358\n",
      "train loss:0.00018083098290640654\n",
      "train loss:0.00010988989910671279\n",
      "train loss:0.0010413332076116845\n",
      "train loss:0.00015691263262281876\n",
      "train loss:0.0033505045508875797\n",
      "train loss:0.0008964748054590217\n",
      "train loss:1.1066194126565055e-05\n",
      "train loss:0.0020521152389145923\n",
      "train loss:0.0006026870780914158\n",
      "train loss:1.0061683847596477e-05\n",
      "train loss:0.0009034099699984263\n",
      "train loss:0.00019841542081545493\n",
      "train loss:0.0007285546860162348\n",
      "train loss:5.592324767838983e-05\n",
      "train loss:4.103122278309843e-05\n",
      "train loss:2.7599172858924485e-05\n",
      "train loss:0.0020906569059979093\n",
      "train loss:0.00046560971060801234\n",
      "train loss:6.0294534468243116e-05\n",
      "train loss:0.0013512158288503196\n",
      "train loss:0.0011125115238310077\n",
      "train loss:0.00013081985200451648\n",
      "train loss:0.0017260924553277807\n",
      "train loss:0.00046162382494839213\n",
      "train loss:0.0013849175778189529\n",
      "train loss:0.00048405876184969546\n",
      "train loss:9.878409301470524e-05\n",
      "train loss:0.0021709762932222553\n",
      "train loss:0.0014907677462975772\n",
      "train loss:3.8678512006351526e-05\n",
      "train loss:0.0012147345550750958\n",
      "train loss:0.0007528905138984126\n",
      "train loss:6.5383356291756815e-06\n",
      "train loss:0.0018589998752713479\n",
      "train loss:0.00029534465428812304\n",
      "train loss:0.0006884415697592189\n",
      "train loss:0.0003562193957898192\n",
      "train loss:0.00011674633280073659\n",
      "train loss:0.004954154768588902\n",
      "train loss:0.001872926062759244\n",
      "train loss:0.005422801643176858\n",
      "train loss:0.00032511693669954244\n",
      "train loss:0.00037678490117324667\n",
      "train loss:0.0007320418264614858\n",
      "train loss:0.00022930445522011936\n",
      "train loss:0.002211767653813071\n",
      "train loss:0.0068115467316492\n",
      "train loss:0.0020811868645624265\n",
      "train loss:0.0009464878601242625\n",
      "train loss:0.0028827816338522104\n",
      "train loss:4.5778284643144295e-05\n",
      "train loss:8.02425870084946e-05\n",
      "train loss:3.812804343303054e-05\n",
      "train loss:0.0024131237459880063\n",
      "train loss:0.000990146948203316\n",
      "train loss:0.000883939102475961\n",
      "train loss:0.0029224593939076175\n",
      "train loss:0.0036517627638603207\n",
      "train loss:0.0007577136197665593\n",
      "train loss:0.0004809368808587414\n",
      "train loss:9.698045842530161e-05\n",
      "train loss:0.00026265532994529015\n",
      "train loss:0.00033348966443559955\n",
      "train loss:0.00010973252563210236\n",
      "train loss:0.0010811130269331982\n",
      "train loss:0.001635191800856171\n",
      "train loss:0.0022553773547751605\n",
      "train loss:5.689693522450342e-05\n",
      "train loss:0.00015398459353642763\n",
      "train loss:0.010690312553256198\n",
      "train loss:9.494232622734172e-05\n",
      "train loss:0.0016000925385520287\n",
      "train loss:0.0015241981468632954\n",
      "train loss:0.00019796184413617597\n",
      "train loss:0.0027910860518264666\n",
      "train loss:0.001232914447739663\n",
      "train loss:0.003999969916543844\n",
      "train loss:0.0013186902242208031\n",
      "train loss:0.003110294373201552\n",
      "train loss:0.0009180260981458057\n",
      "train loss:0.002670562487443387\n",
      "train loss:0.0002090297976320178\n",
      "train loss:0.0022332281056542044\n",
      "train loss:0.000576096434950437\n",
      "train loss:0.00022906660029612582\n",
      "train loss:0.0008761476110978099\n",
      "train loss:0.0010677756702027433\n",
      "train loss:0.0006077340604685226\n",
      "train loss:0.00014851698884050488\n",
      "train loss:0.002042194536684497\n",
      "train loss:0.0011651371439156968\n",
      "train loss:0.00014443683194757716\n",
      "train loss:0.0001689871155284565\n",
      "train loss:0.0006091839522831344\n",
      "train loss:0.0004442858418870308\n",
      "train loss:0.0007996821679678741\n",
      "train loss:0.00036297448699033446\n",
      "train loss:0.00020457212138105148\n",
      "train loss:0.0009003196488147854\n",
      "train loss:0.00026957224257278796\n",
      "train loss:0.00032717134835502355\n",
      "train loss:0.0039634017825202535\n",
      "train loss:0.0006757157847642792\n",
      "train loss:0.001236586419386917\n",
      "train loss:0.00243305091580201\n",
      "train loss:8.918163450992352e-05\n",
      "train loss:0.00038788383638724966\n",
      "train loss:0.0008301546698502331\n",
      "train loss:0.0003198511038113213\n",
      "train loss:0.0003997140454401149\n",
      "train loss:0.0008517170902596977\n",
      "train loss:1.4660540660389592e-05\n",
      "train loss:2.092030222888846e-05\n",
      "train loss:0.001182122027765657\n",
      "train loss:6.607133896512618e-05\n",
      "train loss:0.0004926978318698043\n",
      "train loss:0.0015624390324313587\n",
      "train loss:0.0017707704604580043\n",
      "train loss:0.008152890596671233\n",
      "train loss:0.00043833717470263947\n",
      "train loss:0.00023118389877889938\n",
      "train loss:0.00123396735034445\n",
      "train loss:0.00011235756661414336\n",
      "train loss:0.003582275948707022\n",
      "train loss:0.0017282641652839785\n",
      "train loss:0.0002545811724628059\n",
      "train loss:0.0011619864180592249\n",
      "train loss:4.091434088048049e-05\n",
      "train loss:0.0005386873224555458\n",
      "train loss:0.0003157464195648565\n",
      "train loss:0.0026828176121508453\n",
      "train loss:0.00126369222884025\n",
      "train loss:0.0015351891568258155\n",
      "train loss:0.0011632022657131107\n",
      "train loss:0.0001875693949588413\n",
      "train loss:0.0035032819718417195\n",
      "train loss:0.0007416157191443626\n",
      "train loss:0.0014440995670195356\n",
      "train loss:0.0004943939185683289\n",
      "train loss:0.0003739325807340257\n",
      "train loss:8.510715837555956e-05\n",
      "train loss:0.000725647824084763\n",
      "train loss:0.0014276639087361898\n",
      "train loss:0.003031200897322656\n",
      "train loss:0.006987618285238151\n",
      "train loss:0.0007706769842358912\n",
      "train loss:0.0004070212721782471\n",
      "train loss:0.00034342060055031986\n",
      "train loss:0.0010036040279187213\n",
      "train loss:0.0017306493020082785\n",
      "train loss:5.457109009379909e-05\n",
      "train loss:0.00011926838585475506\n",
      "train loss:0.0031133479541994007\n",
      "train loss:5.9523306326963916e-05\n",
      "train loss:0.00027216229188904007\n",
      "train loss:0.0006285328173171254\n",
      "train loss:6.550323865196263e-06\n",
      "train loss:6.57322514160961e-05\n",
      "train loss:3.1335250333894683e-05\n",
      "train loss:2.960630439383698e-05\n",
      "train loss:0.0002745269528048555\n",
      "train loss:7.483033151573443e-05\n",
      "train loss:4.144158883858647e-05\n",
      "train loss:0.0014957284130601514\n",
      "train loss:5.605432791513587e-05\n",
      "train loss:0.0010713435006234563\n",
      "train loss:0.000384301863174048\n",
      "train loss:0.002176557765562554\n",
      "train loss:0.0020554070495450356\n",
      "train loss:0.00025612943908249927\n",
      "train loss:0.0003625055174704617\n",
      "train loss:0.0002428237437739097\n",
      "train loss:0.00030096559794327583\n",
      "train loss:2.818723479109635e-05\n",
      "train loss:0.0021005891947626786\n",
      "train loss:0.0013182073871520037\n",
      "train loss:0.0014607999166424373\n",
      "train loss:0.0009082987523300176\n",
      "train loss:8.97700091861141e-05\n",
      "train loss:0.0007171749095368468\n",
      "train loss:0.0001249971931144411\n",
      "train loss:0.0013928143903226004\n",
      "train loss:0.005490919337863733\n",
      "train loss:0.0019326456279173357\n",
      "train loss:0.0003602311869662199\n",
      "train loss:0.0013794164107270538\n",
      "train loss:0.001357177333730146\n",
      "train loss:0.0002597582307564214\n",
      "train loss:0.00019762720644054345\n",
      "train loss:0.0019305627954577514\n",
      "train loss:0.0007476072061103061\n",
      "train loss:0.0020459734827734063\n",
      "train loss:0.0008806896877509855\n",
      "train loss:0.012684716051860927\n",
      "train loss:0.0002200010735945427\n",
      "train loss:0.0003132411968909134\n",
      "train loss:0.00213068055854418\n",
      "train loss:0.00039010882530738\n",
      "train loss:0.001247458450810353\n",
      "train loss:0.0011665555454170107\n",
      "train loss:0.0016737457848667293\n",
      "train loss:0.02667228563893409\n",
      "train loss:0.0014318269520613156\n",
      "train loss:0.0004555070914357216\n",
      "train loss:0.0020650003290584224\n",
      "train loss:0.0010322354602155998\n",
      "train loss:0.0002770108067593515\n",
      "train loss:0.003144298246384124\n",
      "train loss:0.0012590025735828285\n",
      "train loss:0.006507191202991822\n",
      "train loss:4.957609802371088e-05\n",
      "train loss:6.1000723062288075e-05\n",
      "train loss:0.019977388985577067\n",
      "train loss:0.016274677740551757\n",
      "train loss:0.005305655974964813\n",
      "train loss:0.003114036631125833\n",
      "train loss:0.0006495754388879138\n",
      "train loss:0.00022279204077660624\n",
      "train loss:0.00017708579712815263\n",
      "train loss:0.0026422416957443966\n",
      "train loss:0.0007063198244862153\n",
      "train loss:0.0014990517063400502\n",
      "train loss:0.0012948924529338796\n",
      "train loss:0.0012623145256029664\n",
      "train loss:0.0006475159447295099\n",
      "train loss:0.0016914242617519384\n",
      "train loss:0.0036381766063186987\n",
      "train loss:0.00027561959860742427\n",
      "train loss:0.0011577488503604434\n",
      "train loss:0.0015244609746723292\n",
      "train loss:0.004263240357591733\n",
      "train loss:0.0006790563063135423\n",
      "train loss:0.0036812492048975422\n",
      "train loss:0.0004450148397897403\n",
      "train loss:0.0007300600106482244\n",
      "train loss:9.417732976636072e-05\n",
      "train loss:0.001643297956896536\n",
      "train loss:0.0009509553445902066\n",
      "train loss:0.0013230145956586825\n",
      "train loss:6.434290304666879e-05\n",
      "train loss:0.000539971073593035\n",
      "train loss:0.0003357252603382632\n",
      "train loss:0.0075733569234019225\n",
      "train loss:0.0002663741911462137\n",
      "train loss:0.0020387690879854533\n",
      "train loss:0.00010792200524438083\n",
      "train loss:0.0006859841387056157\n",
      "train loss:0.0011115770321110845\n",
      "train loss:0.0004243583987514236\n",
      "train loss:0.00020549875662898744\n",
      "train loss:0.006198086669733255\n",
      "train loss:0.0006154327293986626\n",
      "train loss:0.0006158560867329678\n",
      "train loss:0.0017067615926765704\n",
      "train loss:0.0003501154593596967\n",
      "train loss:0.0007946946132656412\n",
      "train loss:0.0002706889675309789\n",
      "train loss:0.0013713851595261602\n",
      "train loss:0.0012150668448662994\n",
      "train loss:0.0004322576665508788\n",
      "train loss:0.0002930357232620091\n",
      "train loss:5.6113867143160746e-05\n",
      "train loss:0.00170798777676757\n",
      "train loss:8.228954735323318e-05\n",
      "train loss:0.00040437010750117965\n",
      "train loss:0.0008753637314313642\n",
      "train loss:2.5214375065959552e-05\n",
      "train loss:0.00038063508298655105\n",
      "train loss:0.00039338445299088703\n",
      "train loss:3.868897059968609e-05\n",
      "train loss:0.005949360815732702\n",
      "train loss:0.0016216492233613192\n",
      "train loss:4.87778636821419e-05\n",
      "train loss:0.005462430154569352\n",
      "train loss:1.2732725488018308e-05\n",
      "train loss:4.883478905368952e-05\n",
      "train loss:8.697877862193968e-05\n",
      "train loss:0.0011344822686517675\n",
      "train loss:0.00040171869057124956\n",
      "train loss:0.0013032340243816234\n",
      "train loss:0.00013047765386600067\n",
      "train loss:0.00031780878294460877\n",
      "train loss:0.0003214715224146607\n",
      "train loss:0.0007521338822236541\n",
      "train loss:0.0017650306006808914\n",
      "train loss:0.0009536652572351112\n",
      "train loss:0.0021762449395717697\n",
      "train loss:0.00023679376503285348\n",
      "train loss:0.0015799374444418965\n",
      "train loss:0.0028350005444684008\n",
      "train loss:0.00010082897653736745\n",
      "train loss:0.00013034757502373217\n",
      "train loss:0.0003571832478301512\n",
      "train loss:0.002471546952228367\n",
      "train loss:0.0005804112515200986\n",
      "train loss:0.0008062994529159391\n",
      "train loss:0.00016706852212010142\n",
      "train loss:8.923473188086153e-05\n",
      "train loss:0.0001081505247065159\n",
      "train loss:5.8170173566597564e-05\n",
      "train loss:0.00011357692251399634\n",
      "train loss:0.00394620603796441\n",
      "train loss:0.000179199072804959\n",
      "train loss:0.00020426623006186345\n",
      "train loss:0.00024784928623362477\n",
      "train loss:0.0013105478749015297\n",
      "train loss:0.00011836473027007882\n",
      "train loss:0.0010220685330468626\n",
      "train loss:0.0020302076591025065\n",
      "train loss:0.000104679222863376\n",
      "train loss:9.559983808674554e-05\n",
      "train loss:0.00040489805074688917\n",
      "train loss:1.221184373193395e-05\n",
      "train loss:0.003946930003521996\n",
      "train loss:0.002368236407646776\n",
      "train loss:0.0010539090239036423\n",
      "train loss:0.00034395317156349424\n",
      "train loss:0.0011433971550070875\n",
      "train loss:2.5463779083836937e-05\n",
      "train loss:8.605448675116131e-05\n",
      "train loss:0.0012124855844741532\n",
      "train loss:8.543285396679637e-05\n",
      "train loss:0.0009957090354326594\n",
      "train loss:0.0013809117177869057\n",
      "train loss:0.0002193192969164554\n",
      "train loss:5.7332106130893976e-05\n",
      "train loss:0.002604228015092039\n",
      "train loss:0.00027180677398789985\n",
      "train loss:2.3205633836367255e-05\n",
      "train loss:0.00022129987237679428\n",
      "train loss:0.00048668646930968325\n",
      "train loss:0.0003985906233562779\n",
      "train loss:4.7721339302060236e-05\n",
      "train loss:0.0003597735537667035\n",
      "train loss:6.995348657572371e-05\n",
      "train loss:6.590807604946178e-05\n",
      "train loss:0.008520501655163023\n",
      "train loss:0.0004249133594435588\n",
      "train loss:8.446338674619656e-05\n",
      "train loss:0.0021799148001772116\n",
      "train loss:0.00015809328528195064\n",
      "train loss:0.006247071308232045\n",
      "train loss:0.0009340061523201387\n",
      "train loss:0.00017166864545194245\n",
      "train loss:0.005251154609368691\n",
      "train loss:0.0009026220506550463\n",
      "train loss:0.0016412573615279572\n",
      "train loss:0.00681194533537051\n",
      "train loss:0.002441878683184386\n",
      "train loss:0.0003879952103707081\n",
      "train loss:0.003271993324433944\n",
      "train loss:9.872739851781511e-05\n",
      "train loss:0.0005643737248229658\n",
      "train loss:8.346331795613661e-05\n",
      "train loss:0.00015202920741348795\n",
      "train loss:0.0010349912747348198\n",
      "train loss:0.001340565714379172\n",
      "train loss:0.0012495838793115048\n",
      "train loss:0.000683464206181792\n",
      "train loss:0.00033834895267581045\n",
      "train loss:0.0012191830447855806\n",
      "train loss:0.002193637627181399\n",
      "train loss:0.0002788062135141032\n",
      "train loss:0.0020975514558214054\n",
      "train loss:0.0022473279982614313\n",
      "train loss:0.0006525900425078397\n",
      "train loss:0.002952073672032997\n",
      "train loss:0.0011606431934185978\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9901\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets.mnist import load_mnist\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6 CNN 시각화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.1 1번째 층의 가중치 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "network = SimpleConvNet()\n",
    "# 무작위(랜덤) 초기화 후의 가중치\n",
    "filter_show(network.params['W1'])\n",
    "\n",
    "# 학습된 가중치\n",
    "network.load_params(\"params.pkl\")\n",
    "filter_show(network.params['W1'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.2 층 깊이에 따른 추출 정보 변화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[노션 참고]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.7 대표적인 CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7.1 LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[노션 참고]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7.2 AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[노션 참고]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.8 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**이번 장에서 배운 내용**\n",
    "- CNN은 지금까지의 완전연결 계층 네트워크에 합성곱 계층과 풀링 계층을 새로 추가한다.\n",
    "- 합성곱 계층과 풀링 계층은 in2col(이미지를 행렬로 전개하는 함수)을 이용하면 간단하고 효율적으로 구현할 수 있다.\n",
    "- CNN을 시각화해보면 계층이 깊어질수록 고급 정보가 추출되는 모습을 확인할 수 있다.\n",
    "- 대표적인 CNN에는 LeNet과 AlexNet이 있다.\n",
    "- 딥러닝의 발전에는 빅데이터와 GPU가 크게 기여했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BAF_kernel",
   "language": "python",
   "name": "baf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
